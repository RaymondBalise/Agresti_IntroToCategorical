[["index.html", "Notes for Agresti’s Introduction to Categorical Data Analysis 3rd Edition 1 Introduction 1.1 Categorical Response Data 1.2 Probability Distributions for Categorical Data 1.3 Statistical Inference for a Proportion 1.4 Statistical Inference for Discrete Data 1.5 Bayesian Inference for Proportions 1.6 Using R software for Statistical Inference about Proportions Exercises", " Notes for Agresti’s Introduction to Categorical Data Analysis 3rd Edition Raymond R. Balise and Wayne F. DeFreitas 2021-01-08 1 Introduction 1.1 Categorical Response Data 1.1.1 Response Variables and Explanatory Variables 1.1.2 Binary-Nominal-Ordinal Scale Distinction 1.1.3 Organization of this Book 1.2 Probability Distributions for Categorical Data 1.2.1 Binomial Distribution \\[\\begin{equation} P(y) = \\frac{n!}{y(n-y)!}\\pi^y(1-\\pi)^{n-y},\\ y = 0, 1, 2, ..., n. \\tag{1} \\end{equation}\\] \\[P(0) = \\frac{10!}{0!10!}(0.20)^0(0.80)^{10} = (0.80)^{10} = 0.107\\] \\[P(1) = \\frac{10!}{1!9!}(0.20)^1(0.80)^{9} = 10(0.20)(0.80)^{9} = 0.268\\] library(kableExtra) bino &lt;- function(pi, n, y) { factorial(n) / (factorial(y) * factorial(n - y)) * pi ^ y * (1 - pi) ^ (n - y) } y &lt;-0:10 table1_1 &lt;- data.frame(y, x2 = bino(.2, 10, y), x3 = bino(.5, 10, y), x4 = bino(.8, 10, y)) kable(table1_1, digits = 3, align=&#39;c&#39;, col.names = c(&quot;$y$&quot;, &quot;$P(y)$ when $\\\\pi = 0.20$ $(\\\\mu = 2.0, \\\\sigma = 1.26)$&quot;, &quot;$P(y)$ when $\\\\pi = 0.50$ $(\\\\mu = 5.0, \\\\sigma = 1.58)$&quot;, &quot;$P(y)$ when $\\\\pi = 0.80$ $(\\\\mu = 8.0, \\\\sigma = 1.26)$&quot;)) \\(y\\) \\(P(y)\\) when \\(\\pi = 0.20\\) \\((\\mu = 2.0, \\sigma = 1.26)\\) \\(P(y)\\) when \\(\\pi = 0.50\\) \\((\\mu = 5.0, \\sigma = 1.58)\\) \\(P(y)\\) when \\(\\pi = 0.80\\) \\((\\mu = 8.0, \\sigma = 1.26)\\) 0 0.107 0.001 0.000 1 0.268 0.010 0.000 2 0.302 0.044 0.000 3 0.201 0.117 0.001 4 0.088 0.205 0.006 5 0.026 0.246 0.026 6 0.006 0.205 0.088 7 0.001 0.117 0.201 8 0.000 0.044 0.302 9 0.000 0.010 0.268 10 0.000 0.001 0.107 \\[E(Y)=\\mu=n\\pi,\\ \\sigma = \\sqrt{n\\pi(1-\\pi)}\\] ### 1.2.2 Multinomial Distribution {#x1.2.2} 1.3 Statistical Inference for a Proportion 1.3.1 Likelihood Function and Maximum Likelihood Estimation 1.3.2 Significance Test about a Binomial Parameter \\[E(\\hat{\\pi})=\\pi,\\ \\sigma(\\hat{\\pi}) = \\sqrt{\\frac{\\pi(1-\\pi)}{n}}\\] \\[z = \\frac{\\hat{\\pi}-\\pi_0}{SE_0} = \\frac{\\hat{\\pi}-\\pi_0}{ \\sqrt{\\frac{\\pi_0(1-\\pi_0)}{n}}}\\] 1.3.3 Example: Surveyed Opinions About Legalized Abortion round(837/1810, 4) [1] 0.4624 \\[z = \\frac{\\hat{\\pi}-\\pi_0}{ \\sqrt{\\frac{\\pi_0(1-\\pi_0)}{n}}} == \\frac{.4624-.5}{ \\sqrt{\\frac{0.50(0.50)}{1810}}} = -3.2\\] z &lt;- round((.4624-.5)/sqrt(0.50*0.50/1810), 2) round(2 * pnorm(z, lower.tail=TRUE), 4) [1] 0.0014 1.3.4 Confidence Intervals for a Binomial Parameter Estimated standard error of \\(\\hat{\\pi}\\) equals \\(SE = \\sqrt{\\hat{\\pi}(1-\\hat{\\pi})/n}\\) \\[\\hat{\\pi}\\pm z_{\\alpha/2}(SE),\\ SE = \\sqrt{\\hat{\\pi}(1-\\hat{\\pi})/n}\\ \\ \\ \\ \\ \\ \\ \\ \\ (1.3)\\] 1.3.5 Better Confidence Intervals for a Binomial Proportion \\[\\frac{| \\hat{\\pi}-\\pi_0|}{ \\sqrt{\\pi_0(1-\\pi_0)/n}} = 1.96\\] for \\(\\pi_0\\) 1.4 Statistical Inference for Discrete Data 1.4.1 Wald, Likelihood-Ratio, and Score Tests \\[z = (\\hat{\\beta}-\\beta)/SE\\] The two-tailed standard normal probability of 0.05 that falls below -1.96 and above 1.96 equals the right-tail chi-squared probability above \\((1.96)^2 = 3.84\\) when df = 1. 2 * pnorm(-1.96) # 2 * standard normal cumulative prob below -1.96 [1] 0.04999579 pchisq(1.96^2, 1) # chi-square cumulative probability [1] 0.9500042 1 - pchisq(1.96^2, 1) # right tailed prob above 1.96 * 1.96 when df = 1 [1] 0.04999579 pchisq(1.96^2, 1, lower.tail = FALSE) # same [1] 0.04999579 \\[2\\ \\mathrm{log}(\\ell_1 / \\ell_0) = \\mathrm{oberved/null}\\] 1.4.2 Example Wald, Score and Likelihood-Ratio Binomial Tests \\[z = (\\hat{\\pi} - \\pi_0)/SE_0 = (0.90 - 0.50)/0.158 = 2.53\\] \\[\\ell(\\pi) = \\frac{10!}{9!1!}\\pi^9(1-\\pi)^1 = 10\\pi^9(1-\\pi)\\] \\[2 log(\\ell_1/\\ell_0)= 2\\ log (0.3874/0.00977) = 7.36.\\] 1.4.3 Small-Sample Binomial Inference and the Mid P-Value 1.5 Bayesian Inference for Proportions 1.5.1 The Bayesian Approach to Statistical Inference \\[ \\ \\ \\ \\ \\ \\ \\\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ell(\\beta)\\ \\ \\ prior \\\\\\ g(\\beta|y) \\mathrm{\\ is\\ proportional\\ to}\\ p(y|\\beta)f(\\beta) \\] 1.5.2 Bayesian Binomial Inference: Beta Prior Distributions \\[ f(\\pi) \\propto \\pi^{\\alpha -1}(1-\\pi)^{(\\beta-1)},\\ 0 \\le \\pi \\le 1 \\] 1.5.3 Example: Opinions about Legalized Abortion, Revisited 1.5.4 Other Prior Distributions 1.6 Using R software for Statistical Inference about Proportions 1.6.1 Reading Data Files and Installing Packages Clinical &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Clinical.dat&quot;, header = TRUE) Clinical subject response 1 1 1 2 2 1 3 3 1 4 4 1 5 5 1 6 6 1 7 7 1 8 8 1 9 9 1 10 10 0 1.6.2 Using R for Statistical Inference about Proportions library(binom) prop.test(837, 1810, p = 0.50, alternative = &quot;two.sided&quot;, correct = FALSE) 1-sample proportions test without continuity correction data: 837 out of 1810, null probability 0.5 X-squared = 10.219, df = 1, p-value = 0.00139 alternative hypothesis: true p is not equal to 0.5 95 percent confidence interval: 0.4395653 0.4854557 sample estimates: p 0.4624309 prop.test(837, 1810, p = 0.50, alternative = &quot;less&quot;, correct = FALSE) 1-sample proportions test without continuity correction data: 837 out of 1810, null probability 0.5 X-squared = 10.219, df = 1, p-value = 0.0006951 alternative hypothesis: true p is less than 0.5 95 percent confidence interval: 0.0000000 0.4817492 sample estimates: p 0.4624309 prop.test(sum(Clinical$response), n = 10, conf.level = 0.95, correct = FALSE) 1-sample proportions test without continuity correction data: sum(Clinical$response) out of 10, null probability 0.5 X-squared = 6.4, df = 1, p-value = 0.01141 alternative hypothesis: true p is not equal to 0.5 95 percent confidence interval: 0.5958500 0.9821238 sample estimates: p 0.9 with(Clinical, prop.test(sum(response), n = 10, conf.level = 0.95, correct = FALSE)) 1-sample proportions test without continuity correction data: sum(response) out of 10, null probability 0.5 X-squared = 6.4, df = 1, p-value = 0.01141 alternative hypothesis: true p is not equal to 0.5 95 percent confidence interval: 0.5958500 0.9821238 sample estimates: p 0.9 binom.confint(9, 10, conf.level = 0.95, method = c(&quot;asymptotic&quot;, &quot;wilson&quot;,&quot;agresti-coull&quot;)) method x n mean lower upper 1 agresti-coull 9 10 0.9 0.5740323 1.0039415 2 asymptotic 9 10 0.9 0.7140615 1.0859385 3 wilson 9 10 0.9 0.5958500 0.9821238 binom.test(9, 10, 0.5, alternative = &quot;two.sided&quot;) Exact binomial test data: 9 and 10 number of successes = 9, number of trials = 10, p-value = 0.02148 alternative hypothesis: true probability of success is not equal to 0.5 95 percent confidence interval: 0.5549839 0.9974714 sample estimates: probability of success 0.9 binom.test(9, 10, 0.5, alternative = &quot;greater&quot;) Exact binomial test data: 9 and 10 number of successes = 9, number of trials = 10, p-value = 0.01074 alternative hypothesis: true probability of success is greater than 0.5 95 percent confidence interval: 0.6058367 1.0000000 sample estimates: probability of success 0.9 library(exactci) exactci::binom.exact(9, 10, 0.50, alternative = &quot;greater&quot;, midp = TRUE) Exact one-sided binomial test, mid-p version data: 9 and 10 number of successes = 9, number of trials = 10, p-value = 0.005859 alternative hypothesis: true probability of success is greater than 0.5 95 percent confidence interval: 0.6504873 1.0000000 sample estimates: probability of success 0.9 library(PropCIs) midPci(9, 10, 0.95) data: 95 percent confidence interval: 0.5966 0.9946 qbeta(c(0.025, 0.975), 837.5, 973.5) [1] 0.4395369 0.4854450 pbeta(0.50, 837.5, 973.5) [1] 0.9993082 1 - pbeta(0.50, 837.5, 973.5) [1] 0.0006918185 1.6.3 Summary: Choosing an Inference Method Exercises "],["Contingency.html", "2 Analyzing Contingency Tables 2.1 Probability Structure for Contingency Tables 2.2 Comparing Proportions in 2 x 2 Contingency Tables 2.3 The Odds Ratio 2.4 Chi-Squared Tests of Independence 2.5 Testing Independence for Ordinal Variables 2.6 Exact Frequentist and Bayesian Inference 2.7 Association in Three-Way Tables Exercises", " 2 Analyzing Contingency Tables table2_1 &lt;- data.frame(Gender = c(&quot;Female&quot;, &quot;Female&quot;, &quot;Male&quot;, &quot;Male&quot;), Belief = c(&quot; Yes&quot;, &quot;No&quot;, &quot; Yes&quot;, &quot;No&quot;), Count = c(1230, 357, 859, 413)) addmargins(xtabs(Count ~ Gender + Belief, table2_1)) Belief Gender Yes No Sum Female 1230 357 1587 Male 859 413 1272 Sum 2089 770 2859 2.1 Probability Structure for Contingency Tables 2.1.1 Joint, Marginal, and Conditional Probabilities \\[ \\hat{\\pi}_{ij} = n_{ij}/n \\] Sex Yes No or undecided Females \\(\\pi11\\) \\(\\pi12\\) \\(\\pi1+\\) Males \\(\\pi21\\) \\(\\pi22\\) \\(\\pi2+\\) \\(\\pi{{+}}1\\) \\(\\pi{{+}}2\\) \\[ \\pi_{1+} = \\pi_{11} + \\pi_{12}\\ \\ \\mathrm{and}\\ \\ \\pi_{+1} = \\pi_{11} + \\pi_{21} \\] ### 2.1.2 Example: Sensitivity and Specificity \\[ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ prediction\\ |\\ truth \\\\ \\mathrm{Sensitivity} = P(Y=1\\ |\\ X = 1), \\\\ \\mathrm{Sepecificity} = P(Y=2\\ |\\ X = 2) \\] ### 2.1.3 Statistical Independence of Two Categorical Variables \\[ P(X = i, Y = j) = P(X = i) P(Y = j)\\ \\mathrm{for}\\ i = 1, ..., r\\ \\mathrm{and}\\ j = 1,..., c. \\] 2.1.4 Binomial and Multinomial Sampling 2.2 Comparing Proportions in 2 x 2 Contingency Tables 2.2.1 Difference of Proportions \\[ SE = \\sqrt{\\frac{\\hat{\\pi}_1 - (1 - \\hat{\\pi}_1)}{n_1} + \\frac{\\hat{\\pi}_2 - (1 - \\hat{\\pi}_2)}{n_2}} \\] \\[ (\\hat{\\pi}_1 - \\hat{\\pi}_2) \\pm z_{\\alpha/2}(SE) \\] 2.2.2 Example: Aspirin and incidence of Heart Attacks table2_2 &lt;- tibble(Group = c(&quot;Placebo&quot;, &quot;Placebo&quot;, &quot;Aspirin&quot;, &quot;Aspirin&quot;), `Myocardial Infarction` = c(&quot; Yes&quot;, &quot;No&quot;, &quot; Yes&quot;, &quot;No&quot;), Count = c(189, 10845, 104, 10933)) addmargins(xtabs(Count ~ Group + `Myocardial Infarction`, table2_2)) Myocardial Infarction Group Yes No Sum Aspirin 104 10933 11037 Placebo 189 10845 11034 Sum 293 21778 22071 \\[ SE = \\sqrt{\\frac{(0.0171) (0.9829)}{11,034} + \\frac{(0.0094) - (0.9906)}{11,0037}} = 0.0015 \\] 2.2.3 Ratio of Proportions (Relative Risk) \\[\\mathrm{Relative\\ risk} = \\frac{\\pi_1}{\\pi_2}\\] 2.2.4 Using R for Comparing Proportions in 2 x 2 Tables prop.test(c(189, 104), c(11034, 11037), correct = FALSE) 2-sample test for equality of proportions without continuity correction data: c(189, 104) out of c(11034, 11037) X-squared = 25.014, df = 1, p-value = 5.692e-07 alternative hypothesis: two.sided 95 percent confidence interval: 0.004687751 0.010724297 sample estimates: prop 1 prop 2 0.01712887 0.00942285 options(digits = 5) library(PropCIs) diffscoreci(189, 11034, 104, 11037, conf.level = 0.95) data: 95 percent confidence interval: 0.0047168 0.0107885 riskscoreci(189, 11034, 104, 11037, conf.level = 0.95) data: 95 percent confidence interval: 1.4339 2.3047 options(digits = 7) 2.3 The Odds Ratio \\[\\mathrm{odds} = \\pi/(1-\\pi).\\] \\[\\pi = \\mathrm{odds/(odds+1)}.\\] \\[\\theta =\\frac{\\mathrm{odds_1}}{\\mathrm{odds_2}} = \\frac{ \\pi_1/(1-\\pi_1)}{\\pi_2/(1-\\pi_2)},\\] 2.3.1 Properties of the Odds Ratio \\[\\theta=\\frac{\\pi_{11}/\\pi_{12}}{\\pi_{21}/\\pi_{22}} = \\frac{\\pi_{11}\\pi_{22}}{\\pi_{12}\\pi_{21}}.\\] \\[\\hat{\\theta}=\\frac{\\hat{\\pi}_1/(1-\\hat{\\pi}_1)}{\\hat{\\pi}_2/(1-\\hat{\\pi}_2)}=\\frac{n_{11}/n_{12}}{n_{21}/n_{22}} = \\frac{n_{11}n_{22}}{n_{12}n_{21}}.\\] 2.3.2 Example: Odds Ratio for Aspirin and Hart Attacks 2.3.3 Inference for Odds Ratios and Log Odds Ratios \\[SE = \\sqrt{\\frac{1}{n_{11}}+ \\frac{1}{n_{12}}+ \\frac{1}{n_{21}}+\\frac{1}{n_{22}}}.\\] \\[log\\ \\hat{\\theta} \\pm z_{\\alpha/2}(SE).\\] \\[SE = \\sqrt{\\frac{1}{189}+ \\frac{1}{10,933}+ \\frac{1}{104}+\\frac{1}{10,845}} = 0.123\\] \\[(\\mathrm{exp}(0.365),\\ \\mathrm{exp}(0.846)) = (e^{0.365},\\ e^{0.846}) = (1.44, 2.33).\\] library(epitools) epitools::oddsratio(c(189, 10845, 104, 10933), method = &quot;wald&quot;) $data Outcome Predictor Disease1 Disease2 Total Exposed1 189 10845 11034 Exposed2 104 10933 11037 Total 293 21778 22071 $measure odds ratio with 95% C.I. Predictor estimate lower upper Exposed1 1.000000 NA NA Exposed2 1.832054 1.440042 2.33078 $p.value two-sided Predictor midp.exact fisher.exact chi.square Exposed1 NA NA NA Exposed2 4.989646e-07 5.032836e-07 5.691897e-07 $correction [1] FALSE attr(,&quot;method&quot;) [1] &quot;Unconditional MLE &amp; normal approximation (Wald) CI&quot; library(PropCIs) # Score CI for odds ratio orscoreci(189, 11034, 104, 11037, conf.level = 0.95) data: 95 percent confidence interval: 1.440802 2.329551 2.3.4 Relationship Between Odds Ratio and Relative Risk \\[\\mathrm{Odds\\ ratio} = \\frac{\\hat{\\pi}_1 / (1- \\hat{\\pi}_1)}{\\hat{\\pi}_2 / (1- \\hat{\\pi}_2)} = \\mathrm{Relative\\ risk} \\times \\left(\\frac{1- \\hat{\\pi}_1}{1- \\hat{\\pi}_2} \\right).\\] 2.3.5 Example: The Odds Ratio Applies in Case-Control Studies table2_3 &lt;- data.frame(Smoker = c(&quot; Yes&quot;, &quot; Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Total&quot;, &quot;Total&quot;), Belief = c(rep(c(&quot;Cases&quot;,&quot;Controls&quot;),3)), Count = c(688, 650, 21, 59, 709, 709)) xtabs(Count ~ Smoker + Belief, table2_3) Belief Smoker Cases Controls Yes 688 650 No 21 59 Total 709 709 \\[\\frac{(688/709)/(21/709)}{(650/709)/(59/709)} = \\frac{688 \\times 59}{650 \\times 21} = 3.0.\\] 2.3.6 Types of Studies Observational Versus Experimental 2.4 Chi-Squared Tests of Independence 2.4.1 Pearson Statistic and the Chi-Squared Distribution \\[\\begin{equation} \\chi^2= \\sum\\frac{(n_{ij}-\\mu_{ij})^2}{\\mu_{ij}}. \\tag{2} \\end{equation}\\] library(ggplot2) library(ggthemes) library(RColorBrewer) colors &lt;- brewer.pal(n = 4, name = &quot;Dark2&quot;) ggplot(data.frame(x = c(0, 40)), aes(x = x)) + stat_function(fun = dchisq, args = list(df = 1), color = colors[1]) + annotate(geom = &quot;segment&quot;, x = 11, y = .11, xend = 2.2, yend = .11, arrow = arrow(length = unit(2, &quot;mm&quot;)), color = colors[1]) + annotate(geom = &quot;text&quot;, x = 11.75, y = .11, label = &quot;df = 1&quot;, hjust = &quot;left&quot;, color = colors[1]) + stat_function(fun = dchisq, args = list(df = 5), color = colors[2]) + annotate(geom = &quot;segment&quot;, x = 11, y = .13, xend = 5, yend = .13, arrow = arrow(length = unit(2, &quot;mm&quot;)), color = colors[2]) + annotate(geom = &quot;text&quot;, x = 11.75, y = .13, label = &quot;df = 5&quot;, hjust = &quot;left&quot;, color = colors[2]) + stat_function(fun = dchisq, args = list(df = 10), color = colors[3]) + annotate(geom = &quot;segment&quot;, x = 15, y = .08, xend = 11, yend = .08, arrow = arrow(length = unit(2, &quot;mm&quot;)), color = colors[3]) + annotate(geom = &quot;text&quot;, x = 15.75, y = .08, label = &quot;df = 10&quot;, hjust = &quot;left&quot;, color = colors[3]) + stat_function(fun = dchisq, args = list(df = 20), color = colors[4]) + annotate(geom = &quot;segment&quot;, x = 25, y = .055, xend = 22.5, yend = .055, arrow = arrow(length = unit(2, &quot;mm&quot;)), color = colors[4]) + annotate(geom = &quot;text&quot;, x = 25.75, y = .055, label = &quot;df = 20&quot;, hjust = &quot;left&quot;, color = colors[4]) + ylim(c(0, 0.2)) + xlab(&quot;Chi-Squared&quot;) + ylab(&quot;Probability Denstiy&quot;) + theme_few() 2.4.2 likelihood-Ratio Statistic \\[G^2 = 2\\sum n_{ij}\\ log \\left(\\frac{n_{ij}}{\\mu_{ij}}\\right).\\] 2.4.3 Testing Independence in Two-Way Contingency Tables \\[H_0: \\pi_{ij} = \\pi_{i+} \\pi_{+j}\\ \\mathrm{for\\ all}\\ i\\ \\mathrm{and}\\ j.\\] \\[\\hat\\mu_{ij}= n\\hat\\pi_{i+}\\hat\\pi_{+j}= n \\left(\\frac{n_{i+}}{n}\\right) \\left(\\frac{n_{+j}}{n}\\right) = \\frac{n_{i+}n_{+j}}{n}\\] \\[df=(rc-1)-[(r-1) + (c-1)] = rc -r -c +1 = (r-1)(c-1)\\] 2.4.4 Example: Gender Gap in Political Party Affiliation Political &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Political.dat&quot;, header = TRUE) Political &lt;- Political %&gt;% mutate(Party = factor(party, levels = c(&quot;Dem&quot;, &quot;Rep&quot;, &quot;Ind&quot;))) library(gmodels) CrossTable(Political$gender, Political$Party, expected = TRUE, prop.c = FALSE, prop.r = FALSE, prop.t = FALSE, prop.chisq=FALSE) Cell Contents |-------------------------| | N | | Expected N | |-------------------------| Total Observations in Table: 2450 | Political$Party Political$gender | Dem | Rep | Ind | Row Total | -----------------|-----------|-----------|-----------|-----------| female | 495 | 272 | 590 | 1357 | | 456.949 | 297.432 | 602.619 | | -----------------|-----------|-----------|-----------|-----------| male | 330 | 265 | 498 | 1093 | | 368.051 | 239.568 | 485.381 | | -----------------|-----------|-----------|-----------|-----------| Column Total | 825 | 537 | 1088 | 2450 | -----------------|-----------|-----------|-----------|-----------| Statistics for All Table Factors Pearson&#39;s Chi-squared test ------------------------------------------------------------ Chi^2 = 12.56926 d.f. = 2 p = 0.00186475 2.4.5 Residuals for Cells in a Contingency Table \\[\\frac{n_{ij} - \\hat\\mu_{ij}} {\\sqrt{\\hat\\mu_{ij}(1-\\hat\\pi_{i+})(1-\\hat\\pi_{+j})}} = \\frac{n(\\hat\\pi_{ij} - {\\hat\\pi_{i+}\\hat\\pi_{+j})}} {\\sqrt{n\\hat\\pi_{i+}\\hat\\pi_{+j}(1-\\hat\\pi_{i+})(1-\\hat\\pi_{+j})}}\\] Political &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Political.dat&quot;, header = TRUE) # Political &lt;- Political %&gt;% # mutate(party = factor(party, levels = c(&quot;Dem&quot;, &quot;Rep&quot;, &quot;Ind&quot;))) %&gt;% # filter(party != &quot;Ind&quot;) library(gmodels) CrossTable(Political$gender, Political$party, prop.r=FALSE, prop.c=FALSE, prop.t=FALSE, prop.chisq=FALSE, sresid=TRUE, asresid=TRUE) Cell Contents |-------------------------| | N | |-------------------------| Total Observations in Table: 2450 | Political$party Political$gender | Dem | Ind | Rep | Row Total | -----------------|-----------|-----------|-----------|-----------| female | 495 | 590 | 272 | 1357 | -----------------|-----------|-----------|-----------|-----------| male | 330 | 498 | 265 | 1093 | -----------------|-----------|-----------|-----------|-----------| Column Total | 825 | 1088 | 537 | 2450 | -----------------|-----------|-----------|-----------|-----------| Political %&gt;% filter(row_number() %in% c(1, 2, n())) person gender party 1 1 female Dem 2 2 female Dem 3 2450 male Ind GenderGap &lt;- xtabs(~gender + party, data = Political) chisq.test(GenderGap) Pearson&#39;s Chi-squared test data: GenderGap X-squared = 12.569, df = 2, p-value = 0.001865 stdres &lt;- chisq.test(GenderGap)$stdres stdres party gender Dem Ind Rep female 3.272365 -1.032199 -2.498557 male -3.272365 1.032199 2.498557 library(vcd) Loading required package: grid conflict_prefer(&quot;oddsratio&quot;, &quot;vcd&quot;) [conflicted] Will prefer vcd::oddsratio over any other package mosaic(GenderGap, gp=shading_Friendly, residuals = stdres, residuals_type=&quot;Std\\nresiduals&quot;, labeling = labeling_residuals()) 2.4.6 Partitioning Chi-Squared Statistics 2.4.7 Limitations of Chi-Squared Tests 2.5 Testing Independence for Ordinal Variables 2.5.1 Linear Trend Alternative to Independence \\[R = \\frac{\\sum_{i,j}(u_i-\\bar{u})(v_j-\\bar{v})\\hat\\pi_{ij}} {\\sqrt{\\left[\\sum_i(u_i-\\bar{u})^2 \\hat\\pi_{i+}\\right]{\\left[\\sum_j(v_i-\\bar{v})^2 \\hat\\pi_{+j}\\right]}}} \\] \\[M^2 = (n-1)R^2\\] 2.5.2 Example: Alcohol Use and Infant Malformation Malform &lt;- matrix(c(17066, 14464, 788, 126, 37, 48, 38, 5, 1, 1), ncol = 2) `Table 2.6` &lt;- bind_cols(Alcohol = c(&quot;0&quot;, &quot;&lt;1&quot;, &quot;1-2&quot;, &quot;3-5&quot;, &quot;&gt;5&quot;), as.data.frame(Malform)) %&gt;% rename(&quot;Abscent&quot; = V1, &quot;Present&quot; = V2) %&gt;% mutate(Total = Abscent + Present) %&gt;% mutate(Percent = round(Present / Total * 100, 2)) `Table 2.6` Alcohol Abscent Present Total Percent 1 0 17066 48 17114 0.28 2 &lt;1 14464 38 14502 0.26 3 1-2 788 5 793 0.63 4 3-5 126 1 127 0.79 5 &gt;5 37 1 38 2.63 Malform &lt;- matrix(c(17066, 14464, 788, 126, 37, 48, 38, 5, 1, 1), ncol = 2) Malform [,1] [,2] [1,] 17066 48 [2,] 14464 38 [3,] 788 5 [4,] 126 1 [5,] 37 1 library(vcdExtra) Loading required package: gnm CMHtest(Malform, rscores = c(0, .5, 1.5, 4, 7), overall = TRUE) Cochran-Mantel-Haenszel Statistics AltHypothesis Chisq Df Prob cor Nonzero correlation 6.5699 1 0.010372 rmeans Row mean scores differ 12.0817 4 0.016754 cmeans Col mean scores differ 6.5699 1 0.010372 general General association 12.0817 4 0.016754 sqrt(6.5699) [1] 2.563182 1 - pnorm(sqrt(6.5699)) [1] 0.005185889 2.5.3 Ordinal Tests Usually Have Greater Power 2.5.4 Choice of Scores 2.5.6 Trend Tests for r x 2 and 2 x c and Nominal-Ordinal Tables 2.6 Exact Frequentist and Bayesian Inference 2.6.1 Fisher’s Exact Test for 2 x 2 Tables 2.6.2 Example: Fisher’s Tea Tasting Colleague tea &lt;- matrix(c(3,1,1,3), ncol = 2) fisher.test(tea) Fisher&#39;s Exact Test for Count Data data: tea p-value = 0.4857 alternative hypothesis: true odds ratio is not equal to 1 95 percent confidence interval: 0.2117329 621.9337505 sample estimates: odds ratio 6.408309 fisher.test(tea, alternative = &quot;greater&quot;) Fisher&#39;s Exact Test for Count Data data: tea p-value = 0.2429 alternative hypothesis: true odds ratio is greater than 1 95 percent confidence interval: 0.3135693 Inf sample estimates: odds ratio 6.408309 2.6.3 Conservatism for Actual P(Type I Error); Mid P-Value library(epitools) ormidp.test(3,1,1,3, or = 1) one.sided two.sided 1 0.1285714 0.2571429 2.6.4 Small-Sample Confidence Intervals for Odds Ratio library(epitools) or.midp(c(3,1,1,3), conf.level = 0.95)$conf.int [1] 0.3100508 306.6338538 2.6.5 Bayesian Estimation for Association Measures 2.6.6 Example: Bayesian Inference in a Small Clinical Trial library(PropCIs) orci.bayes(11, 11, 0, 1, 0.5, 0.5, 0.5, 0.5, 0.95, nsim = 1000000) [1] 3.276438e+00 1.361274e+06 diffci.bayes(11, 11, 0, 1, 0.5, 0.5, 0.5, 0.5, 0.95, nsim = 1000000) [1] 0.09899729 0.99327276 pi1 &lt;- rbeta(100000000, 11.5, 0.5) pi2 &lt;- rbeta(100000000, 0.5, 1.5) options(scipen=99) # default was 0 or &lt;- pi1*(1-pi2)/((1-pi1) * pi2) quantile(or, c(0.025, 0.975)) quantile(pi1 - pi2, c(0.025, 0.975)) mean(pi1 &lt; pi2) 2.7 Association in Three-Way Tables 2.7.1 Partial Tables 2.7.2 Example: Death Penalty Verdicts and Race death &lt;- matrix(c(53, 414, 11.3, 11, 37, 22.9, 0, 16, 0, 4, 139, 2.8, 53, 430, 11, 15, 176, 7.9), ncol = 3, byrow = TRUE) `Table 2.9` &lt;- bind_cols(`Victims&#39; Race` = c(&quot;White&quot;, &quot;&quot;, &quot;Black&quot;, &quot;&quot;, &quot;Total&quot;, &quot;&quot;), `Defendants&#39; Race` = rep(c(&quot;White&quot;, &quot;Black&quot;),3), as.data.frame(death)) %&gt;% mutate(Total = V1 + V2) %&gt;% rename(&quot;Got Death Penalty&quot; = V1, &quot;Not Death Penalty&quot; = V2, &quot;Percent Yes&quot; = V3) `Table 2.9` Victims&#39; Race Defendants&#39; Race Got Death Penalty Not Death Penalty 1 White White 53 414 2 Black 11 37 3 Black White 0 16 4 Black 4 139 5 Total White 53 430 6 Black 15 176 Percent Yes Total 1 11.3 467 2 22.9 48 3 0.0 16 4 2.8 143 5 11.0 483 6 7.9 191 # race association victim and defendant OR round((467 * 143 )/(48 * 16), 0) [1] 87 # victim race by death penalty - whites 53 + 11 [1] 64 414 + 37 [1] 451 # victim race by death penalty - blacks 0 + 4 [1] 4 16 + 139 [1] 155 # odds DP for white victim (53 + 11) / (414 + 37) [1] 0.1419069 # odds DP for black victim (4 / (16 + 139)) [1] 0.02580645 # OR of DP for white victim relative to black ((53 + 11) / (414 + 37)) / (4 / (16 + 139)) [1] 5.498891 2.7.3 Simpson’s Paradox 2.7.4 Conditional and Marginal Odds Ratios 2.7.5 Homogeneous Association \\[\\theta_{XY(1)} = \\theta_{XY(2)} = ...,\\] Exercises "],["Generalized.html", "3 Generalized Linear Models 3.1 Components of a Generalized Linear Model 3.2 Components of a Generalized Linear Model 3.3 Generalized Linear Models for Binary Data 3.4 Generalized Lineaer Models for Counts and Rates 3.5 Fitting Generalized Linear Models", " 3 Generalized Linear Models 3.1 Components of a Generalized Linear Model 3.1.1 Random Component 3.1.2 Linear Predictor \\[\\alpha + \\beta_1x_1+ ... + \\beta_px_p.\\] 3.1.3 Link Function \\[g(\\mu)=\\alpha + \\beta_1x_1+ ... + \\beta_px_p.\\] \\[\\mu=\\alpha + \\beta_1x_1+ ... + \\beta_px_p.\\] \\[log(\\mu)=\\alpha + \\beta_1x_1+ ... + \\beta_px_p.\\] 3.1.4 Ordinary Linear Model: GLM with Normal Random Component 3.2 Components of a Generalized Linear Model 3.2.1 Linear Probability Model \\[ P(Y=1) = \\alpha + \\beta_1x_1 + ... + \\beta_px_p.\\] 3.2.2 Logistic Regression Model \\[\\begin{equation} P(Y=1) = \\frac{exp(\\alpha + \\beta x)}{exp(1+\\alpha + \\beta x}=\\frac{e^{\\alpha + \\beta x}}{1 + e^{\\alpha + \\beta x}}, \\tag{3} \\end{equation}\\] \\[\\mathrm{log}\\left[\\frac{P(Y=1)}{1-P(Y=1)}\\right] = \\alpha + \\beta_1x_1 + ... + \\beta_px_p.\\] 3.2.3 Example Snoring and Heart Disease snore &lt;- matrix(c(24, 1355, 35, 603, 21, 192, 30, 224), ncol = 2, byrow = TRUE) `Table 3.1` &lt;- bind_cols(Snoring = c(&quot;Never&quot;, &quot;Occasionaly&quot;, &quot;Nearly every night&quot;, &quot;Every night&quot;), as.data.frame(snore)) %&gt;% rename(&quot;Yes&quot; = V1, &quot;No&quot; = V2) %&gt;% mutate(Proportion = round(Yes / (Yes + No), 3)) %&gt;% bind_cols(`Linear Fit` = c(0.017, 0.057,0.096,0.116), `Logistic Fit` = c(0.021, 0.044,0.093,0.132)) knitr::kable(`Table 3.1`) Snoring Yes No Proportion Linear Fit Logistic Fit Never 24 1355 0.017 0.017 0.021 Occasionaly 35 603 0.055 0.057 0.044 Nearly every night 21 192 0.099 0.096 0.093 Every night 30 224 0.118 0.116 0.132 3.2.4 Using R to Fit Generalized Lineare Models for Binary Data Heart &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Heart.dat&quot;, header = TRUE, stringsAsFactors = FALSE) knitr::kable(Heart) snoring yes no never 24 1355 occasional 35 603 nearly_every_night 21 192 every_night 30 224 library(tidyverse) Heart &lt;- Heart %&gt;% mutate(snoringNights = recode(snoring, never = 0, occasional = 2, nearly_every_night = 4, every_night = 5)) n &lt;- Heart$yes + Heart$no fit &lt;- glm(yes/n ~ snoringNights, family = binomial(link = logit), weights = n, data = Heart) summary(fit) Call: glm(formula = yes/n ~ snoringNights, family = binomial(link = logit), data = Heart, weights = n) Deviance Residuals: 1 2 3 4 -0.8346 1.2521 0.2758 -0.6845 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -3.86625 0.16621 -23.261 &lt; 2e-16 *** snoringNights 0.39734 0.05001 7.945 1.94e-15 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 65.9045 on 3 degrees of freedom Residual deviance: 2.8089 on 2 degrees of freedom AIC: 27.061 Number of Fisher Scoring iterations: 4 fitted(fit) 1 2 3 4 0.02050742 0.04429511 0.09305411 0.13243885 fit2 &lt;- glm(yes/n ~ snoringNights, family = quasi(link = identity, variance = &quot;mu(1-mu)&quot;), weights = n, data = Heart) summary(fit2) Call: glm(formula = yes/n ~ snoringNights, family = quasi(link = identity, variance = &quot;mu(1-mu)&quot;), data = Heart, weights = n) Deviance Residuals: 1 2 3 4 0.04478 -0.21322 0.11010 0.09798 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 0.0172467 0.0006402 26.94 0.001375 ** snoringNights 0.0197778 0.0005204 38.01 0.000692 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for quasi family taken to be 0.03441852) Null deviance: 65.904481 on 3 degrees of freedom Residual deviance: 0.069191 on 2 degrees of freedom AIC: NA Number of Fisher Scoring iterations: 3 3.2.5 Data Files: Ungrouped or Grouped Binary Data Heart2 &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Heart2.dat&quot;, header = TRUE, stringsAsFactors = FALSE) %&gt;% mutate(snoringNights = recode(snoring, never = 0, occas = 2, nearly = 4, every = 5)) Heart2 %&gt;% filter(row_number() %in% c(1, 2, n())) subject snoring x y snoringNights 1 1 never 0 1 0 2 2 never 0 1 0 3 2484 every 5 0 5 fit &lt;- glm(y ~ snoringNights, family = binomial(link = logit), data = Heart2) summary(fit) Call: glm(formula = y ~ snoringNights, family = binomial(link = logit), data = Heart2) Deviance Residuals: Min 1Q Median 3Q Max -0.5331 -0.3010 -0.2036 -0.2036 2.7882 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -3.86625 0.16621 -23.261 &lt; 2e-16 *** snoringNights 0.39734 0.05001 7.945 1.94e-15 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 900.83 on 2483 degrees of freedom Residual deviance: 837.73 on 2482 degrees of freedom AIC: 841.73 Number of Fisher Scoring iterations: 6 3.3 Generalized Linear Models for Binary Data 3.3.1 Poisson Distribution for Counts \\[E(Y) = \\mathrm{var}(Y)= \\mu,\\ \\ \\ \\sigma(Y)=\\sqrt{\\mu}.\\] 3.3.2 Poisson Loglinear Model \\[\\mathrm{log}\\ \\mu = \\alpha + \\beta x.\\] \\[\\begin{equation} \\mu = \\mathrm{exp}(\\alpha+\\beta x) = e^\\alpha(e^\\beta)^x. \\tag{4} \\end{equation}\\] 3.3.3 Example: Female Horseshoe Crabs and their Satellites Crabs &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Crabs.dat&quot;, header = TRUE, stringsAsFactors = FALSE) %&gt;% tibble() %&gt;% select(color, spine, width, weight, sat) Crabs %&gt;% rename(&quot;C&quot; = color, &quot;S&quot;=spine, &quot;Wi&quot;=width, &quot;Wt&quot;=weight, &quot;Sa&quot;=sat) %&gt;% slice_head(n=6) %&gt;% knitr::kable() C S Wi Wt Sa 2 3 28.3 3.05 8 3 3 22.5 1.55 0 1 1 26.0 2.30 9 3 3 24.8 2.10 0 3 3 26.0 2.60 4 2 3 23.8 2.10 0 fit &lt;- glm(sat ~ width, family = poisson(link=log), data = Crabs) summary(fit) Call: glm(formula = sat ~ width, family = poisson(link = log), data = Crabs) Deviance Residuals: Min 1Q Median 3Q Max -2.8526 -1.9884 -0.4933 1.0970 4.9221 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -3.30476 0.54224 -6.095 1.1e-09 *** width 0.16405 0.01997 8.216 &lt; 2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for poisson family taken to be 1) Null deviance: 632.79 on 172 degrees of freedom Residual deviance: 567.88 on 171 degrees of freedom AIC: 927.18 Number of Fisher Scoring iterations: 6 suppressPackageStartupMessages(library(gam)) suppressWarnings( gam.fit &lt;- gam(sat ~ s(width), family = poisson, data = Crabs) ) plot(sat ~ width, xlab = &quot;Width&quot;, ylab = &quot;Number of satelites&quot;, data = Crabs) curve(predict(gam.fit, data.frame(width = x), type = &quot;resp&quot;), add = TRUE) Crabs$gamPrediction &lt;- predict(gam.fit, type = &quot;resp&quot;) # https://stackoverflow.com/questions/2631780/r-ggplot2-can-i-set-the-plot-title-to-wrap-around-and-shrink-the-text-to-fit-t wrapper &lt;- function(x, ...) {paste(strwrap(x, ...), collapse = &quot;\\n&quot;)} library(ggthemes) Crabs %&gt;% ggplot(aes(x = width, y = sat)) + geom_point(shape = 1, size = 3) + geom_line(aes(y=gamPrediction)) + xlim(c(20, 35))+ theme_few() + xlab(&quot;Width&quot;) + ylab(&quot;Number of satelites&quot;) + ggtitle(wrapper(&quot;Figure 3.3. Number of satellites by female crab shell width (in centimeters), and generalized additive model smoothing fit.&quot;, 70)) \\[\\hat\\mu =\\mathrm{exp}(\\hat\\alpha + \\hat\\beta x)= \\mathrm{exp}[-3.305 + 0.164(26.3)]=2.74.\\] identityGLM &lt;- glm(sat ~ width, family = poisson(link=&quot;identity&quot;), start=c(0.5,0.5), data = Crabs) logitGLM &lt;- glm(sat ~ width, family = poisson(link=&quot;log&quot;), data = Crabs) Crabs2 &lt;- bind_cols(Crabs, &quot;identity&quot; = fitted(identityGLM), &quot;logit&quot; = fitted(logitGLM)) library(RColorBrewer) colors &lt;- brewer.pal(n = 4, name = &quot;Dark2&quot;) CrabBin &lt;- Crabs2 %&gt;% mutate(bin = case_when(width &lt;= 23.25 ~ 23, width &gt; 23.25 &amp; width &lt;= 24.25 ~ 24, width &gt; 24.25 &amp; width &lt;= 25.25 ~ 25, width &gt; 25.25 &amp; width &lt;= 26.25 ~ 26, width &gt; 26.25 &amp; width &lt;= 27.25 ~ 27, width &gt; 27.25 &amp; width &lt;= 28.25 ~ 28, width &gt; 28.25 &amp; width &lt;= 29.25 ~ 29, width &gt; 29.25 ~ 30)) %&gt;% group_by(bin) %&gt;% summarize(Mean = mean(sat, na.rm=TRUE), .groups = &quot;drop&quot;) library(ggthemes) ggplot() + geom_point(data = CrabBin, aes(x=bin, y = Mean)) + geom_line(data = Crabs2, aes(x=width, y = identity, color = colors[1])) + geom_line(data = Crabs2, aes(x=width, y = logit, color = colors[2])) + coord_cartesian(ylim = c(0, 5.5), xlim = c(22, 32)) + scale_y_continuous(breaks=seq(0, 5)) + scale_x_continuous(breaks=seq(22, 32, by = 2)) + theme_few() + annotate(geom = &quot;segment&quot;, x = 23, y = 2.1, xend = 23, yend = 1.67, arrow = arrow(length = unit(2, &quot;mm&quot;)) , color = colors[1]) + annotate(geom = &quot;text&quot;, x = 22.5, y = 2.25, label = &quot;Log link&quot;, hjust = &quot;left&quot;, color = colors[1]) + annotate(geom = &quot;segment&quot;, x = 24.5, y = 1.6, xend = 24, yend = 1.6, arrow = arrow(length = unit(2, &quot;mm&quot;)), color = colors[2]) + annotate(geom = &quot;text&quot;, x = 24.6, y = 1.6, label = &quot;Identity link&quot;, hjust = &quot;left&quot;, color = colors[2]) + theme(legend.position = &quot;none&quot;) + xlab(&quot;Width&quot;) + ylab(&quot;Mean Number of Satellites&quot;) 3.3.4 Overdispersion: Greater Variability than Expected 3.4 Generalized Lineaer Models for Counts and Rates 3.4.1 Wald, Likelihood-Ratio, and Score Inference Use the Likelihood Function \\[z = \\hat\\beta /SE,\\] \\[2\\ \\mathrm{log}(\\ell_1/\\ell_0) = 2[\\mathrm{log}(\\ell_1) - \\mathrm{log}(\\ell_0)] = 2(L_1-L_0),\\]. # https://stackoverflow.com/questions/29642867/drawing-a-tangent-to-the-plot-and-finding-the-x-intercept-using-r x = seq(-3.0, 7, by = .01) df &lt;- tibble(x = x) %&gt;% mutate(y = 10 - (x-2)^2 ) spl &lt;- smooth.spline(df$x, df$y, spar=0.3) newx &lt;- seq(min(df$x), max(df$x), 0.1) pred &lt;- predict(spl, x=newx, deriv=0) # solve for tangent at a given x newx &lt;- 0 pred0 &lt;- predict(spl, x=newx, deriv=0) pred1 &lt;- predict(spl, x=newx, deriv=1) yint &lt;- pred0$y - (pred1$y*newx) xint &lt;- -yint/pred1$y tang &lt;- tibble(x = df$x) %&gt;% mutate(y = yint + pred1$y*x) %&gt;% filter(x &gt; -2.0 &amp; x &lt; 2) library(RColorBrewer) colors &lt;- brewer.pal(n = 4, name = &quot;Dark2&quot;) library(ggthemes) ggplot() + geom_line(data = df, aes(x = x, y = y)) + geom_line(data = tang, aes(x= x, y = y)) + geom_vline(xintercept = 0) + ylim(-22,20) + annotate(geom = &quot;segment&quot;, x = 2, y = 10, xend = 2, yend = -20, color = colors[1]) + annotate(geom = &quot;segment&quot;, x = 2, y = 10, xend = 0, yend = 10, color = colors[1]) + annotate(geom = &quot;text&quot;, x = 1.9, y = -22 , label = &quot;hat(beta)&quot;, parse = TRUE, hjust = &quot;left&quot;, color = colors[1]) + annotate(geom = &quot;text&quot;, x = -.75, y = 11, label = &quot;L[1]&quot;, parse = TRUE, hjust = &quot;left&quot;, color = colors[1]) + annotate(geom = &quot;segment&quot;, x = -.45, y = 11, xend = -.05, yend = 10, arrow = arrow(length = unit(2, &quot;mm&quot;)), color = colors[1]) + annotate(geom = &quot;text&quot;, x = .6, y = 5 , label = &quot;L[0]&quot;, parse = TRUE, hjust = &quot;left&quot;) + annotate(geom = &quot;segment&quot;, x = .5, y = 5, xend = 0.1, yend = 6, arrow = arrow(length = unit(2, &quot;mm&quot;))) + theme_few() + ylab (expression(paste(&quot;L(&quot; , beta, &quot;)&quot;))) + theme(axis.title.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank(), axis.title.y = element_text(angle = 0, vjust = .5)) + scale_x_continuous(breaks = c(0), label = c(expression(paste( beta, &quot;= 0&quot;)))) + ggtitle(&quot;Figure 3.5&quot;) 3.4.2 Example Political Ideology and Belief in Evolution Evo &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Evolution.dat&quot;, header = TRUE, stringsAsFactors = FALSE) n &lt;- Evo$true + Evo$false # gives a Wald z fit &lt;- glm(true/n ~ ideology, family = binomial, weights = n, data = Evo) summary(fit) Call: glm(formula = true/n ~ ideology, family = binomial, data = Evo, weights = n) Deviance Residuals: 1 2 3 4 5 6 7 0.1430 -0.2697 1.4614 -1.0791 0.2922 0.4471 0.2035 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -1.75658 0.20500 -8.569 &lt;2e-16 *** ideology 0.49422 0.05092 9.706 &lt;2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 113.20 on 6 degrees of freedom Residual deviance: 3.72 on 5 degrees of freedom AIC: 42.332 Number of Fisher Scoring iterations: 3 # Null deviance pchisq(3.72, df=5, lower.tail=FALSE) [1] 0.5903905 # Function to get the 95% Wald confidence interval. waldCI &lt;- function(x){ list(lower = summary(x)$coefficients[, 1] + summary(x)$coefficients[, 2] * qnorm(.025,lower.tail=TRUE), upper = summary(x)$coefficients[, 1] + summary(x)$coefficients[, 2] * qnorm(.025,lower.tail=FALSE)) } waldCI(fit) # Wald CI $lower (Intercept) ideology -2.1583654 0.3944219 $upper (Intercept) ideology -1.3547930 0.5940161 confint(fit) # profile likelihood CI Waiting for profiling to be done... 2.5 % 97.5 % (Intercept) -2.165294 -1.3609733 ideology 0.396166 0.5959414 library(car) # for Anova function Loading required package: carData Attaching package: &#39;carData&#39; The following object is masked from &#39;package:vcdExtra&#39;: Burt Anova(fit) # likelihood-ratio tests for effect parameters in a GLM Analysis of Deviance Table (Type II tests) Response: true/n LR Chisq Df Pr(&gt;Chisq) ideology 109.48 1 &lt; 2.2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # can also get with drop1(fit, test = &quot;LRT&quot;) library(statmod) # for glm.scoretest # null model fit0 &lt;- glm(true/n ~ 1, family = binomial, weights = n, data = Evo) glm.scoretest(fit0, Evo$ideology)^2 # score statistic with df = 1 [1] 104.101 \\[\\mathrm{Deviance}=2(L_S-L_M).\\] pchisq(113.20, df = 6, lower.tail=FALSE) # model vs null (Null deviance) [1] 4.353897e-22 pchisq(3.72, df=5, lower.tail=FALSE) # model vs saturated (Residual deviance) [1] 0.5903905 3.4.4 Model Comparison Using the Deviance \\[2(L_1-L_0)=2(L_S-L_0)-2(L_S-L1)= \\mathrm{Deviance}_0 - \\mathrm{Deviance}_1,\\] 3.4.5 Residuals Comparing Ovservations to the Model Fit \\[\\begin{equation} \\mathrm{Pearson\\ residual} = e_i =\\frac{y_i-\\hat\\mu_i}{\\sqrt{\\widehat{var}(y_i)}} \\tag{5} \\end{equation}\\] \\[\\mathrm{Standardized\\ residual} = e_i =\\frac{y_i-\\hat\\mu_i}{SE}.\\] Evo %&gt;% bind_cols(`# sample` = .$true/n, # .$ needed to use existing column `fitted` = fitted(fit), `std. res.` = rstandard(fit, type = &quot;pearson&quot;)) ideology true false # sample fitted std. res. 1 1 11 37 0.2291667 0.2205679 0.1611162 2 2 46 104 0.3066667 0.3168813 -0.3515386 3 3 70 72 0.4929577 0.4319445 1.6480176 4 4 241 214 0.5296703 0.5548525 -1.4995488 5 5 78 36 0.6842105 0.6713982 0.3248519 6 6 89 24 0.7876106 0.7700750 0.5413625 7 7 36 6 0.8571429 0.8459201 0.2206605 3.5 Fitting Generalized Linear Models 3.5.1 The Fisher Scoring Algorithm Fits GLMs 3.5.2 Bayesian Methods for Generalized Lineare Models 3.5.3 GLMs: A Unified Approach to Statistical Analysis Random Component Link Function Explanatory Variables Model Chapter Normal Identity Continuous Regression Normal Identity Categorical Analysis of variance Normal Identity Mixed Analysis of covariance Binomial Logit Mixed Logistic regression 4-5, 8-10 Multinomial Logit Mixed Multinomial logit 8, 8-10 Poison Log Mixed Loglinear 7 "],["Logistic.html", "4 Logistic Regression 4.1 The Logistic Regression Model 4.2 Statistical Inference for Logistic Regression 4.3 Logistic Regression with Categorical Predictors 4.4 Multiple Logistic Regression 4.5 Summarizing Effects in Logistic Regression 4.6 Summzarizing Predictive Power: Classification Tables, ROC Curves and Multiple Correlation", " 4 Logistic Regression 4.1 The Logistic Regression Model 4.1.1 The Logistic Regression Model \\[\\begin{equation} \\mathrm{logit}[\\pi(x)] = \\mathrm{log}\\left[\\frac{\\pi(x)}{1=\\pi(x)}\\right]= \\alpha + \\beta x. \\tag{6} \\end{equation}\\] \\[\\begin{equation} \\pi(x) = \\frac{e^{\\alpha + \\beta x}}{1+e^{\\alpha + \\beta x}}. \\tag{7} \\end{equation}\\] 4.1.2 Odds Ratio and Linear Approximaiton Interpreetations {#4.1.2} \\[\\frac{\\pi(x)}{1-\\pi(x)}=\\mathrm{exp}(\\alpha + \\beta x) = e^\\alpha(e^\\beta)^x.\\] Crabs &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Crabs.dat&quot;, header = TRUE ) library(RColorBrewer) colors &lt;- brewer.pal(n = 4, name = &quot;Dark2&quot;) fit &lt;- glm(y ~ width, family = binomial, data = Crabs) summary(fit) Call: glm(formula = y ~ width, family = binomial, data = Crabs) Deviance Residuals: Min 1Q Median 3Q Max -2.0281 -1.0458 0.5480 0.9066 1.6942 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -12.3508 2.6287 -4.698 2.62e-06 *** width 0.4972 0.1017 4.887 1.02e-06 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 225.76 on 172 degrees of freedom Residual deviance: 194.45 on 171 degrees of freedom AIC: 198.45 Number of Fisher Scoring iterations: 4 at28 &lt;- predict(fit, data.frame(width = 28), type = &quot;resp&quot;) at29 &lt;- predict(fit, data.frame(width = 29), type = &quot;resp&quot;) x &lt;- seq(20, 34, by = .01) df &lt;- tibble(x = x) %&gt;% mutate(y = predict(fit, data.frame(width = x), type = &quot;resp&quot;)) spl &lt;- smooth.spline(df$x, df$y, spar = 0.3) newx &lt;- seq(min(df$x), max(df$x), 0.1) pred &lt;- predict(spl, x = newx, deriv = 0) # solve for tangent at a given x newx &lt;- 28 pred0 &lt;- predict(spl, x = newx, deriv = 0) pred1 &lt;- predict(spl, x = newx, deriv = 1) yint &lt;- pred0$y - (pred1$y * newx) xint &lt;- -yint / pred1$y tang &lt;- tibble(x = df$x) %&gt;% mutate(y = yint + pred1$y * x) %&gt;% filter(x &gt; 25.5 &amp; x &lt; 30.5) library(ggthemes) aLabel &lt;- as.vector(expression(paste(beta, pi, &quot;(1-&quot;, pi, &quot;)&quot;))) ggplot() + geom_line(data = df, aes(x = x, y = y)) + geom_line(data = tang, aes(x = x, y = y)) + annotate( geom = &quot;segment&quot;, x = 28, y = at28, xend = 28, yend = at29, color = colors[1] ) + annotate( geom = &quot;segment&quot;, x = 28, y = at29, xend = 29, yend = at29, color = colors[1] ) + annotate( geom = &quot;text&quot;, x = 26.35, y = at28 + .02, label = &#39;paste(beta, pi, &quot;(1-&quot; , pi, &quot;)&quot;)&#39;, parse = TRUE, hjust = &quot;left&quot;, color = colors[1] ) + annotate( geom = &quot;text&quot;, x = 28.3, y = at29 + .03, label = &quot;1&quot;, hjust = &quot;left&quot;, color = colors[1] ) + theme_few() + theme(axis.title.y = element_text(angle = 0, vjust = .5)) + scale_x_continuous(breaks = seq(20, 34, by = 2)) + scale_y_continuous(breaks = seq(0, 1, by = .2)) + ggtitle(&quot;Figure 4.1&quot;) + xlab(&quot;Width&quot;) + ylab(&quot;Probability&quot;) 4.1.3 Example: Whethr a Female Horsehoe Crab Has Satelites Crabs &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Crabs.dat&quot;, header = TRUE ) Crabs %&gt;% filter(row_number() %in% c(1, 2, n())) crab sat y weight width color spine 1 1 8 1 3.05 28.3 2 3 2 2 0 0 1.55 22.5 3 3 3 173 0 0 2.00 24.5 2 2 library(RColorBrewer) colors &lt;- brewer.pal(n = 4, name = &quot;Dark2&quot;) library(gam) gam.fit &lt;- gam(y ~ s(width), family = binomial, data = Crabs) fit &lt;- glm(y ~ width, family = binomial, data = Crabs) plot(jitter(y, 0.08) ~ width, data = Crabs, xlab = &quot;Width&quot;, ylab = &quot;Satellites&quot;) curve(predict(gam.fit, data.frame(width = x), type = &quot;resp&quot;), col = colors[1], add = TRUE ) curve(predict(fit, data.frame(width = x), type = &quot;resp&quot;), col = colors[2], add = TRUE ) summary(fit) Call: glm(formula = y ~ width, family = binomial, data = Crabs) Deviance Residuals: Min 1Q Median 3Q Max -2.0281 -1.0458 0.5480 0.9066 1.6942 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -12.3508 2.6287 -4.698 2.62e-06 *** width 0.4972 0.1017 4.887 1.02e-06 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 225.76 on 172 degrees of freedom Residual deviance: 194.45 on 171 degrees of freedom AIC: 198.45 Number of Fisher Scoring iterations: 4 # estimated probability of satellite at width = 21.0 predict(fit, data.frame(width = 21.0), type = &quot;resp&quot;) 1 0.129096 predict(fit, data.frame(width = mean(Crabs$width)), type = &quot;resp&quot;) 1 0.6738768 \\[\\mathrm{logit}[\\hat\\pi(x)] = -12.351 + 0.497 x.\\] \\[\\hat\\pi(x) =\\frac{\\mathrm{exp}(-12.351 + 0.497 x)}{1+\\mathrm{exp}(-12.351 + 0.497 x)}.\\] \\[\\frac{\\mathrm{exp}[-12.351 + 0.497 (21.0)]}{1+\\mathrm{exp}[-12.351 + 0.497 (21.0)]} = 0.129.\\] 4.1.4 Logistic Regression with Retrospective Studies 4.1.5 Normally Distributed X Implies Logistic Regression for Y 4.2 Statistical Inference for Logistic Regression 4.2.1 Confidence Intervals for Effects Crabs &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Crabs.dat&quot;, header = TRUE ) fit &lt;- glm(y ~ width, family = binomial, data = Crabs) summary(fit) # z value &amp; p-value Wald test Call: glm(formula = y ~ width, family = binomial, data = Crabs) Deviance Residuals: Min 1Q Median 3Q Max -2.0281 -1.0458 0.5480 0.9066 1.6942 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -12.3508 2.6287 -4.698 2.62e-06 *** width 0.4972 0.1017 4.887 1.02e-06 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 225.76 on 172 degrees of freedom Residual deviance: 194.45 on 171 degrees of freedom AIC: 198.45 Number of Fisher Scoring iterations: 4 suppressMessages( confint(fit) # profile likelihood confidence interval ) 2.5 % 97.5 % (Intercept) -17.8100090 -7.4572470 width 0.3083806 0.7090167 suppressPackageStartupMessages(library(car)) Anova(fit) # likelihood-ratio test of width effect Analysis of Deviance Table (Type II tests) Response: y LR Chisq Df Pr(&gt;Chisq) width 31.306 1 2.204e-08 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 4.2.2 Significance Testing 4.2.3 Fitted Values and Confidence Intervals for Probabilities \\[\\hat P(Y=1)=\\mathrm{exp}(\\hat\\alpha + \\hat\\beta x)/[1 + (\\hat\\alpha + \\hat\\beta x)],\\] Crabs &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Crabs.dat&quot;, header = TRUE, stringsAsFactors = TRUE ) fit &lt;- glm(y ~ width, family = binomial, data = Crabs) pred.prob &lt;- fitted(fit) # ML fitted value estimate of P(Y = 1) lp &lt;- predict(fit, se.fit = TRUE) # linear predictor LB &lt;- lp$fit - 1.96 * lp$se.fit # confidence bounds for linear predictor LB &lt;- lp$fit + qnorm(0.025) * lp$se.fit # better confidence bound UB &lt;- lp$fit + qnorm(0.975) * lp$se.fit LB.p &lt;- exp(LB) / (1 + exp(LB)) # confidence bounds for P(Y = 1) UB.p &lt;- exp(UB) / (1 + exp(UB)) library(dplyr) # bind_cols, filter, row_number predictions &lt;- bind_cols( Width = Crabs$width, `Predicted probaility` = pred.prob, `Lower CB` = LB.p, `Upper CB` = UB.p ) predictions %&gt;% filter(row_number() %in% c(1, 7, n())) # A tibble: 3 x 4 Width `Predicted probaility` `Lower CB` `Upper CB` &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 28.3 0.848 0.753 0.911 2 26.5 0.695 0.612 0.768 3 24.5 0.458 0.356 0.564 fit &lt;- glm(y ~ width, family = binomial, data = Crabs) library(tidyverse) data.plot &lt;- tibble(width = 18:34) lp &lt;- predict(fit, newdata = data.plot, se.fit = TRUE) library(ggthemes) data.plot &lt;- data.plot %&gt;% mutate( pred.prob = exp(lp$fit) / (1 + exp(lp$fit)), LB = lp$fit + qnorm(0.025) * lp$se.fit, UB = lp$fit + qnorm(0.975) * lp$se.fit, LB.p = exp(LB) / (1 + exp(LB)), UB.p = exp(UB) / (1 + exp(UB)) ) data.plot %&gt;% ggplot(aes(x = width)) + geom_point(data = Crabs, aes(x = width, y = jitter(y, .1))) + geom_line(aes(y = pred.prob)) + geom_ribbon(aes(ymin = LB.p, ymax = UB.p), fill = &quot;gray&quot;, alpha = 0.5) + theme_few() + ylab(&quot;Probability (satellites)&quot;) + scale_y_continuous(breaks = seq(0, 1, by = .2)) + xlab(&quot;Width&quot;) + ggtitle(&quot;Figure 4.3&quot;) 4.2.4 Why Use a Model to Estimate Probabilities? 4.3 Logistic Regression with Categorical Predictors 4.3.1 Indicator Variables Represent Categories of Predictors \\[\\mathrm{logit}[P(Y = 1)] = \\alpha + \\beta_1 x + \\beta_2 z\\] x z Logit 0 0 \\(\\alpha\\) 1 0 \\(\\alpha + \\beta_1\\) 0 0 \\(\\alpha + \\beta_2\\) 0 0 \\(\\alpha + \\beta_1 + \\beta_2\\) \\[ = [\\alpha + \\beta_1 (1) + \\beta_2 z] - [\\alpha + \\beta_1 (0) + \\beta_2 z] = \\beta_a.\\] 4.3.2 Example: Survey about Marijuana Use library(tidyverse) Marijuana &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Marijuana.dat&quot;, header = TRUE, stringsAsFactors = TRUE ) Marijuana race gender yes no 1 white female 420 620 2 white male 483 579 3 other female 25 55 4 other male 32 62 fit &lt;- glm(yes / (yes + no) ~ gender + race, weights = yes + no, family = binomial, data = Marijuana ) theFit &lt;- summary(fit) theFit Call: glm(formula = yes/(yes + no) ~ gender + race, family = binomial, data = Marijuana, weights = yes + no) Deviance Residuals: 1 2 3 4 -0.04513 0.04402 0.17321 -0.15493 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -0.83035 0.16854 -4.927 8.37e-07 *** gendermale 0.20261 0.08519 2.378 0.01739 * racewhite 0.44374 0.16766 2.647 0.00813 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 12.752784 on 3 degrees of freedom Residual deviance: 0.057982 on 1 degrees of freedom AIC: 30.414 Number of Fisher Scoring iterations: 3 # pull the 2nd and 3rd element from the &quot;Estimate&quot; column, exponentiate &amp; round round(exp(theFit$coefficients[2:3, &quot;Estimate&quot;]), 2) gendermale racewhite 1.22 1.56 # easier to follow syntax theCoef &lt;- as.data.frame(coef(theFit)) theCoef %&gt;% rownames_to_column(var = &quot;Effect&quot;) %&gt;% select(&quot;Effect&quot;, &quot;Estimate&quot;) %&gt;% filter(Effect != &quot;(Intercept)&quot;) %&gt;% mutate(`Odds Ratio` = exp(Estimate)) %&gt;% mutate_if(is.numeric, round, digits = 2) Effect Estimate Odds Ratio 1 gendermale 0.20 1.22 2 racewhite 0.44 1.56 # library(car) car::Anova(fit) # likelihood-ratio test for individual explanatory variables Analysis of Deviance Table (Type II tests) Response: yes/(yes + no) LR Chisq Df Pr(&gt;Chisq) gender 5.6662 1 0.017295 * race 7.2770 1 0.006984 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 4.3.3 ANOVA-Type Model Representation of Factors \\[\\mathrm{logit}[P(Y=1)] = \\alpha + \\beta_i^x + \\beta_k^z\\] 4.3.4 Tests of Conditoinal Independence and of Homogeneity for Three-Way Contingency Tables \\[\\mathrm{logit}[P(Y = 1)] = \\alpha + \\beta x + \\beta_k^z,\\] 4.4 Multiple Logistic Regression \\[\\mathrm{logit}[P(Y=1)] = \\alpha + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots + \\beta_p x_p.\\] 4.4.1 Example: Horseshoe Crabs with Color and Width Predictors \\[\\begin{equation} \\mathrm{logit}[P(Y=1)] = \\alpha + \\beta_1 x + \\beta_2 c_2 + \\beta_3 c_3 + \\beta_4 c_4. \\tag{8} \\end{equation}\\] Crabs &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Crabs.dat&quot;, header = TRUE, stringsAsFactors = TRUE ) fit &lt;- glm(y ~ width + factor(color), family = binomial, data = Crabs) summary(fit) Call: glm(formula = y ~ width + factor(color), family = binomial, data = Crabs) Deviance Residuals: Min 1Q Median 3Q Max -2.1124 -0.9848 0.5243 0.8513 2.1413 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -11.38519 2.87346 -3.962 7.43e-05 *** width 0.46796 0.10554 4.434 9.26e-06 *** factor(color)2 0.07242 0.73989 0.098 0.922 factor(color)3 -0.22380 0.77708 -0.288 0.773 factor(color)4 -1.32992 0.85252 -1.560 0.119 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 225.76 on 172 degrees of freedom Residual deviance: 187.46 on 168 degrees of freedom AIC: 197.46 Number of Fisher Scoring iterations: 4 \\[\\mathrm{exp}[12.715 + 0.468(26.3)]/\\{1 + \\mathrm{exp}[12.715 + 0.468(26.3)]\\}=0.399.\\] \\[\\mathrm{exp}[11.385 + 0.468(26.3)]/\\{1 + \\mathrm{exp}[11.385 + 0.468(26.3)]\\} = 0.715.\\] 4.4.2 Model Comparison to Check Whether a Term is Needed summary(glm(y ~ width, family = binomial, data = Crabs)) Call: glm(formula = y ~ width, family = binomial, data = Crabs) Deviance Residuals: Min 1Q Median 3Q Max -2.0281 -1.0458 0.5480 0.9066 1.6942 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -12.3508 2.6287 -4.698 2.62e-06 *** width 0.4972 0.1017 4.887 1.02e-06 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 225.76 on 172 degrees of freedom Residual deviance: 194.45 on 171 degrees of freedom AIC: 198.45 Number of Fisher Scoring iterations: 4 # compare deviance = 194.45 vs 187.46 with color also in model library(car) Anova(glm(y ~ width + factor(color), family = binomial, data = Crabs)) Analysis of Deviance Table (Type II tests) Response: y LR Chisq Df Pr(&gt;Chisq) width 24.6038 1 7.041e-07 *** factor(color) 6.9956 3 0.07204 . --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 4.4.3 Example: Treating Color as Quantitative or Binary \\[\\begin{equation} \\mathrm{logit}[P(Y=1)] = \\alpha + \\beta_1 x + \\beta_2 c. \\tag{9} \\end{equation}\\] fit2 &lt;- (glm(y ~ width + color, family = binomial, data = Crabs)) summary(fit2) Call: glm(formula = y ~ width + color, family = binomial, data = Crabs) Deviance Residuals: Min 1Q Median 3Q Max -2.1692 -0.9889 0.5429 0.8700 1.9742 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -10.0708 2.8068 -3.588 0.000333 *** width 0.4583 0.1040 4.406 1.05e-05 *** color -0.5090 0.2237 -2.276 0.022860 * --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 225.76 on 172 degrees of freedom Residual deviance: 189.12 on 170 degrees of freedom AIC: 195.12 Number of Fisher Scoring iterations: 4 anova(fit2, fit, test = &quot;LRT&quot;) # likelihood-ratio test comparing models Analysis of Deviance Table Model 1: y ~ width + color Model 2: y ~ width + factor(color) Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi) 1 170 189.12 2 168 187.46 2 1.6641 0.4351 Crabs$c4 &lt;- ifelse(Crabs$color == 4, 1, 0) # Crabs$c4 &lt;- I(Crabs$color == 4) fit3 &lt;- glm(y ~ width + c4, family = binomial, data = Crabs) summary(fit3) Call: glm(formula = y ~ width + c4, family = binomial, data = Crabs) Deviance Residuals: Min 1Q Median 3Q Max -2.0821 -0.9932 0.5274 0.8606 2.1553 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -11.6790 2.6925 -4.338 1.44e-05 *** width 0.4782 0.1041 4.592 4.39e-06 *** c4 -1.3005 0.5259 -2.473 0.0134 * --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 225.76 on 172 degrees of freedom Residual deviance: 187.96 on 170 degrees of freedom AIC: 193.96 Number of Fisher Scoring iterations: 4 anova(fit3, fit, test = &quot;LRT&quot;) Analysis of Deviance Table Model 1: y ~ width + c4 Model 2: y ~ width + factor(color) Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi) 1 170 187.96 2 168 187.46 2 0.50085 0.7785 4.4.4 Allowing Interaction between Explanatory Variables (interaction &lt;- glm(y ~ width + c4 + width:c4, family = binomial, data = Crabs)) Call: glm(formula = y ~ width + c4 + width:c4, family = binomial, data = Crabs) Coefficients: (Intercept) width c4 width:c4 -12.8117 0.5222 6.9578 -0.3217 Degrees of Freedom: 172 Total (i.e. Null); 169 Residual Null Deviance: 225.8 Residual Deviance: 186.8 AIC: 194.8 summary(interaction) Call: glm(formula = y ~ width + c4 + width:c4, family = binomial, data = Crabs) Deviance Residuals: Min 1Q Median 3Q Max -2.1366 -0.9344 0.4996 0.8554 1.7753 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -12.8117 2.9576 -4.332 1.48e-05 *** width 0.5222 0.1146 4.556 5.21e-06 *** c4 6.9578 7.3182 0.951 0.342 width:c4 -0.3217 0.2857 -1.126 0.260 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 225.76 on 172 degrees of freedom Residual deviance: 186.79 on 169 degrees of freedom AIC: 194.79 Number of Fisher Scoring iterations: 4 # P-value 0.28 from last paragraph of 4.4.4 car::Anova(interaction) Analysis of Deviance Table (Type II tests) Response: y LR Chisq Df Pr(&gt;Chisq) width 26.8351 1 2.216e-07 *** c4 6.4948 1 0.01082 * width:c4 1.1715 1 0.27909 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 4.4.5 Effects Depend on Other Explanatory Variables in Model 4.5 Summarizing Effects in Logistic Regression 4.5.1 Probability-Based Interpretations fit3 &lt;- glm(y ~ width + c4, family = binomial, data = Crabs) round( predict(fit3, data.frame(c4 = 1, width = mean(Crabs$width)), type = &quot;response&quot; ), 3 ) 1 0.401 round( predict(fit3, data.frame(c4 = 0, width = mean(Crabs$width)), type = &quot;response&quot; ), 3 ) 1 0.71 round( predict(fit3, data.frame(c4 = mean(Crabs$c4), width = quantile(Crabs$width)), type = &quot;response&quot; ), 3 ) 0% 25% 50% 75% 100% 0.142 0.516 0.654 0.803 0.985 4.5.2 Marginal Effects and Their Average fit3 &lt;- glm(y ~ width + c4, family = binomial, data = Crabs) suppressPackageStartupMessages(library(mfx)) # with atmean = TRUE, finds effect only at the mean logitmfx(fit3, atmean = FALSE, data = Crabs) Call: logitmfx(formula = fit3, data = Crabs, atmean = FALSE) Marginal Effects: dF/dx Std. Err. z P&gt;|z| width 0.087483 0.024472 3.5748 0.0003504 *** c4 -0.261420 0.105690 -2.4735 0.0133809 * --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 dF/dx is for discrete change for the following variables: [1] &quot;c4&quot; 4.5.3 Standardized Interpretations 4.6 Summzarizing Predictive Power: Classification Tables, ROC Curves and Multiple Correlation 4.6.1 Summarizing Predictive Power: Classification Tables Crabs &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Crabs.dat&quot;, header = TRUE, stringsAsFactors = TRUE ) prop &lt;- sum(Crabs$y) / nrow(Crabs) prop [1] 0.6416185 fit &lt;- glm(y ~ width + factor(color), family = binomial, data = Crabs) predicted &lt;- as.numeric(fitted(fit) &gt; prop) # predict y=1 when est. &gt; 0.6416 xtabs(~ Crabs$y + predicted) predicted Crabs$y 0 1 0 43 19 1 36 75 # Make Table 4.4 predicted50 &lt;- as.numeric(fitted(fit) &gt; 0.50) # predict y=1 when est. &gt; 0.50 xtabs(~ Crabs$y + predicted50) predicted50 Crabs$y 0 1 0 31 31 1 15 96 # reorder levels to flip rows and columns t1 &lt;- xtabs(~ relevel(as.factor(Crabs$y), &quot;1&quot;) + relevel(as.factor(predicted), &quot;1&quot;)) t1df &lt;- as.data.frame.matrix(t1) %&gt;% rename(&quot;t1_1&quot; = `1`) %&gt;% rename(&quot;t1_0&quot; = `0`) t2 &lt;- xtabs(~ relevel(as.factor(Crabs$y), &quot;1&quot;) + relevel(as.factor(predicted50), &quot;1&quot;)) t2df &lt;- as.data.frame.matrix(t2) %&gt;% rename(&quot;t2_1&quot; = `1`) %&gt;% rename(&quot;t2_0&quot; = `0`) Actual &lt;-tibble(Actual = c(&quot;y = 1&quot;, &quot;y = 0&quot;)) Total &lt;- tibble(Total = c(111, 62)) library(officer) # for fp_border() this needs to load before flextable library(flextable) suppressMessages(conflict_prefer(&quot;compose&quot;, &quot;flextable&quot;)) library(dplyr) # for bind_cols() # Make analysis table `Table 4.4` &lt;- bind_cols(Actual, t1df, t2df, Total) # The header needs blank columns for spaces in actual table. # The wide column labels use Unicode characters for pi. Those details are # replaced later with the compose() function. theHeader &lt;- data.frame( col_keys = c(&quot;Actual&quot;, &quot;blank&quot;, &quot;t1_1&quot;, &quot;t1_0&quot;, &quot;blank2&quot;, &quot;t2_1&quot;, &quot;t2_0&quot;, &quot;blank3&quot;, &quot;Total&quot;), line1 = c(&quot;Actual&quot;, &quot;&quot;, rep(&quot;Prediction, \\U1D70B = 0.6416&quot;, 2), &quot;&quot;, rep(&quot;Prediction, \\U1D70B = 0.50&quot;, 2), &quot;&quot;, &quot;Total&quot;), line2 = c(&quot;Actual&quot;, &quot;&quot;, &quot;t1_1&quot;, &quot;t1_0&quot;, &quot;&quot;, &quot;t2_1&quot;, &quot;t2_0&quot;, &quot;&quot;, &quot;Total&quot;)) # Border lines big_border &lt;- fp_border(color=&quot;black&quot;, width = 2) # Make the table - compose uses Unicode character # https://stackoverflow.com/questions/64088118/in-r-flextable-can-complex-symbols-appear-in-column-headings flextable(`Table 4.4`, col_keys = theHeader$col_keys) %&gt;% set_header_df(mapping = theHeader, key = &quot;col_keys&quot;) %&gt;% theme_booktabs() %&gt;% merge_v(part = &quot;header&quot;) %&gt;% merge_h(part = &quot;header&quot;) %&gt;% align(align = &quot;center&quot;, part = &quot;all&quot;) %&gt;% empty_blanks() %&gt;% fix_border_issues() %&gt;% set_caption(caption = &quot;Classification tables for horseshoe crab data with width and factor color predictors.&quot;) %&gt;% set_table_properties(width = 1, layout = &quot;autofit&quot;) %&gt;% hline_top(part=&quot;header&quot;, border = big_border) %&gt;% hline_bottom(part=&quot;body&quot;, border = big_border) %&gt;% # i = 1 refers to top row of column headerings compose(i = 1, j = &quot;t1_1&quot;, part = &quot;header&quot;, value = as_paragraph(&quot;Prediction, \\U1D70B&quot;, as_sub(&quot;0&quot;), &quot;= 0.6416&quot;)) %&gt;% compose(i = 1, j = &quot;t2_1&quot;, part = &quot;header&quot;, value = as_paragraph(&quot;Prediction, \\U1D70B&quot;, as_sub(&quot;0&quot;), &quot;= 0.50&quot;)) %&gt;% # i = 2 refers to second row of column headings compose(part = &quot;header&quot;, i = 2, j = &quot;t1_1&quot;, value = as_paragraph(&quot;y\\U0302 = 1&quot;)) %&gt;% compose(part = &quot;header&quot;, i = 2, j = &quot;t1_0&quot;, value = as_paragraph(&quot;y\\U0302 = 0&quot;)) %&gt;% compose(part = &quot;header&quot;, i = 2, j = &quot;t2_1&quot;, value = as_paragraph(&quot;y\\U0302 = 1&quot;)) %&gt;% compose(part = &quot;header&quot;, i = 2, j = &quot;t2_0&quot;, value = as_paragraph(&quot;y\\U0302 = 0&quot;)) .tabwid table{ border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 5px; margin-bottom: 5px; table-layout: fixed; border-spacing: 0; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-2d79ac3e{table-layout:auto;border-collapse:collapse;width:100%;}.cl-2d74dc40{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-2d74dc54{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-2d74dc5e{font-family:'Helvetica';font-size:7pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;position: relative;top:3pt;}.cl-2d74f37e{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:3pt;padding-top:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;}.cl-2d752b00{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d752b14{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d752b1e{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d752b28{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d752b29{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d752b32{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d752b3c{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 1: Classification tables for horseshoe crab data with width and factor color predictors. ActualPrediction, 𝜋0= 0.6416Prediction, 𝜋0= 0.50Totalŷ = 1ŷ = 0ŷ = 1ŷ = 0y = 175369615111y = 01943313162 \\[\\mathrm{Sensitivity} = P(\\hat y = 1 | y = 1), \\ \\ \\ \\ \\ \\mathrm{Sensitivity} = P(\\hat y = 0 | y = 0)\\] \\[P(\\mathrm{correct\\ classif.}) = \\mathrm{sensitivity}[P(y = 1)] + \\mathrm{specificity}[1 - P(y = 1)],\\] 4.6.2 Summarizing Predictive Power: ROC Curves fit &lt;- glm(y ~ width + factor(color), family = binomial, data = Crabs) suppressMessages(library(pROC)) suppressMessages( rocPlot &lt;- roc(y ~ fitted(fit), data = Crabs) ) x &lt;- data.frame(rocPlot$sensitivities,rocPlot$specificities, rocPlot$thresholds) thePar &lt;- par(pty = &quot;s&quot;) plot.roc(rocPlot, legacy.axes = TRUE, asp = F) par(thePar) auc(rocPlot) Area under the curve: 0.7714 # Make a prettier ROC plot including the probability cut points model &lt;- data.frame(outcome = Crabs$y, predicted = predict(fit, Crabs, type = &quot;response&quot;)) suppressMessages(library(plotROC)) # `d` (disease) holds the known truth # `m` (marker) holds the predictor values ggplot(model, aes(d = outcome, m = predicted)) + geom_roc() + style_roc(xlab = &quot;1-Specificity&quot;, ylab =&quot;Sensitivity&quot;, minor.breaks = c(seq(0, 0.1, by = 0.02), seq(0.9, 1, by = 0.02))) + ggtitle(&quot;ROC curve with probabilty cutpoints&quot;) + theme(aspect.ratio=1) + geom_abline(slope = 1, color = &quot;grey92&quot;) 4.6.3 Summarizing Predictive Power: Multiple Correlation "],["building-and-applying-logistic-regression-models.html", "5 Building and Applying Logistic Regression Models 5.1 Strategies in Model Selection 5.2 Model Checking 5.3 Infinite Estimates in Logistic Regression 5.4 Bayesian Inference, Penalized Likelihood, and Conditional Likelihood for Logistic Regression * 5.5 Alternative Link Functions: Linear Probability and Probit Models * 5.6 Sample Size and Power for Logistic Regression *", " 5 Building and Applying Logistic Regression Models 5.1 Strategies in Model Selection 5.1.1 How Many Explanatory Variables Can the Model Handle? 5.1.2 Example: Horseshoe Crab Satellites Revisited \\[\\mathrm{logit}[P(Y=1)] = \\alpha + \\beta_1 weight + \\beta_2 width + \\beta_3 c_2 + \\beta_4 c_3 + \\beta_5 c_4 + \\beta_6 s_2 + \\beta_7 s_3\\] Crabs &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Crabs.dat&quot;, header = TRUE, stringsAsFactors = TRUE ) fit &lt;- glm(y ~ weight + width + factor(color) + factor(spine), family = binomial, data = Crabs ) summary(fit) Call: glm(formula = y ~ weight + width + factor(color) + factor(spine), family = binomial, data = Crabs) Deviance Residuals: Min 1Q Median 3Q Max -2.1977 -0.9424 0.4849 0.8491 2.1198 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -8.06501 3.92855 -2.053 0.0401 * weight 0.82578 0.70383 1.173 0.2407 width 0.26313 0.19530 1.347 0.1779 factor(color)2 -0.10290 0.78259 -0.131 0.8954 factor(color)3 -0.48886 0.85312 -0.573 0.5666 factor(color)4 -1.60867 0.93553 -1.720 0.0855 . factor(spine)2 -0.09598 0.70337 -0.136 0.8915 factor(spine)3 0.40029 0.50270 0.796 0.4259 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 225.76 on 172 degrees of freedom Residual deviance: 185.20 on 165 degrees of freedom AIC: 201.2 Number of Fisher Scoring iterations: 4 pValue &lt;- 1 - pchisq(225.76 - 185.20, 172 - 165) format(round(pValue, 8), scientific = FALSE) [1] &quot;0.00000098&quot; library(car) Anova(fit) Analysis of Deviance Table (Type II tests) Response: y LR Chisq Df Pr(&gt;Chisq) weight 1.4099 1 0.23507 width 1.7968 1 0.18010 factor(color) 7.5958 3 0.05515 . factor(spine) 1.0091 2 0.60377 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 5.1.3 Stepwise Variable Selection Algorithms 5.1.4 Surposeful Selection of Explanatory Variables 5.1.5 Example: Variable Selection for Horseshoe Crabs 5.1.6 AIC and the Bias/Variance Tradeoff \\[\\mathrm{AIC = -2(log\\ likelihood) + 2(number\\ of\\ parameters\\ in\\ model).}\\] Crabs &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Crabs.dat&quot;, header = TRUE, stringsAsFactors = TRUE ) fit &lt;- glm(y ~ width + factor(color), family = binomial, data = Crabs) -2*logLik(fit) &#39;log Lik.&#39; 187.457 (df=5) AIC(fit) # adds 2(number of parameters) = 2(5) = 10 to -2*logLik(fit) [1] 197.457 fit &lt;- glm(y ~ width + factor(color) + factor(spine), family = binomial, data = Crabs) library(MASS) stepAIC(fit) Start: AIC=200.61 y ~ width + factor(color) + factor(spine) Df Deviance AIC - factor(spine) 2 187.46 197.46 &lt;none&gt; 186.61 200.61 - factor(color) 3 194.43 202.43 - width 1 208.83 220.83 Step: AIC=197.46 y ~ width + factor(color) Df Deviance AIC &lt;none&gt; 187.46 197.46 - factor(color) 3 194.45 198.45 - width 1 212.06 220.06 Call: glm(formula = y ~ width + factor(color), family = binomial, data = Crabs) Coefficients: (Intercept) width factor(color)2 factor(color)3 factor(color)4 -11.38519 0.46796 0.07242 -0.22380 -1.32992 Degrees of Freedom: 172 Total (i.e. Null); 168 Residual Null Deviance: 225.8 Residual Deviance: 187.5 AIC: 197.5 library(tidyverse) # need response variable in last column of data file Crabs2 &lt;- Crabs %&gt;% select(weight, width, color, spine, y) library(leaps) library(bestglm) bestglm(Crabs2, family = binomial, IC = &quot;AIC&quot;) # can also use IC=&quot;BIC&quot; Morgan-Tatar search since family is non-gaussian. AIC BICq equivalent for q in (0.477740316103793, 0.876695783647898) Best Model: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -10.0708390 2.8068339 -3.587971 3.332611e-04 width 0.4583097 0.1040181 4.406056 1.052696e-05 color -0.5090467 0.2236817 -2.275763 2.286018e-02 5.2 Model Checking 5.2.1 Goodness of Fit: Model Comparison Using the Deviance \\[G^2 = 2\\sum\\mathrm{observed[log(observed/fitted)]}\\] 5.2.2 Example: Goodness of Fit for Marijuana Use Survey library(tidyverse) Marijuana &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Marijuana.dat&quot;, header = TRUE, stringsAsFactors = TRUE) Marijuana race gender yes no 1 white female 420 620 2 white male 483 579 3 other female 25 55 4 other male 32 62 fit &lt;- glm(yes/(yes+no) ~ gender + race, weights = yes + no, family = binomial, data = Marijuana) summary(fit) # deviance info is extracted on the next two lines Call: glm(formula = yes/(yes + no) ~ gender + race, family = binomial, data = Marijuana, weights = yes + no) Deviance Residuals: 1 2 3 4 -0.04513 0.04402 0.17321 -0.15493 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -0.83035 0.16854 -4.927 8.37e-07 *** gendermale 0.20261 0.08519 2.378 0.01739 * racewhite 0.44374 0.16766 2.647 0.00813 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 12.752784 on 3 degrees of freedom Residual deviance: 0.057982 on 1 degrees of freedom AIC: 30.414 Number of Fisher Scoring iterations: 3 fit$deviance # deviance goodness-of-fit statistic [1] 0.05798151 fit$df.residual # residual df [1] 1 1 - pchisq(fit$deviance, fit$df.residual ) [1] 0.8097152 fitted(fit) 1 2 3 4 0.4045330 0.4541297 0.3035713 0.3480244 library(dplyr) Marijuana %&gt;% mutate(fit.yes = (yes+no)*fitted(fit)) %&gt;% mutate(fit.no = (yes+no)*(1-fitted(fit))) %&gt;% select(race, gender, yes, fit.yes, no, fit.no) race gender yes fit.yes no fit.no 1 white female 420 420.71429 620 619.28571 2 white male 483 482.28571 579 579.71429 3 other female 25 24.28571 55 55.71429 4 other male 32 32.71429 62 61.28571 5.2.3 Goodness of Fit: Grouped versus Ungrouped Data and Continuous Predictors 5.2.4 Residuals for Logistic Models with Categorical Predictors \\[\\mathrm{Standardized\\ residual} = \\frac{y_i-n_i\\hat\\pi_i}{SE}.\\] ### 5.2.5 Example: Graduate Admissoins at University of Florida library(tidyverse) Admissions &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Admissions.dat&quot;, header = TRUE, stringsAsFactors = TRUE) theModel &lt;- glm(yes/(yes+no) ~ department, family = binomial, data = Admissions, weights = yes+no) theResiduals &lt;- tibble(`Std. Res.` = rstandard(theModel, type = &quot;pearson&quot;)) %&gt;% mutate(`Std. Res.` = round(`Std. Res.`, 2)) %&gt;% dplyr::filter(row_number() %% 2 == 0) # every other record is female theTable &lt;- Admissions %&gt;% mutate(gender = case_when(gender == 1 ~ &quot;Female&quot;, gender == 0 ~ &quot;Male&quot;)) %&gt;% pivot_wider(id_cols = department, names_from = gender, values_from = c(yes, no), names_sep = &quot;&quot;) %&gt;% select(department, yesFemale, noFemale, yesMale, noMale) %&gt;% rename(&quot;Dept&quot; = department, &quot;Females (Yes)&quot; = yesFemale, &quot;Females (No)&quot; = noFemale, &quot;Males (Yes)&quot; = yesMale, &quot;Males (No)&quot; = noMale) %&gt;% bind_cols(theResiduals) knitr::kable(theTable) Dept Females (Yes) Females (No) Males (Yes) Males (No) Std. Res. anthropol 32 81 21 41 -0.76 astronomy 6 0 3 8 2.87 chemistry 12 43 34 110 -0.27 classics 3 1 4 0 -1.07 communicat 52 149 5 10 -0.63 computersci 8 7 6 12 1.16 english 35 100 30 112 0.94 geography 9 1 11 11 2.17 geology 6 3 15 6 -0.26 germanic 17 0 4 1 1.89 history 9 9 21 19 -0.18 latinamer 26 7 25 16 1.65 linguistics 21 10 7 8 1.37 mathematics 25 18 31 37 1.29 philosophy 3 0 9 6 1.34 physics 10 11 25 53 1.32 polisci 25 34 39 49 -0.23 psychology 2 123 4 41 -2.27 religion 3 3 0 2 1.26 romancelang 29 13 6 3 0.14 sociology 16 33 7 17 0.30 statistics 23 9 36 14 -0.01 zoology 4 62 10 54 -1.76 \\[logit(\\pi_{ik}) = \\alpha + \\beta_k.\\] 5.2.6 Standardized versus Pearson and Deviance Residuals fit &lt;- glm(yes/(yes+no) ~ gender + race, weights = yes + no, family = binomial, data = Marijuana) summary(fit) Call: glm(formula = yes/(yes + no) ~ gender + race, family = binomial, data = Marijuana, weights = yes + no) Deviance Residuals: 1 2 3 4 -0.04513 0.04402 0.17321 -0.15493 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -0.83035 0.16854 -4.927 8.37e-07 *** gendermale 0.20261 0.08519 2.378 0.01739 * racewhite 0.44374 0.16766 2.647 0.00813 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 12.752784 on 3 degrees of freedom Residual deviance: 0.057982 on 1 degrees of freedom AIC: 30.414 Number of Fisher Scoring iterations: 3 knitr::kable( bind_cols(Standardized = rstandard(fit, type = &quot;pearson&quot;), Pearson = residuals(fit, type = &quot;pearson&quot;), deviance = residuals(fit, type = &quot;deviance&quot;), `std dev.` = rstandard(fit, type = &quot;deviance&quot;), Race = Marijuana$race, Gender = Marijuana$gender) %&gt;% mutate_if(is.numeric, round, digits = 3) ) Standardized Pearson deviance std dev. Race Gender -0.241 -0.045 -0.045 -0.241 white female 0.241 0.044 0.044 0.241 white male 0.241 0.174 0.173 0.240 other female -0.241 -0.155 -0.155 -0.241 other male 5.2.7 Influence Diagnostics for Logistic Regression 5.2.8 Example: Heart Disease and Blood Pressure HeartBP &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/HeartBP.dat&quot;, header = TRUE, stringsAsFactors = TRUE) theModel &lt;- glm(y/n ~ bp, family = binomial, data = HeartBP, weights = n) summary(theModel) Call: glm(formula = y/n ~ bp, family = binomial, data = HeartBP, weights = n) Deviance Residuals: Min 1Q Median 3Q Max -1.0617 -0.5977 -0.2245 0.2140 1.8501 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -6.082033 0.724320 -8.397 &lt; 2e-16 *** bp 0.024338 0.004843 5.025 5.03e-07 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 30.0226 on 7 degrees of freedom Residual deviance: 5.9092 on 6 degrees of freedom AIC: 42.61 Number of Fisher Scoring iterations: 4 predicted &lt;- round(fitted(theModel)* HeartBP$n, 1) std_res &lt;- round(rstandard(theModel, type = &quot;pearson&quot;),2) #influence.measures(theModel) rDfbeta &lt;- data.frame(dfbetas(theModel)) %&gt;% select(bp) %&gt;% transmute(DFbeta = round(bp, 2)) HeartBP %&gt;% rename(&quot;Blood Presure&quot; = bp, &quot;Sample size&quot; = n, &quot;Observed Disease&quot; = y) %&gt;% bind_cols(&quot;Fitted Disease&quot; = predicted, &quot;Standardized Residual&quot; = std_res, &quot;Dfbeta (not SAS)&quot; = rDfbeta) Blood Presure Sample size Observed Disease Fitted Disease 1 111.5 156 3 5.2 2 121.5 252 17 10.6 3 131.5 284 12 15.1 4 141.5 271 16 18.1 5 151.5 139 12 11.6 6 161.5 85 8 8.9 7 176.5 99 16 14.2 8 191.5 43 8 8.4 Standardized Residual DFbeta 1 -1.11 0.56 2 2.37 -2.24 3 -0.95 0.34 4 -0.57 0.08 5 0.13 0.01 6 -0.33 -0.06 7 0.65 0.38 8 -0.18 -0.11 library(ggthemes) predicted &lt;- predict(theModel, type = &quot;response&quot;) HeartBP %&gt;% mutate(proportion=y/n) %&gt;% ggplot(aes(x= bp, y = proportion)) + geom_point(shape = 4) + geom_smooth(aes(y = predicted)) + theme_few() + scale_x_continuous(breaks = seq(110, 200, by = 10), limits = c(110, 200)) + ggtitle(&quot;Figure 5.1&quot;) `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; 5.3 Infinite Estimates in Logistic Regression 5.3.1 Complete and Quasi-Complete Separation: Perfeect Discrination library(tidyverse) library(ggthemes) data.frame (x = c(10, 20, 30, 40, 60, 70, 80, 90), y = c(0, 0, 0, 0, 1, 1, 1, 1)) %&gt;% ggplot(aes(x = x, y = y)) + geom_point() + theme_few() + ggtitle(&quot;Figure 5.2&quot;) + scale_y_continuous(breaks = c(0,1)) + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank(), axis.title.y = element_text(angle = 0, vjust = 0.5), plot.title = element_text(hjust = 0.5)) 5.3.2 Example: Infinite Estimate for Toy Example x &lt;- c(10, 20, 30, 40, 60, 70, 80, 90) y &lt;- c(0, 0, 0, 0, 1, 1, 1, 1) fit &lt;- glm(y ~ x, family = binomial) Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred # P-value for Wald test of H0: beta = 0 # res deviance = 0 means perfect fit # Fisher iterations: 25 shows very slow convergence summary(fit) Call: glm(formula = y ~ x, family = binomial) Deviance Residuals: Min 1Q Median 3Q Max -1.045e-05 -2.110e-08 0.000e+00 2.110e-08 1.045e-05 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -118.158 296046.187 0 1 x 2.363 5805.939 0 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 1.1090e+01 on 7 degrees of freedom Residual deviance: 2.1827e-10 on 6 degrees of freedom AIC: 4 Number of Fisher Scoring iterations: 25 # maximized log-likelihood = 0, so maximized likelihood = 1 logLik(fit) &#39;log Lik.&#39; -1.09134e-10 (df=2) #library(car) # P-value for likelihood-ratio test of beta = 0 is more sensitive than p-value of 1 for Wald test car::Anova(fit) Analysis of Deviance Table (Type II tests) Response: y LR Chisq Df Pr(&gt;Chisq) x 11.09 1 0.0008678 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 library(profileModel) # ordinary confint function fails for infinite estimates confintModel(fit, objective = &quot;ordinaryDeviance&quot;, method = &quot;zoom&quot;) Preliminary iteration .. Done Profiling for parameter (Intercept) ... Done Profiling for parameter x ... Done Zooming for parameter (Intercept) ... Zooming for parameter x ... Lower Upper (Intercept) -Inf -2.66963 x 0.05876605 Inf attr(,&quot;fitted object&quot;) fit 5.3.3 Sparse Data and Infinite Effects with Categorical Predictors 5.3.4 Example: Risk Factors for Endometrial Cancer Grade library(tidyverse) Endo &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Endometrial.dat&quot;, header = TRUE, stringsAsFactors = TRUE) Endo %&gt;% filter(row_number() %in% c(1, 2, n())) NV PI EH HG 1 0 13 1.64 0 2 0 16 2.26 0 3 0 33 0.85 1 xtabs(~NV + HG, data = Endo) # quasi-complete separation when NV = 1, no HG=0 cases occur HG NV 0 1 0 49 17 1 0 13 fit &lt;- glm(HG ~ NV + PI + EH, family = binomial, data = Endo) # NV&#39;s true estimate is infinity summary(fit) Call: glm(formula = HG ~ NV + PI + EH, family = binomial, data = Endo) Deviance Residuals: Min 1Q Median 3Q Max -1.50137 -0.64108 -0.29432 0.00016 2.72777 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) 4.30452 1.63730 2.629 0.008563 ** NV 18.18556 1715.75089 0.011 0.991543 PI -0.04218 0.04433 -0.952 0.341333 EH -2.90261 0.84555 -3.433 0.000597 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 104.903 on 78 degrees of freedom Residual deviance: 55.393 on 75 degrees of freedom AIC: 63.393 Number of Fisher Scoring iterations: 17 logLik(fit) &#39;log Lik.&#39; -27.69663 (df=4) library(car) Anova(fit) # NV P= .0022 vs Wald 0.99 Analysis of Deviance Table (Type II tests) Response: HG LR Chisq Df Pr(&gt;Chisq) NV 9.3576 1 0.002221 ** PI 0.9851 1 0.320934 EH 19.7606 1 8.777e-06 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 library(profileModel) # ordinary confint function fails for infinite est confintModel(fit, objective = &quot;ordinaryDeviance&quot;, method = &quot;zoom&quot;) # 95% profile likelihood CI for beta 1 Preliminary iteration .... Done Profiling for parameter (Intercept) ... Done Profiling for parameter NV ... Done Profiling for parameter PI ... Done Profiling for parameter EH ... Done Zooming for parameter (Intercept) ... Zooming for parameter NV ... Zooming for parameter PI ... Zooming for parameter EH ... Lower Upper (Intercept) 1.4290183 7.94717425 NV 1.2856920 Inf PI -0.1370717 0.03810556 EH -4.7866976 -1.43682244 attr(,&quot;fitted object&quot;) fit library(detectseparation) # new package # 0 denotes finite est, Inf denotes infinite est. glm(HG ~ NV + PI + EH, family = binomial, data = Endo, method = &quot;detectSeparation&quot;) Implementation: ROI | Solver: lpsolve Separation: TRUE Existence of maximum likelihood estimates (Intercept) NV PI EH 0 Inf 0 0 0: finite value, Inf: infinity, -Inf: -infinity 5.4 Bayesian Inference, Penalized Likelihood, and Conditional Likelihood for Logistic Regression * 5.4.1 Bayesian Modeling: Specification of Prior Distributions 5.4.2 Example: Risk Factors for Endometrial Caner Revisited Endo2 &lt;- Endo %&gt;% mutate(PI2 = scale(PI), EH2 = scale(EH), NV2 = NV - 0.5) fit.ML &lt;- glm(HG ~ NV2 + PI2 + EH2, family = binomial, data = Endo2) summary(fit.ML) Call: glm(formula = HG ~ NV2 + PI2 + EH2, family = binomial, data = Endo2) Deviance Residuals: Min 1Q Median 3Q Max -1.50137 -0.64108 -0.29432 0.00016 2.72777 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) 7.8411 857.8755 0.009 0.992707 NV2 18.1856 1715.7509 0.011 0.991543 PI2 -0.4217 0.4432 -0.952 0.341333 EH2 -1.9219 0.5599 -3.433 0.000597 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 104.903 on 78 degrees of freedom Residual deviance: 55.393 on 75 degrees of freedom AIC: 63.393 Number of Fisher Scoring iterations: 17 library(MCMCpack) # b0 = prior mean, B0 = prior precision = 1/variance Loading required package: coda ## ## Markov Chain Monte Carlo Package (MCMCpack) ## Copyright (C) 2003-2021 Andrew D. Martin, Kevin M. Quinn, and Jong Hee Park ## ## Support provided by the U.S. National Science Foundation ## (Grants SES-0350646 and SES-0350613) ## fitBayes &lt;- MCMClogit(HG ~ NV2 + PI2 + EH2, mcmc = 100000, b0 = 0, B0 = 0.01, data = Endo2) # prior var = 1/0.01 = 100, sd = 10 summary(fitBayes) # posterior deviation Iterations = 1001:101000 Thinning interval = 1 Number of chains = 1 Sample size per chain = 1e+05 1. Empirical mean and standard deviation for each variable, plus standard error of the mean: Mean SD Naive SE Time-series SE (Intercept) 3.2356 2.5948 0.008206 0.026682 NV2 9.1626 5.1639 0.016330 0.053109 PI2 -0.4711 0.4546 0.001437 0.006376 EH2 -2.1332 0.5879 0.001859 0.008450 2. Quantiles for each variable: 2.5% 25% 50% 75% 97.5% (Intercept) -0.3391 1.2619 2.7161 4.6972 9.4865 NV2 2.1105 5.2437 8.1064 12.1133 21.6077 PI2 -1.4163 -0.7676 -0.4445 -0.1538 0.3538 EH2 -3.3781 -2.5087 -2.0977 -1.7227 -1.0786 mean(fitBayes[,2] &lt; 0) # probability below 0 for 2n model parameter (NV2) [1] 0.00016 5.4.3 Penalized Likelihood Reduces Bias in Logistic Regression \\[L^*(\\beta) = L(\\beta) - s(\\beta),\\] 5.4.4 Example: Risk Factors for Endometrial Cancer Revisited library(logistf) fit.penalized &lt;- logistf(HG ~ NV2 + PI2 + EH2, family=binomial, data=Endo2) options(digits = 4) summary(fit.penalized) logistf(formula = HG ~ NV2 + PI2 + EH2, data = Endo2, family = binomial) Model fitted by Penalized ML Coefficients: coef se(coef) lower 0.95 upper 0.95 Chisq p method (Intercept) 0.3080 0.8006 -0.9755 2.7888 0.1690 6.810e-01 2 NV2 2.9293 1.5508 0.6097 7.8546 6.7985 9.124e-03 2 PI2 -0.3474 0.3957 -1.2443 0.4045 0.7468 3.875e-01 2 EH2 -1.7243 0.5138 -2.8903 -0.8162 17.7593 2.507e-05 2 Method: 1-Wald, 2-Profile penalized log-likelihood, 3-None Likelihood ratio test=43.66 on 3 df, p=1.786e-09, n=79 Wald test = 17.48 on 3 df, p = 0.000563 options(digits = 7) 5.4.5 Conditional Likelihood and Conditional Logistic Regression \\[\\mathrm{logit}[P(Y_{it} = 1)] = \\alpha_i + \\beta x_{it},\\] 5.4.6 Conditional Logistic Regression and Exact Tests for Contingency Tables 5.5 Alternative Link Functions: Linear Probability and Probit Models * 5.5.1 Linar Probability Model \\[F(Y = 1) = \\alpha + \\beta_1 x_1 + \\cdots + \\beta_px_p,\\] 5.5.2 Example: Political Ideology and Belief in Evolution library(tidyverse) Evo &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Evolution2.dat&quot;, header = TRUE, stringsAsFactors = TRUE) Evo %&gt;% filter(row_number() %in% c(1, 2, n())) ideology evolved 1 1 1 2 1 1 3 7 0 fit &lt;- glm(evolved ~ ideology, family=quasi(link=identity, variance = &quot;mu(1-mu)&quot;), data = Evo) summary(fit, dispersion = 1) Call: glm(formula = evolved ~ ideology, family = quasi(link = identity, variance = &quot;mu(1-mu)&quot;), data = Evo) Deviance Residuals: Min 1Q Median 3Q Max -2.0558 -1.2617 0.7247 1.0954 1.7440 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) 0.108437 0.038932 2.785 0.00535 ** ideology 0.110102 0.008971 12.273 &lt; 2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for quasi family taken to be 1) Null deviance: 1469.3 on 1063 degrees of freedom Residual deviance: 1359.5 on 1062 degrees of freedom AIC: NA Number of Fisher Scoring iterations: 3 fit2 &lt;- glm(evolved ~ ideology, family=gaussian(link=identity), data = Evo) summary(fit2) Call: glm(formula = evolved ~ ideology, family = gaussian(link = identity), data = Evo) Deviance Residuals: Min 1Q Median 3Q Max -0.8819 -0.5492 0.2290 0.4508 0.7836 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 0.10554 0.04272 2.47 0.0137 * ideology 0.11091 0.01033 10.73 &lt;2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for gaussian family taken to be 0.2247506) Null deviance: 264.57 on 1063 degrees of freedom Residual deviance: 238.69 on 1062 degrees of freedom AIC: 1435.2 Number of Fisher Scoring iterations: 2 5.5.3 Probit Model and Normal Latent Variable Model \\[\\mathrm{probit}[F(Y = 1)] = \\alpha + \\beta_1 x_1 + \\cdots + \\beta_px_p\\] \\[y^* = \\alpha + \\beta_1 x_1+ \\cdots + \\beta_px_p + \\epsilon.\\] 5.5.4 Example: Snoring and Heart Disease Revisited \\[\\mathrm{probit}[\\hat P(Y = 1)] = -2.061 + 0.188x.\\] library(tidyverse) Heart &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Heart.dat&quot;, header = TRUE, stringsAsFactors = TRUE) Heart snoring yes no 1 never 24 1355 2 occasional 35 603 3 nearly_every_night 21 192 4 every_night 30 224 # recode() is in dplyr and car... Heart &lt;- Heart %&gt;% mutate(snoringNights = dplyr::recode(snoring, never = 0, occasional = 2, nearly_every_night = 4, every_night = 5)) fit &lt;- glm(yes/(yes+no) ~ snoringNights, family = binomial(link = probit), weights = yes+no, data = Heart) summary(fit) Call: glm(formula = yes/(yes + no) ~ snoringNights, family = binomial(link = probit), data = Heart, weights = yes + no) Deviance Residuals: 1 2 3 4 -0.6188 1.0388 0.1684 -0.6175 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -2.06055 0.07017 -29.367 &lt; 2e-16 *** snoringNights 0.18777 0.02348 7.997 1.28e-15 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 65.9045 on 3 degrees of freedom Residual deviance: 1.8716 on 2 degrees of freedom AIC: 26.124 Number of Fisher Scoring iterations: 4 options(digits = 4) fitted(fit) 1 2 3 4 0.01967 0.04599 0.09519 0.13100 options(digits = 7) 5.5.5 Latent Variable Models Imply Binary Regression Models 5.5.6 CDFs and Shapes of Curves for Binary Reegressoin Models 5.6 Sample Size and Power for Logistic Regression * 5.6.1 Sample Size for Comparing Two Proportions 5.6.2 Sample Size in Logistic Regression Modeling 5.6.3 Example: Modeling the Probability of Heart Disease "],["Multicategory.html", "6 Multicategory Logit Models 6.1 Baseline-Category Logit Models for Nominal Responses 6.2 Cumulative Logit Models for Ordinal Responses {x6.2} 6.3 Cumulative Link Models: Model Checking and Extensions * 6.4 Paired-Category Logit Modeling of Ordinal Response *", " 6 Multicategory Logit Models 6.1 Baseline-Category Logit Models for Nominal Responses 6.1.1 Baseline-Category Logits \\[\\mathrm{log}\\left(\\frac{\\pi_j}{\\pi_c}\\right),\\ j = 1, \\dots,\\ c-1.\\] \\[\\begin{equation} \\mathrm{log}(\\frac{\\pi_j}{\\pi_c}) = \\alpha_j + \\beta_j x,\\ j = 1, \\dots, c-1 \\tag{10} \\end{equation}\\] \\[\\begin{equation} \\mathrm{log}(\\frac{\\pi_1}{\\pi_2}) = \\mathrm{log}\\left(\\frac{\\pi_1/\\pi_3}{\\pi_2/\\pi_3}\\right) = \\mathrm{log}\\left(\\pi_1/\\pi_3\\right) - \\mathrm{log}\\left(\\pi_2/\\pi_3\\right) \\\\ = (\\alpha_1 + \\beta_1 x) - (\\alpha_2 + \\beta_2 x) \\\\ = (\\alpha_1 -\\alpha_2) + (\\beta_1 - \\beta_2) x \\tag{11} \\end{equation}\\] \\[\\begin{equation} \\mathrm{log}(\\frac{\\pi_j}{\\pi_c}) = \\alpha_j + \\beta_{j1} x_1 + \\beta_{j2} x_2 + \\dots + \\beta_{jp} x_p \\ j = 1, \\dots, c-1 \\tag{12} \\end{equation}\\] 6.1.2 Example: What Do Alligators Eat? library(tidyverse) Gators &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Alligators.dat&quot;, header = TRUE, stringsAsFactors = TRUE) Gators %&gt;% filter(row_number() %in% c(1, 2, n())) x y 1 1.24 I 2 1.30 I 3 3.89 F library(VGAM) # package for multivariate GLMs, such s multinomial models Loading required package: stats4 fit &lt;- vglm(y ~ x, family = multinomial, data = Gators) # vglm = vector GLM summary(fit) Call: vglm(formula = y ~ x, family = multinomial, data = Gators) Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept):1 1.6177 1.3073 1.237 0.21591 (Intercept):2 5.6974 1.7937 3.176 0.00149 ** x:1 -0.1101 0.5171 -0.213 0.83137 x:2 -2.4654 0.8996 NA NA --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Names of linear predictors: log(mu[,1]/mu[,3]), log(mu[,2]/mu[,3]) Residual deviance: 98.3412 on 114 degrees of freedom Log-likelihood: -49.1706 on 114 degrees of freedom Number of Fisher scoring iterations: 5 Warning: Hauck-Donner effect detected in the following estimate(s): &#39;x:2&#39; Reference group is level 3 of the response \\[\\mathrm{log}(\\hat\\pi_1/\\hat\\pi_3) = 1.618 - 0.110x, \\\\ \\mathrm{log}(\\hat\\pi_1/\\hat\\pi_2) = 5.697 - 2.465x. \\] \\[\\mathrm{log}(\\hat\\pi_1 / \\hat\\pi_2) = (1.618 - 5.697) + [- 0.110 - (- 2.465)]x = -4.080 + 2.355x.\\] fit2 &lt;- vglm(y ~ x, family = multinomial(refLevel = 2), data = Gators) summary(fit2) Call: vglm(formula = y ~ x, family = multinomial(refLevel = 2), data = Gators) Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept):1 -4.0797 1.4686 -2.778 0.00547 ** (Intercept):2 -5.6974 1.7937 -3.176 0.00149 ** x:1 2.3553 0.8032 NA NA x:2 2.4654 0.8996 2.741 0.00613 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Names of linear predictors: log(mu[,1]/mu[,2]), log(mu[,3]/mu[,2]) Residual deviance: 98.3412 on 114 degrees of freedom Log-likelihood: -49.1706 on 114 degrees of freedom Number of Fisher scoring iterations: 5 Warning: Hauck-Donner effect detected in the following estimate(s): &#39;x:1&#39; Reference group is level 2 of the response confint(fit2, method = &quot;profile&quot;) 2.5 % 97.5 % (Intercept):1 -7.3475058 -1.518699 (Intercept):2 -9.5913317 -2.485991 x:1 1.0111800 4.199073 x:2 0.8775186 4.463608 fit0 &lt;- vglm(y ~ 1, family=multinomial, data = Gators) # null model deviance(fit0) # deviance for working model is 98.3412 [1] 115.1419 VGAM::lrtest(fit, fit0) # rltest function available in VGAM package for LR tests Likelihood ratio test Model 1: y ~ x Model 2: y ~ 1 #Df LogLik Df Chisq Pr(&gt;Chisq) 1 114 -49.171 2 116 -57.571 2 16.801 0.0002248 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # .00022 deviance diff = 2(log-like. diff.) 6.1.3 Estimating Response Probabilities The response probabilities relate to the model parameters by \\[\\pi_j = \\frac{e^{\\alpha_j + \\beta_{j1} x_1 + \\beta_{j2} x_2 + \\dots + \\beta_{jp} x_p}} {\\sum_{h=1}^c e^{\\alpha_h + \\beta_{h1} x_1 + \\beta_{h2} x_2 + \\dots + \\beta_{hp} x_p}},\\ j = 1, \\dots , c.\\] fitted(fit) %&gt;% data.frame(.) %&gt;% filter(row_number() %in% c(1, 2, n())) F I O 1 0.2265307 0.721964000 0.05150528 2 0.2502564 0.692466814 0.05727683 59 0.7630060 0.004733748 0.23226027 # obs 59 is alligator of length 3.89 meters library(ggthemes) library(RColorBrewer) colors &lt;- brewer.pal(n = 4, name = &quot;Dark2&quot;) fitted(fit) %&gt;% data.frame(.) %&gt;% bind_cols(length = Gators$x) %&gt;% rename(&quot;Fish&quot; = F, &quot;Invertebrates&quot; = I, &quot;Other&quot; = O) %&gt;% pivot_longer(cols = c(Fish, Invertebrates, Other)) %&gt;% ggplot() + geom_line(aes(x = length, y = value, color = name)) + scale_colour_manual(values=colors)+ ylim(0, 1) + xlim(1, 4) + xlab(&quot;Length of Alligator&quot;) + ylab(&quot;Predicted Probability&quot;) + theme_few() + annotate(geom = &quot;segment&quot;, x = 2.8, y = 0.65, xend = 2.60, yend = .71, arrow = arrow(length = unit(2, &quot;mm&quot;)) , color = colors[1]) + annotate(geom = &quot;text&quot;, x = 2.825, y = 0.65, label = &quot;Fish&quot;, hjust = &quot;left&quot;, color = colors[1]) + annotate(geom = &quot;segment&quot;, x = 2.1, y = 0.45, xend = 1.80, yend = .42, arrow = arrow(length = unit(2, &quot;mm&quot;)) , color = colors[2]) + annotate(geom = &quot;text&quot;, x = 2.125, y = 0.45, label = &quot;Invertebrates&quot;, hjust = &quot;left&quot;, color = colors[2]) + annotate(geom = &quot;segment&quot;, x = 2.1, y = 0.05, xend = 1.80, yend = .1, arrow = arrow(length = unit(2, &quot;mm&quot;)) , color = colors[3]) + annotate(geom = &quot;text&quot;, x = 2.125, y = 0.05, label = &quot;Other&quot;, hjust = &quot;left&quot;, color = colors[3]) + theme(legend.position=&quot;none&quot;) + ggtitle(&quot;Figure 6.1&quot;) 6.1.4 Checking multinomial Model Goodness of Fit \\[G^2 = 2\\sum \\mathrm{observed[log(observed/fitted)]}.\\] 6.1.5 Example: Belief in Afterlife Afterlife &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Afterlife.dat&quot;, header = TRUE, stringsAsFactors = TRUE) Afterlife race gender yes undecided no 1 white female 371 49 74 2 white male 250 45 71 3 black female 64 9 15 4 black male 25 5 13 library(VGAM) fit &lt;- vglm(cbind(yes, undecided, no) ~ gender + race, family = multinomial, data = Afterlife) summary(fit) Call: vglm(formula = cbind(yes, undecided, no) ~ gender + race, family = multinomial, data = Afterlife) Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept):1 1.3016 0.2265 5.747 9.1e-09 *** (Intercept):2 -0.6529 0.3405 -1.918 0.0551 . gendermale:1 -0.4186 0.1713 -2.444 0.0145 * gendermale:2 -0.1051 0.2465 -0.426 0.6700 racewhite:1 0.3418 0.2370 1.442 0.1493 racewhite:2 0.2710 0.3541 0.765 0.4442 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Names of linear predictors: log(mu[,1]/mu[,3]), log(mu[,2]/mu[,3]) Residual deviance: 0.8539 on 2 degrees of freedom Log-likelihood: -19.7324 on 2 degrees of freedom Number of Fisher scoring iterations: 3 No Hauck-Donner effect found in any of the estimates Reference group is level 3 of the response fit.gender &lt;- vglm(cbind(yes, undecided, no) ~ gender, family = multinomial, data = Afterlife) deviance(fit.gender) [1] 2.848098 VGAM::lrtest(fit, fit.gender) # deviance dif = 2(log-likelihood. diff.) Likelihood ratio test Model 1: cbind(yes, undecided, no) ~ gender + race Model 2: cbind(yes, undecided, no) ~ gender #Df LogLik Df Chisq Pr(&gt;Chisq) 1 2 -19.732 2 4 -20.730 2 1.9942 0.3689 fit.race &lt;- vglm(cbind(yes, undecided, no) ~ race, family = multinomial, data = Afterlife) deviance(fit.race) [1] 8.046504 VGAM::lrtest(fit, fit.race) # deviance dif = 2(log-likelihood. diff.) Likelihood ratio test Model 1: cbind(yes, undecided, no) ~ gender + race Model 2: cbind(yes, undecided, no) ~ race #Df LogLik Df Chisq Pr(&gt;Chisq) 1 2 -19.732 2 4 -23.329 2 7.1926 0.02742 * --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 data.frame(Afterlife$race, Afterlife$gender, round(fitted(fit), 4)) Afterlife.race Afterlife.gender yes undecided no 1 white female 0.7546 0.0996 0.1459 2 white male 0.6783 0.1224 0.1993 3 black female 0.7074 0.1002 0.1925 4 black male 0.6222 0.1206 0.2573 6.1.6 Discrete Choice Models* 6.1.7 Example: Shopping Destination Choice* 6.2 Cumulative Logit Models for Ordinal Responses {x6.2} 6.2.1 Cumulative Logit Models with Proportional Odds \\[\\begin{equation} \\mathrm{logit}[P(Y \\le j)] = \\alpha_j + \\beta x,\\ j = 1, \\dots,\\ c-1 \\tag{13} \\end{equation}\\] # https://rpubs.com/riazakhan94/logstcdistbasics cdf=function(x,mu,s){ k=(x-mu)/s return(1/(1+exp(-k))) } theData &lt;- tibble(x=seq(-10,12,0.01)) %&gt;% mutate(curve0 = cdf(x, 0, 1)) %&gt;% mutate(curve2 = cdf(x, 2, 1)) %&gt;% mutate(curve4 = cdf(x, 4, 1)) library(ggthemes) # theme_few theData %&gt;% ggplot(aes(x = x)) + geom_line(aes(y = curve0), color = colors[3]) + geom_line(aes(y = curve2), color = colors[2]) + geom_line(aes(y = curve4), color = colors[1]) + ggtitle(&quot;Figure 6.2&quot;) + ylab(expression(&quot;P(Y&quot; &lt;= &quot;j)&quot;)) + scale_y_continuous(breaks=c(0,1), labels=c(&quot;0&quot;, &quot;1&quot;)) + theme_few() + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank(), axis.title.y = element_text(angle = 0, vjust = 0.5), plot.title = element_text(hjust = 0.5)) + annotate(geom = &quot;segment&quot;, x =-5, y = 0.55, xend = 0.0, yend = .55, arrow = arrow(length = unit(2, &quot;mm&quot;)), color = colors[3]) + annotate(geom = &quot;text&quot;, x = -8, y = 0.55, label = paste(&quot;P(Y &lt;= 3)&quot;), parse = TRUE,hjust = &quot;left&quot;, color = colors[3]) + annotate(geom = &quot;segment&quot;, x =5, y = 0.65, xend = 2.75, yend = .65, arrow = arrow(length = unit(2, &quot;mm&quot;)) , color = colors[2]) + annotate(geom = &quot;text&quot;, x = 5, y = 0.65, label = paste(&quot;P(Y &lt;= 2)&quot;), parse = TRUE, hjust = &quot;left&quot;, color = colors[2]) + annotate(geom = &quot;segment&quot;, x =7.5, y = 0.75, xend = 5.25, yend = .75, arrow = arrow(length = unit(2, &quot;mm&quot;)) , color = colors[1]) + annotate(geom = &quot;text&quot;, x = 7.5, y = 0.75, label = paste(&quot;P(Y &lt;= 1)&quot;), parse = TRUE, hjust = &quot;left&quot;, color = colors[1]) \\[\\frac{P(Y \\le j\\ |\\ x = a) / P(Y &gt; j\\ |\\ x = a)}{P(Y \\le j\\ |\\ x = b) / P(Y &gt; j\\ |\\ x = b)}.\\] \\[\\begin{equation} \\mathrm{logit}[P(Y \\le j)] = \\alpha_j + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots + \\beta_p x_p,\\ j = 1, \\dots,\\ c-1 \\tag{14} \\end{equation}\\] 6.2.2 Example: Political Ideology and Political Party Affiliation Polviews &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Polviews.dat&quot;, header = TRUE, stringsAsFactors = TRUE) Polviews gender party y1 y2 y3 y4 y5 1 female dem 25 105 86 28 4 2 female repub 0 5 15 83 32 3 male dem 20 73 43 20 3 4 male repub 0 1 14 72 32 library(VGAM) # parallel = TRUE imposes proportional odds structure # 4 intercepts for 5 y categories fit &lt;- vglm(cbind(y1,y2,y3,y4,y5) ~ party + gender, family = cumulative(parallel = TRUE), data = Polviews) summary(fit) # same effects for all 4 logits Call: vglm(formula = cbind(y1, y2, y3, y4, y5) ~ party + gender, family = cumulative(parallel = TRUE), data = Polviews) Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept):1 -2.12233 0.16875 -12.577 &lt;2e-16 *** (Intercept):2 0.16892 0.11481 1.471 0.141 (Intercept):3 1.85716 0.15103 12.297 &lt;2e-16 *** (Intercept):4 4.65005 0.23496 19.791 &lt;2e-16 *** partyrepub -3.63366 0.21785 -16.680 &lt;2e-16 *** gendermale 0.04731 0.14955 0.316 0.752 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Names of linear predictors: logitlink(P[Y&lt;=1]), logitlink(P[Y&lt;=2]), logitlink(P[Y&lt;=3]), logitlink(P[Y&lt;=4]) Residual deviance: 9.8072 on 10 degrees of freedom Log-likelihood: -35.2032 on 10 degrees of freedom Number of Fisher scoring iterations: 4 No Hauck-Donner effect found in any of the estimates Exponentiated coefficients: partyrepub gendermale 0.02641936 1.04844945 \\[P(Y \\le j) = \\frac{\\mathrm{exp}(\\alpha_j + \\beta_1 x_1 + \\beta_2 x_2)}{1 + \\mathrm{exp}(\\alpha_j + \\beta_1 x_1 + \\beta_2 x_2)}.\\] \\[P(Y=3)= P(Y \\le 3) - P(Y \\le 2).\\] Polviews &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Polviews.dat&quot;, header = TRUE, stringsAsFactors = TRUE) # y1 = very lib, y5 = very conservative. data.frame(Polviews$gender, Polviews$party, round(fitted(fit), 4)) Polviews.gender Polviews.party y1 y2 y3 y4 y5 1 female dem 0.1069 0.4352 0.3228 0.1256 0.0095 2 female repub 0.0032 0.0272 0.1144 0.5895 0.2657 3 male dem 0.1115 0.4423 0.3165 0.1206 0.0090 4 male repub 0.0033 0.0284 0.1189 0.5927 0.2566 6.2.3 Inference about Cumulative Logit Model Parameters fit2 &lt;- vglm(cbind(y1,y2,y3,y4,y5) ~ gender, family = cumulative(parallel = TRUE), data = Polviews) VGAM::lrtest(fit, fit2) Likelihood ratio test Model 1: cbind(y1, y2, y3, y4, y5) ~ party + gender Model 2: cbind(y1, y2, y3, y4, y5) ~ gender #Df LogLik Df Chisq Pr(&gt;Chisq) 1 10 -35.203 2 11 -236.827 1 403.25 &lt; 2.2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 fit &lt;- vglm(cbind(y1,y2,y3,y4,y5) ~ party + gender, family = cumulative(parallel = TRUE), data = Polviews) # profile likelihood CIs for beta_1 and beta_2 in full model confint(fit, method = &quot;profile&quot;) 2.5 % 97.5 % (Intercept):1 -2.46596771 -1.8014863 (Intercept):2 -0.05464962 0.3937706 (Intercept):3 1.56835767 2.1616181 (Intercept):4 4.20347943 5.1226824 partyrepub -4.07163810 -3.2178566 gendermale -0.24638939 0.3414038 fit &lt;- vglm(cbind(y5,y4,y3,y2,y1) ~ party + gender, family = cumulative(parallel = TRUE), data = Polviews) library(tidyverse) confint(fit, method = &quot;profile&quot;) %&gt;% data.frame() %&gt;% rename(LCL= X2.5..) %&gt;% rename(UCL= X97.5..) %&gt;% rownames_to_column(var = &quot;Param&quot;) %&gt;% filter(Param == &quot;partyrepub&quot;) %&gt;% mutate(`LCL OR` = exp(LCL)) %&gt;% mutate(`UCL OR` = exp(UCL)) %&gt;% mutate(across(c(&quot;LCL&quot;, &quot;UCL&quot;), round, 3)) %&gt;% mutate(across(c(&quot;LCL OR&quot;, &quot;UCL OR&quot;), round, 1)) Param LCL UCL LCL OR UCL OR 1 partyrepub 3.218 4.072 25 58.7 6.2.4 Increased Power for Ordinal Analyses 6.2.5 Example: Happiness and Family Income Happy &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Happy.dat&quot;, header = TRUE, stringsAsFactors = TRUE) Happy income y1 y2 y3 1 1 37 90 45 2 2 25 93 56 3 3 6 18 13 fit &lt;- vglm(cbind(y1, y2, y3) ~ income, family = cumulative(parallel = TRUE), data = Happy) fit0 &lt;- vglm(cbind(y1, y2, y3) ~ 1, family = cumulative(parallel = TRUE), data = Happy) VGAM::lrtest(fit, fit0) Likelihood ratio test Model 1: cbind(y1, y2, y3) ~ income Model 2: cbind(y1, y2, y3) ~ 1 #Df LogLik Df Chisq Pr(&gt;Chisq) 1 3 -14.566 2 4 -16.121 1 3.109 0.07786 . --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 fit2 &lt;- vglm(cbind(y1, y2, y3) ~ factor(income), family = multinomial, data = Happy) fit0 &lt;- vglm(cbind(y1, y2, y3) ~ 1, family = multinomial, data = Happy) Warning in vglm.fitter(x = x, y = y, w = w, offset = offset, Xm2 = Xm2, : some quantities such as z, residuals, SEs may be inaccurate due to convergence at a half-step # baseline cat logit null model equivalent to cumulative logit null model VGAM::lrtest(fit2, fit0) Likelihood ratio test Model 1: cbind(y1, y2, y3) ~ factor(income) Model 2: cbind(y1, y2, y3) ~ 1 #Df LogLik Df Chisq Pr(&gt;Chisq) 1 0 -14.058 2 4 -16.121 4 4.1258 0.3892 6.2.6 Latent Variable Linear Models Imply Cumulative Link Models \\[y = j\\ \\mathrm{if}\\ \\alpha_{j-1} &lt; y^* \\le \\alpha_j.\\] \\[Y^* = \\beta_1 x_1 + \\beta_2 x_2 + \\cdots + \\beta_p x_p + \\epsilon,\\] \\[\\begin{equation} \\mathrm{link}[P(Y \\le j)] = \\alpha_j - \\beta_1 x_1 - \\beta_2 x_2 - \\cdots - \\beta_p x_p,\\ j = 1, \\dots,\\ c-1 \\tag{15} \\end{equation}\\] 6.2.7 Invariance to Choice of Response Categories 6.3 Cumulative Link Models: Model Checking and Extensions * 6.3.1 Checking Ordinal Model Goodness of Fit Polviews &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Polviews.dat&quot;, header = TRUE, stringsAsFactors = TRUE) library(VGAM) # parallel = TRUE imposes proportional odds structure # 4 intercepts for 5 y categories fit &lt;- vglm(cbind(y1,y2,y3,y4,y5) ~ party + gender, family = cumulative(parallel = TRUE), data = Polviews) fitWithInteraction &lt;- vglm(cbind(y1,y2,y3,y4,y5) ~ party + gender + party:gender, family = cumulative(parallel = TRUE), data = Polviews) VGAM::lrtest(fitWithInteraction, fit) Likelihood ratio test Model 1: cbind(y1, y2, y3, y4, y5) ~ party + gender + party:gender Model 2: cbind(y1, y2, y3, y4, y5) ~ party + gender #Df LogLik Df Chisq Pr(&gt;Chisq) 1 9 -34.526 2 10 -35.203 1 1.3544 0.2445 6.3.2 Cumulative Logit Model without Proportional Odds notParallel &lt;- summary(vglm(cbind(y1,y2,y3,y4,y5) ~ party + gender, family = cumulative, # parallel=FALSE by default data = Polviews)) parallel &lt;- summary(vglm(cbind(y1,y2,y3,y4,y5) ~ party + gender, family = cumulative(parallel=TRUE), data = Polviews)) VGAM::lrtest(notParallel, parallel) Likelihood ratio test Model 1: cbind(y1, y2, y3, y4, y5) ~ party + gender Model 2: cbind(y1, y2, y3, y4, y5) ~ party + gender #Df LogLik Df Chisq Pr(&gt;Chisq) 1 4 -32.093 2 10 -35.203 6 6.2211 0.3989 6.3.3 Simpler Interpretatoins Using Probabiliteis 6.3.4 Example: Modeling Mental Impairment \\[\\mathrm{logit}[P(Y \\le j)] = \\alpha_j - \\beta_1 x_1 - \\beta_2 x_2,\\] Mental &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Mental.dat&quot;, header = TRUE, stringsAsFactors = TRUE) Mental %&gt;% filter(row_number() %in% c(1, 2, n())) impair ses life 1 1 1 1 2 1 1 9 3 4 0 9 # polr() function requires response to be a factor y &lt;- factor(Mental$impair) fit &lt;- MASS::polr(y ~ life + ses, method = &quot;logistic&quot;, data = Mental) summary(fit) Re-fitting to get Hessian Call: MASS::polr(formula = y ~ life + ses, data = Mental, method = &quot;logistic&quot;) Coefficients: Value Std. Error t value life 0.3189 0.1210 2.635 ses -1.1112 0.6109 -1.819 Intercepts: Value Std. Error t value 1|2 -0.2819 0.6423 -0.4389 2|3 1.2128 0.6607 1.8357 3|4 2.2094 0.7210 3.0644 Residual Deviance: 99.0979 AIC: 109.0979 predict(fit, data.frame(ses = 0, life = mean(Mental$life)), type = &quot;probs&quot;) 1 2 3 4 0.1617811 0.3007047 0.2372921 0.3002222 predict(fit, data.frame(ses = 1, life = mean(Mental$life)), type = &quot;probs&quot;) 1 2 3 4 0.3696301 0.3536702 0.1529587 0.1237410 predict(fit, data.frame(ses = 0, life = min(Mental$life)), type = &quot;probs&quot;) 1 2 3 4 0.42998727 0.34080542 0.13029529 0.09891202 predict(fit, data.frame(ses = 0, life = max(Mental$life)), type = &quot;probs&quot;) 1 2 3 4 0.04102612 0.11914448 0.18048372 0.65934567 predict(fit, data.frame(ses = 1, life = min(Mental$life)), type = &quot;probs&quot;) 1 2 3 4 0.69621280 0.21463441 0.05428168 0.03487110 predict(fit, data.frame(ses = 1, life = max(Mental$life)), type = &quot;probs&quot;) 1 2 3 4 0.1150236 0.2518325 0.2439856 0.3891584 source(&quot;./ocAME.R&quot;) ocAME(fit) Re-fitting to get Hessian $ME.1 effect std.error z.value p.value life -0.057 0.019 -3.005 0.003 ses 0.198 0.104 1.913 0.056 $ME.4 effect std.error z.value p.value life 0.048 0.017 2.780 0.005 ses -0.171 0.094 -1.819 0.069 attr(,&quot;class&quot;) [1] &quot;ocAME&quot; 6.3.5 A Latent Variable Probability Comparison of Groups \\[\\hat P(Y_2^* &gt; Y_1^*) = \\mathrm{exp}(\\hat\\beta_2/\\sqrt{2})/[1 + \\mathrm{exp}(\\hat\\beta_2/\\sqrt{2})] = 0.31\\] 6.3.6 Cumulative Probit Model Polviews2 &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Polviews2.dat&quot;, header = TRUE, stringsAsFactors = TRUE) Polviews2 %&gt;% filter(row_number() %in% c(1, 2, n())) subject gender party ideology 1 1 female dem 1 2 2 female dem 1 3 661 male repub 5 y &lt;- factor(Polviews2$ideology) fit.probit &lt;- MASS::polr(y ~ party + gender, method = &quot;probit&quot;, data = Polviews2) summary(fit.probit) # same effects for all 4 logits Re-fitting to get Hessian Call: MASS::polr(formula = y ~ party + gender, data = Polviews2, method = &quot;probit&quot;) Coefficients: Value Std. Error t value partyrepub 2.032496 0.10996 18.48409 gendermale -0.007489 0.08562 -0.08747 Intercepts: Value Std. Error t value 1|2 -1.2353 0.0890 -13.8853 2|3 0.1033 0.0694 1.4901 3|4 1.0532 0.0808 13.0376 4|5 2.6171 0.1194 21.9153 Residual Deviance: 1565.195 AIC: 1577.195 6.3.7 \\(R^2\\) Based on Latent Variable Model \\[R_L^2 = \\frac{\\sum_i(y_i^* - \\bar y^*)^2 - \\sum_i(\\hat y_i^* - \\bar y^*)^2}{\\sum_i(y_i^* - \\bar y^*)^2} = \\frac{\\sum_i(\\hat y_i^* - \\bar y^*)^2}{\\sum_i(y_i^* - \\bar y^*)^2},\\] fit.logit &lt;- MASS::polr(y ~ party + gender, method = &quot;logistic&quot;, data = Polviews2) # lp = linear predictor # R-squared based on logistic latent variable model r &lt;- var(fit.logit$lp)/ (var(fit.logit$lp) + pi^2/3) r [1] 0.4869847 sqrt(r) [1] 0.6978429 var(fit.probit$lp) / (var(fit.probit$lp) + 1.0) [1] 0.494531 6.3.8 Bayesian Inference for Multinomial Models 6.3.9 Example: Modeling Mental Impairment Revisited Mental2 &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Mental2.dat&quot;, header = TRUE, stringsAsFactors = TRUE) Mental2 %&gt;% filter(row_number() %in% c(1, 2, n())) impair ses life 1 i1 0.5 1 2 i1 0.5 9 40 i4 -0.5 9 fit_freq &lt;- MASS::polr(impair ~ life + ses, method = &quot;logistic&quot;, data = Mental2) summary(fit_freq) Re-fitting to get Hessian Call: MASS::polr(formula = impair ~ life + ses, data = Mental2, method = &quot;logistic&quot;) Coefficients: Value Std. Error t value life 0.3189 0.1210 2.635 ses -1.1112 0.6109 -1.819 Intercepts: Value Std. Error t value i1|i2 0.2737 0.5756 0.4755 i2|i3 1.7684 0.6325 2.7958 i3|i4 2.7650 0.7147 3.8690 Residual Deviance: 99.0979 AIC: 109.0979 #install_github(&quot;tjmckinley/BayesOrd&quot;) library(BayesOrd) # mnb, varb are mean, var. of beta&#39;s; vart = var of intercepts fit &lt;- bayesord(impair ~ life + ses, fixed = TRUE, mnb = 0, varb = 100, niter = 1e+6, nchains = 2, start = 10000, data = Mental2) summary(fit, digits = 3) props &lt;- as.matrix(fit$beta) # posterior P(beta &gt; 0) for each effect parameter apply(props, 2, function(x)sum(x&gt; 0)/length(x)) 6.4 Paired-Category Logit Modeling of Ordinal Response * 6.4.1 Adjacent-Categories Logits \\[\\mathrm{log}\\left(\\frac{\\pi_j}{\\pi_{j+1}}\\right),\\ j = 1, \\dots, c-1.\\] \\[\\begin{equation} \\mathrm{log}\\left(\\frac{\\pi_j}{\\pi_{j+1}}\\right) = \\alpha_j + \\beta x,\\ j = 1, \\dots, c-1. \\tag{16} \\end{equation}\\] 6.4.2 Example: Political Ideology Revisited fit &lt;- vglm(cbind(y1,y2,y3,y4,y5) ~ party + gender, family = acat(parallel = TRUE, reverse = TRUE), data = Polviews) # family=acat gives adjacent-category logits summary(fit) Call: vglm(formula = cbind(y1, y2, y3, y4, y5) ~ party + gender, family = acat(parallel = TRUE, reverse = TRUE), data = Polviews) Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept):1 -1.38707 0.17079 -8.121 4.61e-16 *** (Intercept):2 0.36218 0.11749 3.083 0.00205 ** (Intercept):3 0.77529 0.14720 5.267 1.39e-07 *** (Intercept):4 2.99240 0.23132 12.936 &lt; 2e-16 *** partyrepub -2.23478 0.16841 -13.270 &lt; 2e-16 *** gendermale 0.01212 0.09661 0.125 0.90016 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Names of linear predictors: loglink(P[Y=1]/P[Y=2]), loglink(P[Y=2]/P[Y=3]), loglink(P[Y=3]/P[Y=4]), loglink(P[Y=4]/P[Y=5]) Residual deviance: 13.4665 on 10 degrees of freedom Log-likelihood: -37.0329 on 10 degrees of freedom Number of Fisher scoring iterations: 4 Warning: Hauck-Donner effect detected in the following estimate(s): &#39;partyrepub&#39; pValue &lt;- 1 - pchisq(13.47, 10) format(round(pValue, 8), scientific = FALSE) [1] &quot;0.1985672&quot; 6.4.3 Sequential Logits 6.4.4 Example: Tonsil Size and Streptococcus Tonsils &lt;- tibble(carrier = c(&quot;yes&quot;, &quot;no&quot;), y1 = c(19, 497), y2 = c(29, 560), y3 = c(24, 269)) fit &lt;- vglm(cbind(y1, y2, y3) ~ carrier, family = sratio(parallel = TRUE), data = Tonsils) summary(fit) Call: vglm(formula = cbind(y1, y2, y3) ~ carrier, family = sratio(parallel = TRUE), data = Tonsils) Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept):1 -0.51102 0.05614 -9.102 &lt; 2e-16 *** (Intercept):2 0.73218 0.07286 10.049 &lt; 2e-16 *** carrieryes -0.52846 0.19775 -2.672 0.00753 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Names of linear predictors: logitlink(P[Y=1|Y&gt;=1]), logitlink(P[Y=2|Y&gt;=2]) Residual deviance: 0.0057 on 1 degrees of freedom Log-likelihood: -11.7659 on 1 degrees of freedom Number of Fisher scoring iterations: 3 No Hauck-Donner effect found in any of the estimates "],["Loglinear.html", "7 Loglinear Models for Contingency Tables and Counts 7.1 Loglinear Models for Counts in Contingency Tables 7.2 Statistical Inference for Loglinear Models 7.3 The Loglinear - Logistic Model Connection 7.4 Independence Graphs and Collapsibility 7.5 Modeling Ordinal Associations in Contingency Tables 7.6 Loglinear Modeling of Count Response Variables *", " 7 Loglinear Models for Contingency Tables and Counts 7.1 Loglinear Models for Counts in Contingency Tables \\[\\pi_{ij} = P(X=i)P(Y=j) = \\pi_{i+}\\pi_{+j},\\ i = 1, \\dots, r,\\ j = 1, \\dots, c.\\] 7.1.1 Loglinear Model of Independence for Two-Way Contingency Tables \\[\\begin{equation} P(Y=1) = \\mathrm{log}\\mu_{ij} = \\lambda + \\lambda_i^X + \\lambda_j^Y, \\tag{17} \\end{equation}\\] 7.1.2 Interpretation of Parameters in the Independence Model 7.1.3 Example: Happiness and Belief in Heaven HappyHeaven &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/HappyHeaven.dat&quot;, header = TRUE, stringsAsFactors = TRUE) HappyHeaven happy heaven count 1 not no 32 2 not yes 190 3 pretty no 113 4 pretty yes 611 5 very no 51 6 very yes 326 with(HappyHeaven, questionr::wtd.table(happy, heaven, weight = count) ) no yes not 32 190 pretty 113 611 very 51 326 # canonical link for Poisson is log, so &quot;(link = log)&quot; is not necessary # loglm() function in MASS library also fits loglinear models fit &lt;- glm(count ~ happy + heaven, family = poisson, data = HappyHeaven) summary(fit) Call: glm(formula = count ~ happy + heaven, family = poisson, data = HappyHeaven) Deviance Residuals: 1 2 3 4 5 6 -0.15570 0.06459 0.54947 -0.23152 -0.65897 0.27006 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) 3.49313 0.09408 37.13 &lt; 2e-16 *** happypretty 1.18211 0.07672 15.41 &lt; 2e-16 *** happyvery 0.52957 0.08460 6.26 3.86e-10 *** heavenyes 1.74920 0.07739 22.60 &lt; 2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for poisson family taken to be 1) Null deviance: 1019.87238 on 5 degrees of freedom Residual deviance: 0.89111 on 2 degrees of freedom AIC: 49.504 Number of Fisher Scoring iterations: 3 7.1.4 Saturated Model for Two-Way Contingency Tables \\[ \\mathrm{log}\\mu_{ij} = \\lambda + \\lambda_i^X + \\lambda_j^Y + \\lambda_{ij}^{XY} \\] \\[\\mathrm{log}\\theta = \\mathrm{log}\\big( \\frac{\\mu_{11}\\mu_{22}}{\\mu_{12}\\mu_{21}}\\big) = \\mathrm{log}\\mu_{11} + \\mathrm{log}\\mu_{22} - \\mathrm{log}\\mu_{12} - \\mathrm{log}\\mu_{21}.\\] 7.1.5 Loglinear Models for Three-Way Contingency Tables \\[\\mathrm{log}\\mu_{ijk} =\\lambda + \\lambda_i^X+ \\lambda_j^Y + \\lambda_k^Z +\\lambda_{ik}^{XZ} + +\\lambda_{jk}^{YZ}.\\] \\[\\mathrm{log}\\mu_{ijk} =\\lambda + \\lambda_i^X+ \\lambda_j^Y + \\lambda_k^Z + \\lambda_{ij}^{XY} +\\lambda_{ik}^{XZ} + +\\lambda_{jk}^{YZ}.\\] 7.1.6 Two-Factor Parameters Describe Conditional Associations 7.1.7 Example: Student Alcohol, Cigarette, and Marijuana Use Drugs &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Substance.dat&quot;, header = TRUE, stringsAsFactors = TRUE) Drugs &lt;- Drugs %&gt;% rename(A = &quot;alcohol&quot;) %&gt;% rename(C = &quot;cigarettes&quot;) %&gt;% rename(M = &quot;marijuana&quot;) `Table 7.1` &lt;- bind_cols(`Alcohol Use` = c(&quot;Yes&quot;, &quot;&quot;, &quot;No&quot;, &quot;&quot;), `Defendants&#39; Race` = rep(c(&quot;Yes&quot;, &quot;No&quot;),2), matrix(Drugs$count, ncol = 2,byrow = T, dimnames = list(NULL, c(&quot;Marijuana Use (Yes)&quot;, &quot;Marijuana Use (No)&quot;)))) knitr::kable(`Table 7.1`) Alcohol Use Defendants’ Race Marijuana Use (Yes) Marijuana Use (No) Yes Yes 911 538 No 44 456 No Yes 3 43 No 2 279 A_C_M &lt;- glm(count ~ A + C + M, family = poisson, data = Drugs) `(A, C, M)` &lt;- round(exp(predict(A_C_M, data.frame(Drugs))), 1) AM_CM &lt;- glm(count ~ A + C + M + A:M + C:M, family = poisson, data = Drugs) `(AM, CM)` &lt;- round(exp(predict(AM_CM, data.frame(Drugs))), 2) AC_AM_CM &lt;- glm(count ~ A + C + M + A:C + A:M + C:M, family = poisson, data = Drugs) `(AC, AM, CM)` &lt;- round(exp(predict(AC_AM_CM, data.frame(Drugs))), 1) ACM &lt;- glm(count ~ A + C + M + A:C + A:C + A:M + C:M + A:C:M, family = poisson, data = Drugs) `(ACM)` &lt;- round(exp(predict(ACM, data.frame(Drugs))), 1) `Table 7.2` &lt;- bind_cols(`Alcohol Use` = c(&quot;Yes&quot;, rep(&quot;&quot;, 3), &quot;No&quot;, rep(&quot;&quot;,3)), `Cigarette Use` = rep(c(&quot;Yes&quot;, &quot; &quot;, &quot;No&quot;, &quot;&quot;),2), `Marijuana Use` = rep(c(&quot;Yes&quot;, &quot;No&quot;), 4), `(A, C, M)` = `(A, C, M)`, `(AM, CM)` = `(AM, CM)`, `(AC, AM, CM)` = `(AC, AM, CM)`, `(ACM)` = `(ACM)`) knitr::kable(`Table 7.2`) Alcohol Use Cigarette Use Marijuana Use (A, C, M) (AM, CM) (AC, AM, CM) (ACM) Yes Yes Yes 540.0 909.24 910.4 911 No 740.2 438.84 538.6 538 No Yes 282.1 45.76 44.6 44 No 386.7 555.16 455.4 456 No Yes Yes 90.6 4.76 3.6 3 No 124.2 142.16 42.4 43 No Yes 47.3 0.24 1.4 2 No 64.9 179.84 279.6 279 # Table 7.3 line2 &lt;- round(exp(coef(AM_CM)[c(&quot;Ayes:Myes&quot;, &quot;Cyes:Myes&quot;)]), 1) line3 &lt;- round(exp(coef(AC_AM_CM)[c(&quot;Ayes:Cyes&quot;, &quot;Ayes:Myes&quot;, &quot;Cyes:Myes&quot;)]), 1) line4 &lt;- round(exp(coef(ACM)[c(&quot;Ayes:Cyes&quot;, &quot;Ayes:Myes&quot;, &quot;Cyes:Myes&quot;)]), 1) `Table 7.3` &lt;- bind_cols(Model = c(&quot;(A, C, M)&quot;, &quot;(AM, CM)&quot;, &quot;(AC, AM, CM)&quot;, &quot;(ACM)&quot;), matrix(c(rep (1.0, 3), 1.0, line2[&quot;Ayes:Myes&quot;], line2[&quot;Cyes:Myes&quot;], line3[&quot;Ayes:Cyes&quot;], line3[&quot;Ayes:Myes&quot;], line3[&quot;Cyes:Myes&quot;], line4[&quot;Ayes:Cyes&quot;], line4[&quot;Ayes:Myes&quot;], line4[&quot;Cyes:Myes&quot;]), ncol = 3, byrow = T, dimnames = list(NULL, c(&quot;AC&quot;, &quot;AM&quot;, &quot;CM&quot;)))) knitr::kable(`Table 7.3`) Model AC AM CM (A, C, M) 1.0 1.0 1.0 (AM, CM) 1.0 61.9 25.1 (AC, AM, CM) 7.8 19.8 17.3 (ACM) 7.7 13.5 9.7 \\[2.7 = \\frac{(909.24 + 438.84)*(0.24 + 179.84)}{(45.76 + 555.16)*(4.76 + 142.16)}.\\] AM_CM &lt;- glm(count ~ A + C + M + A:M + C:M, family = poisson, data = Drugs) round(exp(predict(AM_CM, data.frame(Drugs))), 2) # Table 7.2 round(exp(coef(AM_CM)), 1) # Table 7.3 is2.7 &lt;- ((909.2395833 + 438.8404255)*(0.2395833 + 179.8404255)) / ((45.7604167 + 555.1595745)*(4.7604167 + 142.1595745)) # collapse over M AC &lt;- Drugs %&gt;% group_by(A, C) %&gt;% summarise(Count2 = sum(count), .groups = &quot;drop_last&quot;) AC_marginal &lt;- glm(Count2 ~ A + C + A:C, family = poisson, data = AC) round(exp(predict(AC_marginal, data.frame(AC))), 2) round(exp(coef(AC_marginal)), 5) (1449*281)/(500*46) Drugs &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Substance.dat&quot;, header = TRUE, stringsAsFactors = TRUE) Drugs %&gt;% filter(row_number() %in% c(1, n())) alcohol cigarettes marijuana count 1 yes yes yes 911 2 no no no 279 Drugs &lt;- Drugs %&gt;% rename(A = &quot;alcohol&quot;) %&gt;% rename(C = &quot;cigarettes&quot;) %&gt;% rename(M = &quot;marijuana&quot;) #A &lt;- Drugs$alcohol #C &lt;- Drugs$cigarettes #M &lt;- Drugs$marijuana fit &lt;- glm(count ~ A + C + M + A:C + A:M + C:M, family = poisson, data = Drugs) summary(fit) Call: glm(formula = count ~ A + C + M + A:C + A:M + C:M, family = poisson, data = Drugs) Deviance Residuals: 1 2 3 4 5 6 7 8 0.02044 -0.02658 -0.09256 0.02890 -0.33428 0.09452 0.49134 -0.03690 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) 5.63342 0.05970 94.361 &lt; 2e-16 *** Ayes 0.48772 0.07577 6.437 1.22e-10 *** Cyes -1.88667 0.16270 -11.596 &lt; 2e-16 *** Myes -5.30904 0.47520 -11.172 &lt; 2e-16 *** Ayes:Cyes 2.05453 0.17406 11.803 &lt; 2e-16 *** Ayes:Myes 2.98601 0.46468 6.426 1.31e-10 *** Cyes:Myes 2.84789 0.16384 17.382 &lt; 2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for poisson family taken to be 1) Null deviance: 2851.46098 on 7 degrees of freedom Residual deviance: 0.37399 on 1 degrees of freedom AIC: 63.417 Number of Fisher Scoring iterations: 4 7.2 Statistical Inference for Loglinear Models 7.2.1 Chi-Squared Goodness-of-Fit Tests # p-value for the (AC, AM, CM) model AC_AM &lt;- glm(count ~ A + C + M + A:C + A:M, family = poisson, data = Drugs) AC_CM &lt;- glm(count ~ A + C + M + A:C + C:M, family = poisson, data = Drugs) AM_CM &lt;- glm(count ~ A + C + M + A:M + C:M, family = poisson, data = Drugs) AC_AM_CM &lt;- glm(count ~ A + C + M + A:C + A:M + C:M, family = poisson, data = Drugs) # function to convert to a p-value and return &quot;&lt; 0.0...&quot; with a digit threshold residualP &lt;- function(x, digits = 2){ pValue &lt;- 1 - pchisq(deviance(x), df.residual(x)) value &lt;- format(round(pValue, digits), scientific = FALSE) if(value == 0) { paste0(&quot;&lt; 0.&quot;, strrep(&quot;0&quot;, digits-1), &quot;1&quot;) } else { value } } `Table 7.4` &lt;- bind_cols(Model = c(&quot;(AC, AM)&quot;, &quot;(AC, CM)&quot;, &quot;(AM, CM)&quot;, &quot;(AC, AM, CM)&quot;), Deviance = c(deviance(AC_AM), deviance(AC_CM), deviance(AM_CM), deviance(AC_AM_CM)), df = c(df.residual(AC_AM), df.residual(AC_CM), df.residual(AC_AM), df.residual(AC_AM_CM)), `P-value` = c(residualP(AC_AM, 4), residualP(AC_CM, 4), residualP(AC_AM, 4), residualP(AC_AM_CM))) %&gt;% mutate(Deviance = round(Deviance, 1)) kable(`Table 7.4`) Model Deviance df P-value (AC, AM) 497.4 2 &lt; 0.0001 (AC, CM) 92.0 2 &lt; 0.0001 (AM, CM) 187.8 2 &lt; 0.0001 (AC, AM, CM) 0.4 1 0.54 7.2.2 Cell Standardized Residuals for Loglinear Models fit &lt;- glm(count ~ A + C + M + A:C + A:M + C:M, family = poisson, data = Drugs) fit2 &lt;- glm(count ~ A + C + M + A:M + C:M, family = poisson, data = Drugs) deviance(fit) [1] 0.3739859 deviance(fit2) [1] 187.7543 res &lt;- round(rstandard(fit, type = &quot;pearson&quot;), 3) res2 &lt;- round(rstandard(fit2, type = &quot;pearson&quot;), 3) tibble(Alcohol = Drugs$A, Cigarettes = Drugs$C, Marijuana = Drugs$M, Count = Drugs$count, &quot;Fitted from fit&quot; = fitted(fit), &quot;Std. Resid. from fit&quot; = rstandard(fit, type = &quot;pearson&quot;), &quot;Fitted from fi2&quot; = fitted(fit2), &quot;Std. Resid. from fit2&quot; = rstandard(fit2, type = &quot;pearson&quot;)) %&gt;% mutate(across(contains(&quot;fit&quot;), round, 3)) # A tibble: 8 x 8 Alcohol Cigarettes Marijuana Count `Fitted from fi… `Std. Resid. fr… &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; 1 yes yes yes 911 910. 0.633 2 yes yes no 538 539. -0.633 3 yes no yes 44 44.6 -0.633 4 yes no no 456 455. 0.633 5 no yes yes 3 3.62 -0.633 6 no yes no 43 42.4 0.633 7 no no yes 2 1.38 0.633 8 no no no 279 280. -0.633 # … with 2 more variables: `Fitted from fi2` &lt;dbl&gt;, `Std. Resid. from # fit2` &lt;dbl&gt; 7.2.3 Significance Tests about Conditional Associations library(car) Anova(fit) Analysis of Deviance Table (Type II tests) Response: count LR Chisq Df Pr(&gt;Chisq) A 1281.71 1 &lt; 2.2e-16 *** C 227.81 1 &lt; 2.2e-16 *** M 55.91 1 7.575e-14 *** A:C 187.38 1 &lt; 2.2e-16 *** A:M 91.64 1 &lt; 2.2e-16 *** C:M 497.00 1 &lt; 2.2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 7.2.4 Confidence Intervals for Conditional Odds Ratios fit &lt;- glm(count ~ A + C + M + A:C + A:M + C:M, family = poisson, data = Drugs) summary(fit) Call: glm(formula = count ~ A + C + M + A:C + A:M + C:M, family = poisson, data = Drugs) Deviance Residuals: 1 2 3 4 5 6 7 8 0.02044 -0.02658 -0.09256 0.02890 -0.33428 0.09452 0.49134 -0.03690 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) 5.63342 0.05970 94.361 &lt; 2e-16 *** Ayes 0.48772 0.07577 6.437 1.22e-10 *** Cyes -1.88667 0.16270 -11.596 &lt; 2e-16 *** Myes -5.30904 0.47520 -11.172 &lt; 2e-16 *** Ayes:Cyes 2.05453 0.17406 11.803 &lt; 2e-16 *** Ayes:Myes 2.98601 0.46468 6.426 1.31e-10 *** Cyes:Myes 2.84789 0.16384 17.382 &lt; 2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for poisson family taken to be 1) Null deviance: 2851.46098 on 7 degrees of freedom Residual deviance: 0.37399 on 1 degrees of freedom AIC: 63.417 Number of Fisher Scoring iterations: 4 exp(confint(fit)) Waiting for profiling to be done... 2.5 % 97.5 % (Intercept) 2.481623e+02 313.62395491 Ayes 1.404993e+00 1.89112888 Cyes 1.087964e-01 0.20616472 Myes 1.700562e-03 0.01136462 Ayes:Cyes 5.601452e+00 11.09714777 Ayes:Myes 8.814046e+00 56.64359514 Cyes:Myes 1.264576e+01 24.06925090 Caution: Notice the LCL is in scientific notation and UCL is not. 7.2.5 Bayesian Fitting of Loglinear Models # library(MCMCpack) fitBayes &lt;- MCMCpack::MCMCpoisson(count ~ A + C + M + A:C + A:M + C:M, family = poisson, data = Drugs) summary(fitBayes) Iterations = 1001:11000 Thinning interval = 1 Number of chains = 1 Sample size per chain = 10000 1. Empirical mean and standard deviation for each variable, plus standard error of the mean: Mean SD Naive SE Time-series SE (Intercept) 5.6317 0.06074 0.0006074 0.002972 Ayes 0.4887 0.07724 0.0007724 0.003819 Cyes -1.9087 0.16429 0.0016429 0.008122 Myes -5.4132 0.52796 0.0052796 0.028710 Ayes:Cyes 2.0777 0.17597 0.0017597 0.008503 Ayes:Myes 3.0854 0.51755 0.0051755 0.028275 Cyes:Myes 2.8521 0.16623 0.0016623 0.008234 2. Quantiles for each variable: 2.5% 25% 50% 75% 97.5% (Intercept) 5.514 5.5910 5.6335 5.6734 5.7516 Ayes 0.341 0.4368 0.4876 0.5405 0.6403 Cyes -2.236 -2.0164 -1.9130 -1.7984 -1.5781 Myes -6.630 -5.7281 -5.3880 -5.0329 -4.5381 Ayes:Cyes 1.724 1.9634 2.0824 2.1995 2.4190 Ayes:Myes 2.200 2.7239 3.0505 3.3822 4.2256 Cyes:Myes 2.542 2.7370 2.8498 2.9643 3.1767 # posterior prob. that AM log odds ratio &lt; 0 # (parameter 6 in model is AM log odds ratio) mean(fitBayes[, 6] &lt; 0) [1] 0 7.2.6 Loglinear Models for Higher-Dimensional Contingency Tables 7.2.7 Example: Automobile Accidents and Seat Belts 7.2.8 Interpreting Three-Factor Interaction Terms Accidents &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Accidents2.dat&quot;, header = TRUE, stringsAsFactors = TRUE) Accidents %&gt;% filter(row_number() %in% c(1, n())) gender location seatbelt injury count 1 female rural no no 3246 2 male urban yes yes 380 Accidents &lt;- Accidents %&gt;% rename(&quot;G&quot; = gender, &quot;L&quot; = location, &quot;S&quot; = seatbelt, &quot;I&quot; = injury) # G*I = G + I + G:I fit &lt;- glm(count ~ G*L*S + G*I + L*I + S*I, family = poisson, data = Accidents) summary(fit) Call: glm(formula = count ~ G * L * S + G * I + L * I + S * I, family = poisson, data = Accidents) Deviance Residuals: 1 2 3 4 5 6 7 8 -0.15190 0.27851 0.51823 -1.44646 0.16160 -0.43483 -0.42327 1.69037 9 10 11 12 13 14 15 16 -0.34700 0.83292 -0.05675 0.20564 0.21675 -0.76754 0.09329 -0.49684 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) 8.08784 0.01654 488.884 &lt; 2e-16 *** Gmale 0.63640 0.02015 31.579 &lt; 2e-16 *** Lurban 0.80411 0.01966 40.891 &lt; 2e-16 *** Syes 0.62713 0.02027 30.940 &lt; 2e-16 *** Iyes -1.21640 0.02649 -45.918 &lt; 2e-16 *** Gmale:Lurban -0.28274 0.02441 -11.584 &lt; 2e-16 *** Gmale:Syes -0.54186 0.02590 -20.925 &lt; 2e-16 *** Lurban:Syes -0.15752 0.02441 -6.453 1.09e-10 *** Gmale:Iyes -0.54483 0.02727 -19.982 &lt; 2e-16 *** Lurban:Iyes -0.75806 0.02697 -28.105 &lt; 2e-16 *** Syes:Iyes -0.81710 0.02765 -29.551 &lt; 2e-16 *** Gmale:Lurban:Syes 0.12858 0.03228 3.984 6.78e-05 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for poisson family taken to be 1) Null deviance: 61709.5207 on 15 degrees of freedom Residual deviance: 7.4645 on 4 degrees of freedom AIC: 184.92 Number of Fisher Scoring iterations: 3 7.2.9 Statistical Versus Practical Significance: Dissimilarity Index \\[D = \\sum |n_i - \\hat\\mu_i|/2n = \\sum |p_i - \\hat\\pi_i|/2.\\] fit &lt;- glm(count ~ G*L*S + G*I + L*I + S*I, family = poisson, data = Accidents) # dissimilarity index for loglinear model (GLS, GI, LI, SI) DI &lt;- sum(abs(Accidents$count - fitted(fit)))/(2*sum(Accidents$count)) round(DI, 5) [1] 0.00251 fit2 &lt;- glm(count ~ G*L + G*S + G*I + L*S + L*I + S*I, family = poisson, data = Accidents) # dissimilarity index for loglinear model (GLS, GI, LI, SI) DI2 &lt;- sum(abs(Accidents$count - fitted(fit2)))/(2*sum(Accidents$count)) round(DI2, 5) [1] 0.00822 7.3 The Loglinear - Logistic Model Connection 7.3.1 Using Logistic Models to Interpret Loglinear Models 7.3.2 Example: Auto Accident Data Revisited \\[\\begin{equation} \\mathrm{logit}[P(I=1)]=\\alpha + \\beta_g^G + \\beta_l^L + \\beta_s^S. \\tag{18} \\end{equation}\\] Injury &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Injury_binom.dat&quot;, header = TRUE, stringsAsFactors = TRUE) # 8 lines in data file, one for each binomial on injury given (G, L, S) Injury %&gt;% filter(row_number() %in% c(1, 2, n())) gender location seatbelt no yes 1 female urban no 7287 996 2 female urban yes 11587 759 3 male rural yes 6693 513 Injury &lt;- Injury %&gt;% rename(&quot;G&quot; = gender, &quot;L&quot; = location, &quot;S&quot; = seatbelt) fit2 &lt;- glm(yes/(no + yes) ~ G + L + S, family = binomial, weights = no+yes, data = Injury) summary(fit2) Call: glm(formula = yes/(no + yes) ~ G + L + S, family = binomial, data = Injury, weights = no + yes) Deviance Residuals: 1 2 3 4 5 6 7 8 -0.4639 1.7426 0.3172 -1.5365 -0.7976 -0.5055 0.9023 0.2133 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -1.21640 0.02649 -45.92 &lt;2e-16 *** Gmale -0.54483 0.02727 -19.98 &lt;2e-16 *** Lurban -0.75806 0.02697 -28.11 &lt;2e-16 *** Syes -0.81710 0.02765 -29.55 &lt;2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 1912.4532 on 7 degrees of freedom Residual deviance: 7.4645 on 4 degrees of freedom AIC: 82.167 Number of Fisher Scoring iterations: 3 7.3.3 Condition for Equivalent Loglinear and Logistic Models 7.3.4 Loglinear/Logistic Model Selection Issues 7.4 Independence Graphs and Collapsibility 7.4.1 Independence Graphs library(igraph) # pairs of vertices to connect g &lt;- graph(c(&quot;W&quot;,&quot;X&quot;, &quot;Y&quot;,&quot;Z&quot;, &quot;Y&quot;,&quot;W&quot;, &quot;Z&quot;,&quot;W&quot;), directed = FALSE) LO &lt;- layout_nicely(g) # original layout angle &lt;- 2*pi * 7.495/12 # amount of clock face to rotate RotMat &lt;- matrix(c(cos(angle),sin(angle),-sin(angle), cos(angle)), ncol=2) LO2 &lt;- LO %*% RotMat plot(g, vertex.shape = &quot;none&quot;, layout = LO2) # Manually draw the plot tibble(x = c(0, 1, 2, 2, 1), y = c(0, 0, 1, -1, 0), name = c(&quot;X&quot;, &quot;W&quot;, &quot;Y&quot;, &quot;Z&quot;, &quot;W&quot;) ) %&gt;% ggplot(aes(x = x, y = y)) + geom_path() + geom_point(size = 8, color = &quot;white&quot;) + theme_void() + geom_text(aes(label=name), hjust= .5, vjust= .4) tibble(x = c(0, 1, 2, 3), y = c(0, 0, 0, 0), name = c(&quot;W&quot;, &quot;X&quot;, &quot;Y&quot;, &quot;Z&quot;) ) %&gt;% ggplot(aes(x = x, y = y)) + geom_path() + geom_point(size = 8, color = &quot;white&quot;) + theme_void() + geom_text(aes(label=name), hjust= .5, vjust= .4) 7.4.2 Collapsibility Conditions for Contingency Tables tibble(x = c(0, 1, 2), y = c(0, 0, 0), name = c(&quot;A&quot;, &quot;M&quot;, &quot;C&quot;) ) %&gt;% ggplot(aes(x = x, y = y)) + geom_path() + geom_point(size = 8, color = &quot;white&quot;) + theme_void() + geom_text(aes(label=name), hjust= .5, vjust= .4) tibble(x = c(0, 1, 2), y = c(0, 0, 0), name = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;) ) %&gt;% ggplot(aes(x = x, y = y)) + geom_path() + geom_point(size = 8, color = &quot;white&quot;) + theme_void() + geom_text(aes(label=name), hjust= .5, vjust= .4) 7.4.3 Example: Loglinear Model Building for Student Substance Use Drugs2 &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Substance2.dat&quot;, header = TRUE, stringsAsFactors = TRUE) library(dplyr) `Table 7.5` &lt;- bind_cols(`Alcohol Use` = c(&quot;Yes&quot;, &quot;&quot;, &quot;No&quot;, &quot;&quot;), `Cigarette Use` = rep(c(&quot;Yes&quot;, &quot;No&quot;),2), matrix(Drugs2$count, ncol = 8,byrow = T, dimnames = list(NULL, c(&quot;Y_F_W&quot;, &quot;N_F_W&quot;, &quot;Y_M_W&quot;, &quot;N_M_W&quot;, # Yes/No Female/Male whites &quot;Y_F_O&quot;, &quot;N_F_O&quot;, &quot;Y_M_O&quot;, &quot;N_M_O&quot;)))) # whites #knitr::kable(`Table 7.5`) library(flextable) my_header &lt;- data.frame( col_keys= colnames(`Table 7.5`), line1 = c(&quot;Alcohol Use&quot;, &quot;Cigarette Use&quot;, rep(&quot;Marijuna Use&quot;, 8)), line2 = c(&quot;Alcohol Use&quot;, &quot;Cigarette Use&quot;, rep(&quot;White&quot;, 4), rep(&quot;Other&quot;, 4)), line3 = c(&quot;Alcohol Use&quot;, &quot;Cigarette Use&quot;, rep(c(rep(&quot;Female&quot;, 2), rep(&quot;Male&quot;, 2)),2)), line4 = c(&quot;Alcohol Use&quot;, &quot;Cigarette Use&quot;, rep(c(&quot;Yes&quot;, &quot;No&quot;), 4)) ) flextable(`Table 7.5`) %&gt;% set_header_df( mapping = my_header, key = &quot;col_keys&quot; ) %&gt;% theme_booktabs() %&gt;% merge_v(part = &quot;header&quot;) %&gt;% merge_h(part = &quot;header&quot;) %&gt;% align(align = &quot;center&quot;, part = &quot;all&quot;) .tabwid table{ border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 5px; margin-bottom: 5px; table-layout: fixed; border-spacing: 0; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-380c3ebe{border-collapse:collapse;}.cl-3807a3b8{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-3807b0d8{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:3pt;padding-top:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;}.cl-3807e580{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3807e59e{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3807e5a8{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3807e5b2{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3807e5bc{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Alcohol UseCigarette UseMarijuna UseWhiteOtherFemaleMaleFemaleMaleYesNoYesNoYesNoYesNoYesYes40526845322823233019No1321828201219118NoYes1171170118No11171133012017 Drugs2 &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Substance2.dat&quot;, header = TRUE, stringsAsFactors = TRUE) #A &lt;- Drugs$alcohol #C &lt;- Drugs$cigarettes #M &lt;- Drugs$marijuana fit1 &lt;- glm(count ~ A + C + M + R + G + G:R, family = poisson, data = Drugs2) fit2 &lt;- glm(count ~ (A + C + M + R + G)^2, family = poisson, data = Drugs2) fit3 &lt;- glm(count ~ (A + C + M + R + G)^3, family = poisson, data = Drugs2) fit4 &lt;- glm(count ~ A + C + M + R + G + A:C + A:M + C:G + C:M + A:G + A:R + G:M + G:R + M:R, family = poisson, data = Drugs2) fit5 &lt;- glm(count ~ A + C + M + R + G + A:C + A:M + C:M + A:G + A:R + G:M + G:R + M:R, family = poisson, data = Drugs2) fit6 &lt;- glm(count ~ A + C + M + R + G + A:C + A:M + C:M + A:G + A:R + G:M + G:R, family = poisson, data = Drugs2) # summary(fit1) # summary(fit2) # summary(fit3) # summary(fit4) # summary(fit5) # summary(fit6) `Table 7.9` &lt;- tibble(Model = c(&quot;1. Mutual independence + GR&quot;, &quot;2. Homogeneous association&quot;, &quot;3. All three-factor terms&quot;, &quot;4. AC, AM, CG, CM, AG, AR, GM, GR, MR&quot;, &quot;5. AC, AM, CM, AG, AR, GM, GR, MR&quot;, &quot;6. AC, AM, CM, AG, AR, GM, GR&quot;), Deviance = c(deviance(fit1), deviance(fit2), deviance(fit3), deviance(fit4), deviance(fit5), deviance(fit6)), df = c(df.residual(fit1), df.residual(fit2), df.residual(fit3), df.residual(fit4), df.residual(fit5), df.residual(fit6))) %&gt;% mutate(Deviance = round(Deviance, 2)) `Table 7.9` # A tibble: 6 x 3 Model Deviance df &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; 1 1. Mutual independence + GR 1325. 25 2 2. Homogeneous association 15.3 16 3 3. All three-factor terms 5.27 6 4 4. AC, AM, CG, CM, AG, AR, GM, GR, MR 15.8 17 5 5. AC, AM, CM, AG, AR, GM, GR, MR 16.7 18 6 6. AC, AM, CM, AG, AR, GM, GR 19.9 19 7.4.4 Collapsibility and Logistic Models 7.5 Modeling Ordinal Associations in Contingency Tables Teenagers &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Teenagers.dat&quot;, header = TRUE, stringsAsFactors = TRUE) %&gt;% mutate(`Premarital Sex` = recode_factor(sex, &quot;1&quot; = &quot;Always wrong&quot;, &quot;2&quot; = &quot;Almost always wrong&quot;, &quot;3&quot; = &quot;Wrong only sometimes&quot;, &quot;4&quot; = &quot;Not wrong at all&quot;)) %&gt;% mutate(`Teenage Birth Control` = recode_factor(birth, &quot;1&quot; = &quot;Strongly Disagree&quot;, &quot;2&quot; = &quot;Disagree&quot;, &quot;3&quot; = &quot;Agree&quot;, &quot;4&quot; = &quot;Strongly Agree&quot;)) fit &lt;- glm(count ~ factor(sex) + factor(birth), family=poisson, data = Teenagers) #summary(fit) # shows Residual deviance: 127.65 on 9 degrees of freedom #fitted(fit) fitLinear &lt;- glm(count ~ factor(sex) + factor(birth) + sex:birth, family=poisson, data = Teenagers) # summary(fitLinear) # Residual deviance: 11.534 on 8 degrees of freedom #fitted(fitLinear) # raw data # xtabs(Teenagers$count ~ Teenagers$sex + Teenagers$birth) with(Teenagers, xtabs(count ~ `Premarital Sex` + `Teenage Birth Control`)) Teenage Birth Control Premarital Sex Strongly Disagree Disagree Agree Strongly Agree Always wrong 81 68 60 38 Almost always wrong 24 26 29 14 Wrong only sometimes 18 41 74 42 Not wrong at all 36 57 161 157 TeenagersPlus &lt;- bind_cols(Teenagers, independence = round(fitted(fit), 1), linear = round(fitted(fitLinear), 1)) with(TeenagersPlus, xtabs(independence ~ `Premarital Sex` + `Teenage Birth Control`)) Teenage Birth Control Premarital Sex Strongly Disagree Disagree Agree Strongly Agree Always wrong 42.4 51.2 86.4 67.0 Almost always wrong 16.0 19.3 32.5 25.2 Wrong only sometimes 30.0 36.3 61.2 47.4 Not wrong at all 70.6 85.2 143.8 111.4 with(TeenagersPlus, xtabs(linear ~ `Premarital Sex` + `Teenage Birth Control`)) Teenage Birth Control Premarital Sex Strongly Disagree Disagree Agree Strongly Agree Always wrong 80.9 67.7 69.4 29.1 Almost always wrong 20.8 23.1 31.5 17.6 Wrong only sometimes 24.4 36.2 65.7 48.8 Not wrong at all 33.0 65.1 157.4 155.5 7.5.1 Linear-by-Linear Association Model \\[\\mathrm{log}\\mu_{ij}= \\lambda + \\lambda_i^X + \\lambda_j^Y + \\beta\\upsilon_i\\nu_j.\\] \\[\\begin{equation} \\frac{\\mu_{ab}\\mu_{cd}}{\\mu_{ad}\\mu_{cg}} = \\mathrm{exp}[\\beta(\\upsilon_c - \\upsilon_a)(\\nu_d - \\nu_b)] \\tag{19} \\end{equation}\\] 7.5.2 Example: Linear-by-Linear Association for Sex Opinions Teenagers &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Teenagers.dat&quot;, header = TRUE, stringsAsFactors = TRUE) Teenagers %&gt;% filter(row_number() %in% c(1, 2, n())) sex birth count 1 1 1 81 2 1 2 68 3 4 4 157 # quantitative sex-by birth interaction term fit &lt;- glm(count ~ factor(sex) + factor(birth) + sex:birth, family=poisson, data = Teenagers) summary(fit) Call: glm(formula = count ~ factor(sex) + factor(birth) + sex:birth, family = poisson, data = Teenagers) Deviance Residuals: Min 1Q Median 3Q Max -1.35834 -0.91606 0.07972 0.61648 1.57618 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) 4.10684 0.08951 45.881 &lt; 2e-16 *** factor(sex)2 -1.64596 0.13473 -12.216 &lt; 2e-16 *** factor(sex)3 -1.77002 0.16464 -10.751 &lt; 2e-16 *** factor(sex)4 -1.75369 0.23432 -7.484 7.20e-14 *** factor(birth)2 -0.46411 0.11952 -3.883 0.000103 *** factor(birth)3 -0.72452 0.16201 -4.472 7.74e-06 *** factor(birth)4 -1.87966 0.24910 -7.546 4.50e-14 *** sex:birth 0.28584 0.02824 10.122 &lt; 2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for poisson family taken to be 1) Null deviance: 431.078 on 15 degrees of freedom Residual deviance: 11.534 on 8 degrees of freedom AIC: 118.21 Number of Fisher Scoring iterations: 4 # interaction is likelihood ratio test for L x L association term car::Anova(fit) Analysis of Deviance Table (Type II tests) Response: count LR Chisq Df Pr(&gt;Chisq) factor(sex) 201.042 3 &lt; 2.2e-16 *** factor(birth) 91.243 3 &lt; 2.2e-16 *** sex:birth 116.119 1 &lt; 2.2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 \\[\\mathrm{exp}[\\beta(\\upsilon_4 - \\upsilon_1)(\\nu_4 - \\nu_1)] = \\mathrm{exp}[0.286(4-1)(4-1) = 13.1\\] 7.5.3 Ordinal Significance Tests of Independence 7.6 Loglinear Modeling of Count Response Variables * 7.6.1 Count Regressoin Modeling of Rate Data \\[\\mathrm{log}(\\mu/t)= \\alpha + \\beta_1 x_1 + \\cdots + \\beta_p x_p.\\] \\[\\mathrm{log} \\mu - \\mathrm{log} t = \\alpha + \\beta_1 x_1 + \\cdots + \\beta_p x_p.\\] \\[\\mu = t\\ \\mathrm{exp}(\\alpha + \\beta_1 x_1 + \\cdots + \\beta_p x_p).\\] 7.6.2 Example: Death Rates for Lung Cancer Patients Cancer &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Cancer.dat&quot;, header = TRUE, stringsAsFactors = TRUE) cancerCountWide &lt;- Cancer %&gt;% select(-risktime) %&gt;% pivot_wider(id = time, names_from = c(histology, stage), values_from=count) %&gt;% mutate(time = case_when(time == 1 ~ &quot;0-2&quot;, time == 2 ~ &quot;2-4&quot;, time == 3 ~ &quot;4-6&quot;, time == 4 ~ &quot;6-8&quot;, time == 5 ~ &quot;8-10&quot;, time == 6 ~ &quot;10-12&quot;, time == 7 ~ &quot;12+&quot;,)) %&gt;% mutate(`histo` = &quot; &quot;) %&gt;% # blank column for column headings select(time, histo, everything()) cancerRiskTimeWide &lt;- Cancer %&gt;% select(-count) %&gt;% mutate(risktime = paste0(&quot;(&quot;, risktime, &quot;)&quot;)) %&gt;% pivot_wider(id = time, names_from = c(histology, stage), values_from=risktime) %&gt;% mutate(time = case_when(time == 1 ~ &quot;0-2&quot;, time == 2 ~ &quot;2-4&quot;, time == 3 ~ &quot;4-6&quot;, time == 4 ~ &quot;6-8&quot;, time == 5 ~ &quot;8-10&quot;, time == 6 ~ &quot;10-12&quot;, time == 7 ~ &quot;12+&quot;,)) %&gt;% mutate(`histo` = &quot; &quot;) %&gt;% select(time, histo, everything()) # function to interleave two matrices # https://stackoverflow.com/questions/19781723/interleave-rows-of-matrix-stored-in-a-list-in-r # https://gist.github.com/mrdwab/7313857 Interleave &lt;- function(myList, append.source = TRUE, sep = &quot;: &quot;, drop = FALSE) { sources &lt;- myList sources[sapply(sources, is.null)] &lt;- NULL sources &lt;- lapply(sources, function(x) { if (is.matrix(x) || is.data.frame(x)) { x } else { t(x) } }) nrows &lt;- sapply(sources, nrow) mrows &lt;- max(nrows) if (any(nrows != mrows &amp; nrows != 1)) { stop(&quot;Arguments have differening numbers of rows.&quot;) } sources &lt;- lapply(sources, function(x) { if (nrow(x) == 1) { x[rep(1, mrows), , drop = drop] } else { x } }) tmp &lt;- do.call(&quot;rbind&quot;, sources) nsources &lt;- length(sources) indexes &lt;- outer((0:(nsources - 1)) * mrows, 1:mrows, &quot;+&quot;) retval &lt;- tmp[indexes, , drop = drop] if (append.source &amp;&amp; !is.null(names(sources))) { if (!is.null(row.names(tmp))) { row.names(retval) &lt;- paste(format(row.names(retval)), format(names(sources)), sep = sep ) } else { row.names(retval) &lt;- rep(names(sources), mrows) } } retval } # objects to interleave l &lt;- list(a=as.matrix(cancerCountWide),b=as.matrix(cancerRiskTimeWide)) # interleave counts and risk time bigMatrix &lt;- Interleave(l) # add columns for titles biggerMatrix &lt;- data.frame(cbind(bigMatrix[,1], bigMatrix[,2:11])) names(biggerMatrix) &lt;- names(cancerCountWide) my_header &lt;- data.frame( col_keys = c(&quot;time&quot;, &quot;histo&quot;, &quot;blank1&quot;, &quot;1_1&quot;, &quot;2_1&quot;, &quot;3_1&quot;, &quot;blank2&quot;, &quot;1_2&quot;, &quot;2_2&quot;, &quot;3_2&quot;, &quot;blank3&quot;, &quot;1_3&quot;, &quot;2_3&quot;,&quot;3_3&quot;), line2 = c(&quot;Follow-up&quot;, &quot;Histology&quot;, &quot;&quot;, rep(&quot;I&quot;, 3), &quot;&quot;, rep(&quot;II&quot;, 3), &quot;&quot;, rep(&quot;III&quot;, 3)), line3 = c(&quot;Follow-up&quot;, &quot;Disease Stage&quot;, rep(c(&quot;&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;), 3)) ) library(officer) big_border = fp_border(color=&quot;black&quot;, width = 2) library(flextable) flextable(biggerMatrix, col_keys = my_header$col_keys) %&gt;% set_header_df( mapping = my_header, key = &quot;col_keys&quot; ) %&gt;% theme_booktabs() %&gt;% merge_v(part = &quot;header&quot;) %&gt;% merge_h(part = &quot;header&quot;) %&gt;% merge_v(part = &quot;body&quot;) %&gt;% align(align = &quot;center&quot;, part = &quot;all&quot;) %&gt;% autofit() %&gt;% empty_blanks() %&gt;% hline_top(part=&quot;header&quot;, border = big_border) %&gt;% hline_bottom(part=&quot;body&quot;, border = big_border) %&gt;% fix_border_issues() .tabwid table{ border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 5px; margin-bottom: 5px; table-layout: fixed; border-spacing: 0; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-395c7a36{border-collapse:collapse;}.cl-3955905e{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-3955907c{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-39559db0{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:3pt;padding-top:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;}.cl-3955fb5c{width:15pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fb70{width:41pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fb7a{width:35pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fb8e{width:63pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fb98{width:87pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fb99{width:35pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fba2{width:15pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fbac{width:41pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fbb6{width:87pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fbc0{width:63pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fbc1{width:15pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fbca{width:35pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fbd4{width:41pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fbd5{width:63pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fbde{width:87pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fbe8{width:41pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fbf2{width:35pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fbf3{width:63pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fbfc{width:15pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fc06{width:87pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fc10{width:35pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fc11{width:87pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fc1a{width:41pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fc1b{width:15pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fc24{width:63pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fc2e{width:41pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fc38{width:35pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fc42{width:15pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fc43{width:63pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fc4c{width:87pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fc56{width:15pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fc60{width:41pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fc6a{width:87pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fc74{width:63pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fc88{width:35pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fc89{width:63pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fc92{width:15pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fca6{width:41pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fca7{width:35pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fcb0{width:87pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fcba{width:41pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fcc4{width:15pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fcc5{width:35pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fcce{width:63pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fcd8{width:87pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fcd9{width:41pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fce2{width:35pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fcec{width:63pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fced{width:15pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3955fcf6{width:87pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Follow-upHistologyIIIIIIDisease Stage1231231230-2 9511241422819(157)(77)(21)(134)(71)(22)(212)(130)(101)2-4 221 731261911(139)(68)(17)(110)(63)(18)(136)(72)(63)4-6 931 5531210 7(126)(63)(14)(96)(58)(14)(90)(42)(43)6-81021104110 5 6(102)(55)(12)(86)(42)(10)(64)(21)(32)8-10 120 420 5 0 3(88)(50)(10)(66)(35)(8)(47)(14)(21)10-12 321 310 4 3 3(82)(45)(8)(59)(32)(8)(39)(13)(14)12+ 120 442 1 2 3(76)(42)(6)(51)(28)(6)(29)(7)(10) \\[\\mathrm{log}(\\mu_{ijk}/t_{ijk}) = \\beta_0 + \\beta_i^H + \\beta_j^S + \\beta_k^T,\\] Cancer &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Cancer.dat&quot;, header = TRUE, stringsAsFactors = TRUE) Cancer %&gt;% filter(row_number() %in% c(1, n())) time histology stage count risktime 1 1 1 1 9 157 2 7 3 3 3 10 Cancer &lt;- Cancer %&gt;% mutate(&quot;logrisktime&quot; = log(Cancer$risktime)) # showing 6 time effects fit &lt;- glm(count ~ factor(histology) + factor(stage) + factor(time), family = poisson, offset = logrisktime, data = Cancer) summary(fit) Call: glm(formula = count ~ factor(histology) + factor(stage) + factor(time), family = poisson, data = Cancer, offset = logrisktime) Deviance Residuals: Min 1Q Median 3Q Max -2.00333 -0.74769 -0.03194 0.46468 1.70832 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -3.00928 0.16651 -18.073 &lt; 2e-16 *** factor(histology)2 0.16244 0.12195 1.332 0.18285 factor(histology)3 0.10754 0.14745 0.729 0.46580 factor(stage)2 0.47001 0.17444 2.694 0.00705 ** factor(stage)3 1.32431 0.15205 8.709 &lt; 2e-16 *** factor(time)2 -0.12745 0.14908 -0.855 0.39259 factor(time)3 -0.07973 0.16352 -0.488 0.62585 factor(time)4 0.11892 0.17107 0.695 0.48694 factor(time)5 -0.66511 0.26061 -2.552 0.01071 * factor(time)6 -0.35015 0.24348 -1.438 0.15040 factor(time)7 -0.17518 0.24985 -0.701 0.48321 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for poisson family taken to be 1) Null deviance: 175.718 on 62 degrees of freedom Residual deviance: 43.923 on 52 degrees of freedom AIC: 251.74 Number of Fisher Scoring iterations: 5 # likelihood-ratio test of effects, adjusting for the others car::Anova(fit) Analysis of Deviance Table (Type II tests) Response: count LR Chisq Df Pr(&gt;Chisq) factor(histology) 1.876 2 0.39132 factor(stage) 99.155 2 &lt; 2e-16 *** factor(time) 11.383 6 0.07724 . --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 7.6.3 Negativee Binomial Regression Models \\[E(Y) = \\mu,\\ \\ \\mathrm{var}(Y) = \\mu + D\\mu^2.\\] 7.6.4 Example: Female Horseshoe Crab Satelites Revisited Crabs &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Crabs.dat&quot;, header = TRUE, stringsAsFactors = TRUE) Crabs %&gt;% filter(row_number() %in% c(1, n())) crab sat y weight width color spine 1 1 8 1 3.05 28.3 2 3 2 173 0 0 2.00 24.5 2 2 fit.pois &lt;- glm(sat ~ width, family = poisson, data = Crabs) summary(fit.pois) Call: glm(formula = sat ~ width, family = poisson, data = Crabs) Deviance Residuals: Min 1Q Median 3Q Max -2.8526 -1.9884 -0.4933 1.0970 4.9221 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -3.30476 0.54224 -6.095 1.1e-09 *** width 0.16405 0.01997 8.216 &lt; 2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for poisson family taken to be 1) Null deviance: 632.79 on 172 degrees of freedom Residual deviance: 567.88 on 171 degrees of freedom AIC: 927.18 Number of Fisher Scoring iterations: 6 fit.negbin &lt;- MASS::glm.nb(sat ~ width, data = Crabs) summary(fit.negbin) Call: MASS::glm.nb(formula = sat ~ width, data = Crabs, init.theta = 0.90456808, link = log) Deviance Residuals: Min 1Q Median 3Q Max -1.7798 -1.4110 -0.2502 0.4770 2.0177 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -4.05251 1.17143 -3.459 0.000541 *** width 0.19207 0.04406 4.360 1.3e-05 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for Negative Binomial(0.9046) family taken to be 1) Null deviance: 213.05 on 172 degrees of freedom Residual deviance: 195.81 on 171 degrees of freedom AIC: 757.29 Number of Fisher Scoring iterations: 1 Theta: 0.905 Std. Err.: 0.161 2 x log-likelihood: -751.291 "],["Matched.html", "8 Models for Matched Pairs 8.1 Comparing Dependent Proporitons for Binary Mached Pairs 8.2 Marginal Models and Subject-Specific Models for Matched Pairs 8.3 Comparing Proportions for Nominal Matched-Pairs Responses 8.4 Comparing Proportions for Ordinal Matched-Pairs Responses 8.5 Analyzing Rater Agreement * 8.6 Bradley-Terry Model for Paired Preferences *", " 8 Models for Matched Pairs Opinions &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Envir_opinions.dat&quot;, header = TRUE, stringsAsFactors = TRUE) # Make contingency table tab &lt;- as.matrix(addmargins(xtabs(~y1 + y2, data = Opinions))) library(tibble) # Add label as the first column and variable names `Table 8.1` &lt;- tibble(`Pay Higher Taxes` = c(&quot;Yes&quot;, &quot;No&quot;, &quot;Total&quot;), Yes = tab[,1], No = tab[,2], Total = tab[,3]) # horrible kludge `Table 8.1`$Yes &lt;- paste(`Table 8.1`$Yes, c(&quot; (pi11)&quot;, &quot; (pi21)&quot;, &quot;&quot;)) `Table 8.1`$No &lt;- paste(`Table 8.1`$No, c(&quot; (pi12)&quot;, &quot; (pi22)&quot;, &quot;&quot;)) library(flextable) my_header &lt;- data.frame( col_keys = colnames(`Table 8.1`), line1 = c(&quot;Pay Higher Taxes&quot;, rep(&quot;Cut Living Standards&quot;, 2), &quot;Total&quot;), line2 = colnames(`Table 8.1`) ) flextable(`Table 8.1`, col_keys = my_header$col_keys) %&gt;% set_header_df( mapping = my_header, key = &quot;col_keys&quot; ) %&gt;% theme_booktabs() %&gt;% autofit(part = &quot;all&quot;) %&gt;% align(align = &quot;center&quot;, part = &quot;all&quot;) %&gt;% merge_h(part = &quot;header&quot;) %&gt;% merge_v(part = &quot;header&quot;) %&gt;% merge_h(part = &quot;body&quot;) %&gt;% merge_v(part = &quot;body&quot;) %&gt;% align_nottext_col(align = &quot;center&quot;) %&gt;% set_caption(caption = &quot;Table 8.1&quot;) .tabwid table{ border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 5px; margin-bottom: 5px; table-layout: fixed; border-spacing: 0; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-3a14ff98{border-collapse:collapse;}.cl-3a10c004{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-3a10cb76{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:3pt;padding-top:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;}.cl-3a10ec5a{width:43pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3a10ec6e{width:117pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3a10ec78{width:103pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3a10ec82{width:117pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3a10ec83{width:103pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3a10ec8c{width:43pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3a10ec96{width:117pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3a10eca0{width:103pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3a10eca1{width:43pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3a10ecaa{width:117pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3a10ecb4{width:103pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3a10ecbe{width:43pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 2: Table 8.1 Pay Higher TaxesCut Living StandardsTotalYesNoYes227 (pi11)132 (pi12)359No107 (pi21)678 (pi22)785Total334 810 1,144 8.1 Comparing Dependent Proporitons for Binary Mached Pairs 8.1.1 McNemar Test Comparing Marginal Proportions \\[H_0: P(Y_1 = 1) = P(Y_2 = 1), \\mathrm{\\ or\\ equivalently\\ } H_0: \\pi_{12} = \\pi_{21}.\\] \\[\\begin{equation} z = \\frac{n_{12}-(\\frac{1}{2}n^*)}{\\sqrt{n^*(\\frac{1}{2})(\\frac{1}{2})}}= \\frac{n_{12}- n_{21}}{\\sqrt{n_{12}+n_{21}}} \\tag{20} \\end{equation}\\] Opinions &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Envir_opinions.dat&quot;, header = TRUE, stringsAsFactors = TRUE) library(dplyr) # Data file has 1144 lines, one for each of 1144 people. # Each person has two binary responses (y1 and y2) Opinions %&gt;% filter(row_number() %in% c(1, 2, n())) person y1 y2 1 1 1 1 2 2 1 1 3 1144 2 2 tab &lt;- xtabs(~y1 + y2, data = Opinions) tab y2 y1 1 2 1 227 132 2 107 678 # Don&#39;t use continuity correction, which is too conservative. mcnemar.test(tab, correct = FALSE) McNemar&#39;s Chi-squared test data: tab McNemar&#39;s chi-squared = 2.6151, df = 1, p-value = 0.1059 library(PropCIs) # specific to how to round currentDigits = unlist(options(&quot;digits&quot;)) # save current rounding options(digits = 1) # 95% Wald CI for difference of marginal probabilities diffpropci.Wald.mp(107, 132, 1144, 0.95) # (n21, n12, n, confidence level) data: 95 percent confidence interval: -0.005 0.048 sample estimates: [1] 0.02 diffpropci.Wald.mp(tab[2,1], tab[1,2], sum(tab), 0.95) data: 95 percent confidence interval: -0.005 0.048 sample estimates: [1] 0.02 # 95% score CI for difference of marginal probabilities scoreci.mp(tab[2,1], tab[1,2], sum(tab), 0.95) data: 95 percent confidence interval: -0.005 0.048 options(digits = currentDigits) # reset rounding 8.1.2 Estimating the difference between Dependent Proportions 8.2 Marginal Models and Subject-Specific Models for Matched Pairs 8.2.1 Marginal Models for Marginal Proportions \\[P(Y_1 = 1) = \\alpha + \\delta,\\ P(Y_2= 1) = \\alpha,\\] \\[P(Y_1 = 1) = \\alpha + \\delta x_i\\] \\[\\begin{equation} \\mathrm{logit}[P(Y_t = 1)] = \\alpha + \\beta x_i. \\tag{21} \\end{equation}\\] 8.2.2 Example: Enironmental Options Revisted Opinions &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Opinions.dat&quot;, header = TRUE, stringsAsFactors = TRUE) # Data file has 1144 lines, one for each of 1144 people. # Each person has two binary responses (y1 and y2) Opinions %&gt;% filter(row_number() %in% c(1, 2, 3, 4, n()-1, n())) person question y 1 1 1 1 2 1 0 1 3 2 1 1 4 2 0 1 5 1144 1 0 6 1144 0 0 library(gee) # id identifies variable on which observe y1, y2 fit &lt;- gee(y ~ question, id = person, family = binomial(link = &quot;identity&quot;), data = Opinions) Beginning Cgee S-function, @(#) geeformula.q 4.13 98/01/27 running glm to get initial regression estimate (Intercept) question 0.29195804 0.02185315 summary(fit) # question parameter for identity link is difference of proportions GEE: GENERALIZED LINEAR MODELS FOR DEPENDENT DATA gee S-function, version 4.13 modified 98/01/27 (1998) Model: Link: Identity Variance to Mean Relation: Binomial Correlation Structure: Independent Call: gee(formula = y ~ question, id = person, data = Opinions, family = binomial(link = &quot;identity&quot;)) Summary of Residuals: Min 1Q Median 3Q Max -0.3138112 -0.3138112 -0.2919580 0.6861888 0.7080420 Coefficients: Estimate Naive S.E. Naive z Robust S.E. Robust z (Intercept) 0.29195804 0.01344828 21.709701 0.0134424 21.719196 question 0.02185315 0.01921587 1.137245 0.0134982 1.618967 Estimated Scale Parameter: 1.000875 Number of Iterations: 1 Working Correlation [,1] [,2] [1,] 1 0 [2,] 0 1 fit2 &lt;- gee(y ~ question, id = person, family = binomial(link = logit), data = Opinions) Beginning Cgee S-function, @(#) geeformula.q 4.13 98/01/27 running glm to get initial regression estimate (Intercept) question -0.8858933 0.1035319 summary(fit2) # question parameter for logit link is log odds ratio GEE: GENERALIZED LINEAR MODELS FOR DEPENDENT DATA gee S-function, version 4.13 modified 98/01/27 (1998) Model: Link: Logit Variance to Mean Relation: Binomial Correlation Structure: Independent Call: gee(formula = y ~ question, id = person, data = Opinions, family = binomial(link = logit)) Summary of Residuals: Min 1Q Median 3Q Max -0.3138112 -0.3138112 -0.2919580 0.6861888 0.7080420 Coefficients: Estimate Naive S.E. Naive z Robust S.E. Robust z (Intercept) -0.8858933 0.06505597 -13.617401 0.06502753 -13.623357 question 0.1035319 0.09107816 1.136737 0.06397794 1.618244 Estimated Scale Parameter: 1.000875 Number of Iterations: 1 Working Correlation [,1] [,2] [1,] 1 0 [2,] 0 1 8.2.3 Subject-Specific and Population-Averaging Tables `Table 8.2` &lt;- data.frame(Question = c(&quot;yi1: Pay higher taxes?&quot;, &quot;yi2: Cut living standards?&quot;), Yes = c(1, 1), No = c(0, 0)) theHeader &lt;- data.frame(col_keys = colnames(`Table 8.2`), line1 = c(&quot;Question&quot;, rep(&quot;Response&quot;, 2)), line2 = colnames(`Table 8.2`)) library(flextable) library(dplyr) flextable(`Table 8.2`, col_keys = theHeader$col_keys) %&gt;% set_header_df( mapping = theHeader, key = &quot;col_keys&quot; ) %&gt;% theme_booktabs() %&gt;% merge_v(part = &quot;header&quot;) %&gt;% merge_h(part = &quot;header&quot;) %&gt;% align(align = &quot;center&quot;, part = &quot;all&quot;) %&gt;% #autofit() %&gt;% empty_blanks() %&gt;% fix_border_issues() %&gt;% set_caption(caption = &quot;Table 8.2: Representation of subject-specific table for matched pair contributing to count n_11 = 227 in Table 8.1.&quot;) %&gt;% set_table_properties(width = .75, layout = &quot;autofit&quot;) .tabwid table{ border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 5px; margin-bottom: 5px; table-layout: fixed; border-spacing: 0; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-3b0bc648{table-layout:auto;border-collapse:collapse;width:75%;}.cl-3b080a1c{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-3b0814ee{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:3pt;padding-top:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;}.cl-3b08310e{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3b083122{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3b08312c{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3b083136{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3b083137{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3: Table 8.2: Representation of subject-specific table for matched pair contributing to count n_11 = 227 in Table 8.1. QuestionResponseYesNoyi1: Pay higher taxes?10yi2: Cut living standards?10 8.2.4 Conditional Logistic Regression for Matched-Pairs* \\[\\begin{equation} \\mathrm{logit}[P(Y_{it} = 1)] = \\alpha_i + \\beta x_{it},\\ t = 1,\\ 2, \\tag{22} \\end{equation}\\] \\[P(Y_{i1} = 1) = \\frac{\\mathrm{exp}(\\alpha_i + \\beta)}{1 + \\mathrm{exp}(\\alpha_i + \\beta)},\\ P(Y_{i2} = 1) = \\frac{\\mathrm{exp}(\\alpha_i)}{1 + \\mathrm{exp}(\\alpha_i)}.\\] ### 8.2.5 Logistic Regression for Matched Case-Control Studies* library(tidyverse) `Table 8.3` &lt;- tibble(`Normal Birth Weight (Controls)` = c(&quot;Nonsmokers&quot;, &quot;Smokers&quot;), Nonsmokers = c(159, 8), Smokers = c(22, 14)) theHeader &lt;- data.frame(col_keys = c(&quot;Normal Birth Weight (Controls)&quot;, &quot;blank&quot;, &quot;Nonsmokers&quot;, &quot;Smokers&quot;), line1 = c(&quot;Normal Birth Weight (Controls)&quot;, &quot;&quot;, rep(&quot;Low Birth Weight (Cases)&quot;, 2)), line2 = c(&quot;Normal Birth Weight (Controls)&quot;, &quot;blank&quot;, &quot;Nonsmokers&quot;, &quot;Smokers&quot;)) library(flextable) library(dplyr) library(officer) big_border = fp_border(color=&quot;black&quot;, width = 2) flextable(`Table 8.3`, col_keys = theHeader$col_keys) %&gt;% set_header_df( mapping = theHeader, key = &quot;col_keys&quot; ) %&gt;% theme_booktabs() %&gt;% merge_v(part = &quot;header&quot;) %&gt;% merge_h(part = &quot;header&quot;) %&gt;% align(align = &quot;center&quot;, part = &quot;all&quot;) %&gt;% #autofit() %&gt;% empty_blanks() %&gt;% fix_border_issues() %&gt;% set_caption(caption = &quot;Table 8.3&quot;) %&gt;% set_table_properties(width = .75, layout = &quot;autofit&quot;) %&gt;% hline_top(part=&quot;header&quot;, border = big_border) %&gt;% hline_bottom(part=&quot;body&quot;, border = big_border) .tabwid table{ border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 5px; margin-bottom: 5px; table-layout: fixed; border-spacing: 0; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-3b40fb1a{table-layout:auto;border-collapse:collapse;width:75%;}.cl-3b3c9318{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-3b3c9336{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-3b3ca0a6{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:3pt;padding-top:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;}.cl-3b3cc5c2{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3b3cc5d6{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3b3cc5ea{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3b3cc5eb{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3b3cc5f4{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3b3cc5fe{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3b3cc608{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 4: Table 8.3 Normal Birth Weight (Controls)Low Birth Weight (Cases)NonsmokersSmokersNonsmokers15922Smokers814 library(tidyverse) `Table 8.4` &lt;- tibble(`Smoker` = c(&quot;No&quot;, &quot;Yes&quot;), aCase = c(1, 0), aCon = c(1, 0), bCase = c(0, 1), bCon = c(1, 0), cCase = c(1, 0), cCon = c(0, 1), dCase = c(0, 1), dCon = c(0, 1)) theHeader &lt;- data.frame(col_keys = c(&quot;Smoker&quot; , &quot;aCase&quot;, &quot;aCon&quot;, &quot;blank1&quot;, &quot;bCase&quot;, &quot;bCon&quot;, &quot;blank2&quot;, &quot;cCase&quot;, &quot;cCon&quot;, &quot;blank3&quot;, &quot;dCase&quot;, &quot;dCon&quot;, &quot;blank4&quot; ), line1 = c(&quot;Smoker&quot;, rep(&quot;a&quot;, 2), &quot;&quot;, rep(&quot;b&quot;, 2), &quot;&quot;, rep(&quot;c&quot;, 2), &quot;&quot;, rep(&quot;d&quot;, 2),&quot;&quot;), line2 = c(&quot;Smoker&quot;, rep(c(&quot;Case&quot;, &quot;Control&quot;, &quot; &quot;), 4))) library(flextable) library(dplyr) flextable(`Table 8.4`, col_keys = theHeader$col_keys) %&gt;% set_header_df( mapping = theHeader, key = &quot;col_keys&quot; ) %&gt;% theme_booktabs() %&gt;% merge_v(part = &quot;header&quot;) %&gt;% merge_h(part = &quot;header&quot;) %&gt;% align(align = &quot;center&quot;, part = &quot;all&quot;) %&gt;% #autofit() %&gt;% empty_blanks() %&gt;% fix_border_issues() %&gt;% set_caption(caption = &quot;Table 8.4&quot;) %&gt;% set_table_properties(width = .75, layout = &quot;autofit&quot;) %&gt;% hline_top(part=&quot;header&quot;, border = big_border) %&gt;% hline_top(part=&quot;body&quot;, border = big_border) %&gt;% hline_bottom(part=&quot;body&quot;, border = big_border) .tabwid table{ border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 5px; margin-bottom: 5px; table-layout: fixed; border-spacing: 0; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-3b745dc0{table-layout:auto;border-collapse:collapse;width:75%;}.cl-3b703d76{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-3b703d8a{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-3b70488e{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:3pt;padding-top:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;}.cl-3b706ea4{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3b706eb8{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3b706ec2{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3b706ec3{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3b706ecc{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3b706ed6{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3b706ee0{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 5: Table 8.4 SmokerabcdCaseControlCaseControlCaseControlCaseControlNo11011000Yes00100111 8.3 Comparing Proportions for Nominal Matched-Pairs Responses \\[P(Y_1 = i) = P(Y_2 = i)\\ \\mathrm{for}\\ i = 1, \\dots, c,\\] 8.3.1 Marginal Homogeneity for Baseline-Category Logit Models \\[\\mathrm{log}\\left[\\frac{P(Y_1 = j)}{P(Y_1 = c)}\\right] = \\alpha_j + \\beta_j,\\ \\mathrm{log}\\left[\\frac{P(Y_2 = j)}{P(Y_2 = c)}\\right] = \\alpha_j\\] ### 8.3.2 Example: Coffee Brand Market Share Coffee &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Coffee.dat&quot;, header = TRUE, stringsAsFactors = TRUE) library(dplyr) library(tidyr) coffee_wide &lt;- Coffee %&gt;% tidyr::pivot_wider(id_cols = person, names_from=purchase, names_prefix = &quot;y&quot;, values_from = y) # Make contingency table tab &lt;- as.matrix(addmargins(xtabs(~y1 + y0, data = coffee_wide))) library(tibble) # Add label as the first column and variable names `Table 8.5` &lt;- tibble(`First Purchase` = c(&quot;High Point&quot;, &quot;Taster&#39;s Choice&quot;, &quot;Sanka&quot;, &quot;Nescafe&quot;, &quot;Brim&quot;, &quot;Total&quot;), `High Point` = tab[, 1], `Taster&#39;s Choice` = tab[,2], `Sanka` = tab[, 3], `Nescafe` = tab[,4], `Brim` = tab[,5], Total = tab[, 6]) theHeader &lt;- data.frame(col_keys = c(&quot;First Purchase&quot;, &quot;Blank&quot;, &quot;High Point&quot;, &quot;Taster&#39;s Choice&quot;, &quot;Sanka&quot;, &quot;Nescafe&quot;, &quot;Brim&quot;, &quot;Total&quot;), line1 = c(&quot;First Purchase&quot;, &quot;&quot;, rep(&quot;Second Purchase&quot;, 6)), line2 = c(&quot;First Purchase&quot;, &quot;&quot;, &quot;High Point&quot;, &quot;Taster&#39;s Choice&quot;, &quot;Sanka&quot;, &quot;Nescafe&quot;, &quot;Brim&quot;, &quot;Total&quot;)) library(flextable) library(dplyr) library(officer) big_border = fp_border(color=&quot;black&quot;, width = 2) flextable(`Table 8.5`, col_keys = theHeader$col_keys) %&gt;% set_header_df( mapping = theHeader, key = &quot;col_keys&quot; ) %&gt;% theme_booktabs() %&gt;% merge_v(part = &quot;header&quot;) %&gt;% merge_h(part = &quot;header&quot;) %&gt;% align(align = &quot;center&quot;, part = &quot;all&quot;) %&gt;% align(j=&quot;First Purchase&quot;, align= &quot;left&quot;, part = &quot;all&quot;) %&gt;% #autofit() %&gt;% empty_blanks() %&gt;% fix_border_issues() %&gt;% set_caption(caption = &quot;Table 8.5&quot;) %&gt;% set_table_properties(width = .75, layout = &quot;autofit&quot;) %&gt;% hline_top(part=&quot;header&quot;, border = big_border) %&gt;% hline_bottom(part=&quot;body&quot;, border = big_border) .tabwid table{ border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 5px; margin-bottom: 5px; table-layout: fixed; border-spacing: 0; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-3bf9aa70{table-layout:auto;border-collapse:collapse;width:75%;}.cl-3bf557a4{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-3bf557b8{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-3bf56302{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:3pt;padding-top:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;}.cl-3bf56316{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:3pt;padding-top:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;}.cl-3bf591d8{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3bf591ec{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3bf591f6{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3bf591f7{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3bf59200{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3bf5920a{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3bf59214{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3bf5921e{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3bf5921f{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3bf59228{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 6: Table 8.5 First PurchaseSecond PurchaseHigh PointTaster's ChoiceSankaNescafeBrimTotalHigh Point931744710171Taster's Choice946110975Sanka1711155912204Nescafe64915236Brim1041222755Total135822313360541 Using GEE methodology, we can fit the baseline-category logit model, as shown in the following R output. Coffee &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Coffee.dat&quot;, header = TRUE, stringsAsFactors = TRUE) # subject-specific data file, purchase is 1 for first purchase 0 for second Coffee %&gt;% filter(row_number() %in% c(1, 2, 3, 4, n()-1, n())) person purchase y 1 1 1 1 2 1 0 1 3 2 1 1 4 2 0 1 5 541 1 5 6 541 0 5 library(multgee) # package for multinomial GEE analysis fit &lt;- nomLORgee(y ~ purchase, id = person, LORstr = &quot;independence&quot;, data = Coffee) # san.se = robust SE # beta01 is alpha1 in our notation summary(fit) # nomLORgee uses baseline category logits for nominal response GEE FOR NOMINAL MULTINOMIAL RESPONSES version 1.6.0 modified 2017-07-10 Link : Baseline Category Logit Local Odds Ratios: Structure: independence Homogenous scores: TRUE call: nomLORgee(formula = y ~ purchase, data = Coffee, id = person, LORstr = &quot;independence&quot;) Summary of residuals: Min. 1st Qu. Median Mean 3rd Qu. Max. -0.4270 -0.2495 -0.1386 0.0000 -0.0610 0.9390 Number of Iterations: 1 Coefficients: Estimate san.se san.z Pr(&gt;|san.z|) beta10 0.81093 0.15516 5.2265 &lt; 2e-16 *** purchase:1 0.32340 0.16830 1.9215 0.05466 . beta20 0.31237 0.16989 1.8387 0.06596 . purchase:2 -0.00222 0.18662 -0.0119 0.99051 beta30 1.34807 0.14490 9.3036 &lt; 2e-16 *** purchase:3 -0.03729 0.15807 -0.2359 0.81353 beta40 -0.59784 0.21672 -2.7585 0.00581 ** purchase:4 0.17402 0.23531 0.7396 0.45957 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Local Odds Ratios Estimates: [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [1,] 0 0 0 0 1 1 1 1 [2,] 0 0 0 0 1 1 1 1 [3,] 0 0 0 0 1 1 1 1 [4,] 0 0 0 0 1 1 1 1 [5,] 1 1 1 1 0 0 0 0 [6,] 1 1 1 1 0 0 0 0 [7,] 1 1 1 1 0 0 0 0 [8,] 1 1 1 1 0 0 0 0 pvalue of Null model: &lt;0.0001 fit0 &lt;- nomLORgee(y ~ 1, id = person, LORstr = &quot;independence&quot;, data = Coffee) # Model under H_0: y ~ 1 null model (marginal homogeneity) waldts(fit0, fit) Goodness of Fit based on the Wald test Model under H_0: y ~ 1 Model under H_1: y ~ purchase Wald Statistic=12.4869, df=4, p-value=0.0141 with(Coffee, mantelhaen.test(purchase, y, person)) Cochran-Mantel-Haenszel test data: purchase and y and person Cochran-Mantel-Haenszel M^2 = 12.291, df = 4, p-value = 0.01531 8.3.3 Using Cochran-Mantel-Haenszel Test to Test marinal Homogeneity* 8.3.4 Symmetry and Quasi-Symmetry Models for Square Contingency Tables \\[\\pi_{ij} = \\pi_{ji}\\] \\[\\mathrm{log}(\\pi_{ij}/\\pi_{ji}) = 0\\ \\mathrm{for\\ all}\\ i \\ \\mathrm{and}\\ j.\\] \\[r_{ij} = (n_{ij} - n_{ji})/\\sqrt{n_{ij} + n_{ji}}.\\] \\[\\begin{equation} \\mathrm{log}(\\pi_{ij}/\\pi_{ji}) = \\beta_i - \\beta_j\\ \\mathrm{for\\ all}\\ i \\ \\mathrm{and}\\ j. \\tag{23} \\end{equation}\\] 8.3.5 Example: Coffee Brand market Share Revisited Coffee2 &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Coffee2.dat&quot;, header = TRUE, stringsAsFactors = TRUE) # quasi-symmetry model, nij and nji are opposite cell counts in table 8.5 Coffee2 H T S N B nij nji 1 1 -1 0 0 0 17 9 2 1 0 -1 0 0 44 17 3 1 0 0 -1 0 7 6 4 1 0 0 0 -1 10 10 5 0 1 -1 0 0 11 11 6 0 1 0 -1 0 0 4 7 0 1 0 0 -1 9 4 8 0 0 1 -1 0 9 9 9 0 0 1 0 -1 12 12 10 0 0 0 1 -1 2 2 symm &lt;- glm(nij/(nij+nji) ~ -1, family = binomial, weights = nij + nji, data = Coffee2) summary(symm) # symmetry model, -1 in model statement sets intercept = 0 Call: glm(formula = nij/(nij + nji) ~ -1, family = binomial, data = Coffee2, weights = nij + nji) Deviance Residuals: Min 1Q Median 3Q Max -2.355 0.000 0.000 1.123 3.518 No Coefficients (Dispersion parameter for binomial family taken to be 1) Null deviance: 22.473 on 10 degrees of freedom Residual deviance: 22.473 on 10 degrees of freedom AIC: 52.433 Number of Fisher Scoring iterations: 0 QS &lt;- glm(nij/(nij+nji) ~ -1 + H + T + S + N + B , family = binomial, weights = nij + nji, data = Coffee2) summary(QS) Call: glm(formula = nij/(nij + nji) ~ -1 + H + T + S + N + B, family = binomial, data = Coffee2, weights = nij + nji) Deviance Residuals: Min 1Q Median 3Q Max -2.1010 -0.2902 -0.0804 0.7165 1.4120 Coefficients: (1 not defined because of singularities) Estimate Std. Error z value Pr(&gt;|z|) H 0.595440 0.293658 2.028 0.0426 * T -0.004004 0.329359 -0.012 0.9903 S -0.113299 0.285082 -0.397 0.6911 N 0.302115 0.401589 0.752 0.4519 B NA NA NA NA --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 22.473 on 10 degrees of freedom Residual deviance: 9.974 on 6 degrees of freedom AIC: 47.934 Number of Fisher Scoring iterations: 4 8.4 Comparing Proportions for Ordinal Matched-Pairs Responses 8.4.1 Marginal Homogeneity and Cummulative Logit Marginal Model \\[\\mathrm{logit}[P(Y_1 \\le j)] = \\alpha_j + \\beta,\\ \\mathrm{logit}[P(Y_2 \\le j)] = \\alpha_j\\] 8.4.2 Example: Recycle or Drive Less to Help the Environment? Envir &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Envir.dat&quot;, header = TRUE, stringsAsFactors = TRUE) library(dplyr) library(tidyr) envir_wide &lt;- Envir %&gt;% tidyr::pivot_wider(id_cols = person, names_from=question, names_prefix = &quot;y&quot;, values_from = y) # Make contingency table tab &lt;- as.matrix(xtabs(~y1 + y0, data = envir_wide)) library(tibble) # Add label as the first column and variable names `Table 8.6` &lt;- tibble(`Recycle` = c(&quot;Always&quot;, &quot;Often&quot;, &quot;Sometimes&quot;, &quot;Never&quot;), `Always` = tab[, 1], `Often` = tab[,2], `Sometimes` = tab[, 3], `Never` = tab[,4]) theHeader &lt;- data.frame(col_keys = c(&quot;Recycle&quot;, &quot;Blank&quot;, &quot;Always&quot;, &quot;Often&quot;, &quot;Sometimes&quot;, &quot;Never&quot;), line1 = c(&quot;Recycle&quot;, &quot;&quot;, rep(&quot;Drive Less&quot;, 4)), line2 = c(&quot;Recycle&quot;, &quot;&quot;, &quot;Always&quot;, &quot;Often&quot;, &quot;Sometimes&quot;, &quot;Never&quot;)) library(flextable) library(dplyr) library(officer) big_border = fp_border(color=&quot;black&quot;, width = 2) flextable(`Table 8.6`, col_keys = theHeader$col_keys) %&gt;% set_header_df( mapping = theHeader, key = &quot;col_keys&quot; ) %&gt;% theme_booktabs() %&gt;% merge_v(part = &quot;header&quot;) %&gt;% merge_h(part = &quot;header&quot;) %&gt;% align(align = &quot;center&quot;, part = &quot;all&quot;) %&gt;% align(j=&quot;Recycle&quot;, align= &quot;left&quot;, part = &quot;all&quot;) %&gt;% autofit() %&gt;% empty_blanks() %&gt;% fix_border_issues() %&gt;% set_caption(caption = &quot;Table 8.6&quot;) %&gt;% #set_table_properties(width = .75, layout = &quot;autofit&quot;) %&gt;% hline_top(part=&quot;header&quot;, border = big_border) %&gt;% hline_bottom(part=&quot;body&quot;, border = big_border) .tabwid table{ border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 5px; margin-bottom: 5px; table-layout: fixed; border-spacing: 0; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-3d4144e2{border-collapse:collapse;}.cl-3d3cab62{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-3d3cab80{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-3d3cb6c0{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:3pt;padding-top:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;}.cl-3d3cb6d4{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:3pt;padding-top:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;}.cl-3d3cde98{width:45pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3d3cdeac{width:70pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3d3cdeb6{width:67pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3d3cdec0{width:42pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3d3cdeca{width:15pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3d3cded4{width:70pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3d3cded5{width:45pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3d3cdede{width:70pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3d3cdee8{width:70pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3d3cdef2{width:15pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3d3cdef3{width:67pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3d3cdefc{width:42pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3d3cdf10{width:42pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3d3cdf11{width:67pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3d3cdf1a{width:70pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3d3cdf24{width:15pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3d3cdf2e{width:45pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3d3cdf2f{width:70pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3d3cdf38{width:67pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3d3cdf42{width:42pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3d3cdf43{width:15pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3d3cdf4c{width:70pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3d3cdf56{width:70pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3d3cdf57{width:45pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3d3cdf60{width:45pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3d3cdf6a{width:42pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3d3cdf74{width:70pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3d3cdf75{width:67pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3d3cdf7e{width:70pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 7: Table 8.6 RecycleDrive LessAlwaysOftenSometimesNeverAlways1243163233Often42199185Sometimes4877230Never0118132 Envir &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Envir.dat&quot;, header = TRUE, stringsAsFactors = TRUE) Envir %&gt;% filter(row_number() %in% c(1, 2, n()-1, n())) person question y 1 1 1 1 2 1 0 1 3 1230 1 4 4 1230 0 4 library(multgee) fit &lt;- ordLORgee(y ~ question, id = person, LORstr = &quot;independence&quot;, data = Envir) summary(fit) GEE FOR ORDINAL MULTINOMIAL RESPONSES version 1.6.0 modified 2017-07-10 Link : Cumulative logit Local Odds Ratios: Structure: independence call: ordLORgee(formula = y ~ question, data = Envir, id = person, LORstr = &quot;independence&quot;) Summary of residuals: Min. 1st Qu. Median Mean 3rd Qu. Max. -0.354916 -0.264742 -0.059210 -0.002021 -0.033859 0.966141 Number of Iterations: 1 Coefficients: Estimate san.se san.z Pr(&gt;|san.z|) beta10 -3.35111 0.08289 -40.4287 &lt; 2.2e-16 *** beta20 -2.27673 0.07430 -30.6424 &lt; 2.2e-16 *** beta30 -0.58488 0.05882 -9.9443 &lt; 2.2e-16 *** question 2.75361 0.08147 33.7985 &lt; 2.2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Local Odds Ratios Estimates: [,1] [,2] [,3] [,4] [,5] [,6] [1,] 0 0 0 1 1 1 [2,] 0 0 0 1 1 1 [3,] 0 0 0 1 1 1 [4,] 1 1 1 0 0 0 [5,] 1 1 1 0 0 0 [6,] 1 1 1 0 0 0 pvalue of Null model: &lt;0.0001 8.4.3 An Ordinal Quasi-Symmetry Model * \\[\\begin{equation} \\mathrm{log}(\\pi_{ij}/\\pi_{ji}) = \\beta(u_j = u_i). \\tag{24} \\end{equation}\\] 8.4.4 Example: Recycle or Drive Less Revisited? Envir &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Environment.dat&quot;, header = TRUE, stringsAsFactors = TRUE) # nij and nji are opposite cell counts in Table 8.6 # x = j-1 = distance between categories, 6 pairs of opposite cells Envir always often sometimes never x nij nji 1 1 -1 0 0 1 43 4 2 1 0 -1 0 2 163 4 3 1 0 0 -1 3 233 0 4 0 1 -1 0 1 99 8 5 0 1 0 -1 2 185 1 6 0 0 1 -1 1 230 18 fit &lt;- glm(nij/(nij+nji) ~ -1 + x, family = binomial, weight = nij + nji, data = Envir) summary(fit) # ordinal quasi symmetry; -1 in model sets intercept = 0 Call: glm(formula = nij/(nij + nji) ~ -1 + x, family = binomial, data = Envir, weights = nij + nji) Deviance Residuals: 1 2 3 4 5 6 -0.03567 -1.82023 0.59541 0.33794 0.46512 0.64368 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) x 2.3936 0.1508 15.88 &lt;2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 1106.1240 on 6 degrees of freedom Residual deviance: 4.4139 on 5 degrees of freedom AIC: 23.35 Number of Fisher Scoring iterations: 4 fit.QS &lt;- glm(nij/(nij+nji) ~ -1 + always + often + sometimes + never, family = binomial, weight = nij + nji, data = Envir) summary(fit.QS) # quasi symmetry Call: glm(formula = nij/(nij + nji) ~ -1 + always + often + sometimes + never, family = binomial, data = Envir, weights = nij + nji) Deviance Residuals: 1 2 3 4 5 6 0.7689 -1.1439 0.6760 0.4572 0.3006 -0.1381 Coefficients: (1 not defined because of singularities) Estimate Std. Error z value Pr(&gt;|z|) always 6.9269 0.4708 14.71 &lt;2e-16 *** often 4.9332 0.3617 13.64 &lt;2e-16 *** sometimes 2.5817 0.2386 10.82 &lt;2e-16 *** never NA NA NA NA --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 1106.1240 on 6 degrees of freedom Residual deviance: 2.6751 on 3 degrees of freedom AIC: 25.611 Number of Fisher Scoring iterations: 4 8.5 Analyzing Rater Agreement * 8.5.1 Example: Agreement on Carcinoma Diagnosis Pathology &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Pathologists.dat&quot;, header = TRUE, stringsAsFactors = TRUE) library(dplyr) library(tibble) # Make contingency table mat &lt;- matrix(Pathology$count, ncol = 4,byrow = T) %&gt;% addmargins() colnames(mat) &lt;- c(&quot;V1&quot;, &quot;V2&quot;, &quot;V3&quot;, &quot;V4&quot;, &quot;Sum&quot;) `Table 8.7` &lt;- mat %&gt;% as_tibble() %&gt;% bind_cols(`Pathologist X` = c(1:4, &quot;Total&quot;)) %&gt;% select(`Pathologist X`, everything()) theHeader &lt;- data.frame(col_keys = c(&quot;Pathologist X&quot;, &quot;Blank&quot;, &quot;V1&quot;, &quot;V2&quot;, &quot;V3&quot;, &quot;V4&quot;, &quot;Sum&quot;), line1 = c(&quot;Pathologist X&quot;, &quot;&quot;, rep(&quot;Pathologist Y&quot;, 4), &quot;Total&quot;), line2 = c(&quot;Pathologist X&quot;, &quot;&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;Total&quot;)) library(flextable) library(dplyr) library(officer) big_border = fp_border(color=&quot;black&quot;, width = 2) flextable(`Table 8.7`, col_keys = theHeader$col_keys) %&gt;% set_header_df( mapping = theHeader, key = &quot;col_keys&quot; ) %&gt;% theme_booktabs() %&gt;% merge_v(part = &quot;header&quot;) %&gt;% merge_h(part = &quot;header&quot;) %&gt;% align(align = &quot;center&quot;, part = &quot;all&quot;) %&gt;% align(j=&quot;Pathologist X&quot;, align= &quot;left&quot;, part = &quot;all&quot;) %&gt;% autofit() %&gt;% empty_blanks() %&gt;% fix_border_issues() %&gt;% set_caption(caption = &quot;Table 8.7&quot;) %&gt;% #set_table_properties(width = .75, layout = &quot;autofit&quot;) %&gt;% hline_top(part=&quot;header&quot;, border = big_border) %&gt;% hline_bottom(part=&quot;body&quot;, border = big_border) .tabwid table{ border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 5px; margin-bottom: 5px; table-layout: fixed; border-spacing: 0; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-3e836e20{border-collapse:collapse;}.cl-3e7da648{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-3e7da65c{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-3e7db1ec{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:3pt;padding-top:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;}.cl-3e7db200{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:3pt;padding-top:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;}.cl-3e7ddd84{width:40pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3e7ddd98{width:27pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3e7ddda2{width:15pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3e7dddac{width:80pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3e7dddb6{width:80pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3e7dddc0{width:40pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3e7dddca{width:27pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3e7dddd4{width:15pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3e7dddde{width:80pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3e7ddddf{width:80pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3e7ddde8{width:15pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3e7dddf2{width:40pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3e7dddfc{width:27pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3e7dddfd{width:80pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3e7dde06{width:80pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3e7dde10{width:27pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3e7dde11{width:80pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3e7dde1a{width:40pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3e7dde24{width:80pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3e7dde25{width:15pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3e7dde2e{width:27pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3e7dde38{width:80pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3e7dde39{width:40pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3e7dde42{width:15pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3e7dde4c{width:80pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3e7dde56{width:15pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3e7dde57{width:27pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3e7dde6a{width:80pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3e7dde6b{width:40pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3e7dde74{width:80pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 8: Table 8.7 Pathologist XPathologist YTotal1234122220262571402630236038401171028Total27126910118 8.5.2 Cell Residuals for Independence Model 8.5.3 Quasi-Independence Model Pathology &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Pathologists.dat&quot;, header = TRUE, stringsAsFactors = TRUE) Pathology # diag: separate category (1, 2, 3, 4) for each main-diagonal cell X Y count diag 1 1 1 22 1 2 1 2 2 0 3 1 3 2 0 4 1 4 0 0 5 2 1 5 0 6 2 2 7 2 7 2 3 14 0 8 2 4 0 0 9 3 1 0 0 10 3 2 2 0 11 3 3 36 3 12 3 4 0 0 13 4 1 0 0 14 4 2 1 0 15 4 3 17 0 16 4 4 10 4 # and a single (0) for all other cells fit &lt;- glm(count ~ factor(X) + factor(Y) + factor(diag), family = poisson, data = Pathology) # quasi independence, not showing intercept or main effects summary(fit) Call: glm(formula = count ~ factor(X) + factor(Y) + factor(diag), family = poisson, data = Pathology) Deviance Residuals: 1 2 3 4 5 6 7 8 0.00000 1.19586 -0.74802 -0.00006 1.48661 0.00000 -0.66364 -0.00014 9 10 11 12 13 14 15 16 -1.23667 0.63080 0.00000 -0.00008 -1.93254 -1.35095 1.02517 0.00000 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -0.7700 0.6979 -1.103 0.26986 factor(X)2 1.6321 0.5604 2.912 0.00359 ** factor(X)3 0.5017 0.9261 0.542 0.58801 factor(X)4 1.3946 0.5551 2.512 0.01199 * factor(Y)2 0.4796 0.6552 0.732 0.46414 factor(Y)3 1.9493 0.4971 3.921 8.80e-05 *** factor(Y)4 -19.3097 4988.8789 -0.004 0.99691 factor(diag)1 3.8611 0.7297 5.291 1.22e-07 *** factor(diag)2 0.6042 0.6900 0.876 0.38119 factor(diag)3 1.9025 0.8367 2.274 0.02298 * factor(diag)4 20.9877 4988.8789 0.004 0.99664 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for poisson family taken to be 1) Null deviance: 190.398 on 15 degrees of freedom Residual deviance: 13.178 on 5 degrees of freedom AIC: 75.997 Number of Fisher Scoring iterations: 17 8.5.4 Quasi Independence and Odds Ratios Summarizing Agreement \\[\\tau_{ab} = \\mathrm{exp}(\\delta_a + \\delta_b).\\] 8.5.5 Kappa Summary Measure of Agreement \\[\\kappa = \\frac{\\sum_i\\pi_{ii}-\\sum_i\\pi_{i+}\\pi_{+i}}{1-\\sum_i\\pi_{i+}\\pi_{+i}}\\] library(psych) dat &lt;- matrix(Pathology$count, ncol = 4, byrow = TRUE) cohen.kappa(dat) Call: cohen.kappa1(x = x, w = w, n.obs = n.obs, alpha = alpha, levels = levels) Cohen Kappa and Weighted Kappa correlation coefficients and confidence boundaries lower estimate upper unweighted kappa 0.38 0.49 0.60 weighted kappa 0.78 0.78 0.78 Number of subjects = 118 8.6 Bradley-Terry Model for Paired Preferences * `Table 8.8` &lt;- tibble(Winner = c(&quot;Djokovic&quot;, &quot;Federer&quot;, &quot;Murray&quot;, &quot;Nadal&quot;, &quot;Wawrinka&quot;), Djokovic = c(&quot;-&quot;, 6, 3, 2, 3), Federer = c(9, &quot;-&quot;, 0 ,1 , 2), Murray = c(14, 5, &quot;-&quot;, 4, 2), Nadal = c(9, 5, 2, &quot;-&quot;, 3), Wawrinka = c(4, 7, 2, 4, &quot;-&quot;)) theHeader &lt;- data.frame(col_keys = c(&quot;Winner&quot;, &quot;Blank&quot;, &quot;Djokovic&quot;, &quot;Federer&quot;, &quot;Murray&quot;, &quot;Nadal&quot;, &quot;Wawrinka&quot;), line1 = c(&quot;Winner&quot;, &quot;&quot;, rep(&quot;Looser&quot;, 5)), line2 = c(&quot;Winner&quot;, &quot;&quot;, &quot;Djokovic&quot;, &quot;Federer&quot;, &quot;Murray&quot;, &quot;Nadal&quot;, &quot;Wawrinka&quot;)) library(flextable) library(dplyr) library(officer) big_border = fp_border(color=&quot;black&quot;, width = 2) flextable(`Table 8.8`, col_keys = theHeader$col_keys) %&gt;% set_header_df( mapping = theHeader, key = &quot;col_keys&quot; ) %&gt;% theme_booktabs() %&gt;% merge_v(part = &quot;header&quot;) %&gt;% merge_h(part = &quot;header&quot;) %&gt;% align(align = &quot;center&quot;, part = &quot;all&quot;) %&gt;% align(j=&quot;Winner&quot;, align= &quot;left&quot;, part = &quot;all&quot;) %&gt;% autofit() %&gt;% empty_blanks() %&gt;% fix_border_issues() %&gt;% set_caption(caption = &quot;Resuls of 2014-2018 matches for men tennis players.&quot;) %&gt;% #set_table_properties(width = .75, layout = &quot;autofit&quot;) %&gt;% hline_top(part=&quot;header&quot;, border = big_border) %&gt;% hline_bottom(part=&quot;body&quot;, border = big_border) .tabwid table{ border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 5px; margin-bottom: 5px; table-layout: fixed; border-spacing: 0; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-3f083182{border-collapse:collapse;}.cl-3f0365e4{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-3f0365f8{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-3f03712e{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:3pt;padding-top:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;}.cl-3f037138{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:3pt;padding-top:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;}.cl-3f039c3a{width:15pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039c4e{width:63pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039c58{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039c62{width:49pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039c6c{width:44pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039c76{width:57pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039c80{width:63pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039c8a{width:63pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039c8b{width:44pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039c94{width:57pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039c95{width:15pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039d0c{width:63pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039d16{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039d20{width:49pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039d21{width:63pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039d2a{width:63pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039d34{width:44pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039d35{width:57pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039d3e{width:49pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039d48{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039d52{width:15pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039d53{width:57pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039d66{width:63pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039d70{width:49pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039d71{width:15pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039d7a{width:63pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039d84{width:44pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039d8e{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039d98{width:15pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039da2{width:63pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039dac{width:63pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039dad{width:49pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039db6{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039dc0{width:44pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039dca{width:57pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039dcb{width:44pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039dd4{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039dde{width:57pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039ddf{width:63pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039de8{width:63pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3f039de9{width:49pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 9: Resuls of 2014-2018 matches for men tennis players. WinnerLooserDjokovicFedererMurrayNadalWawrinkaDjokovic-91494Federer6-557Murray30-22Nadal214-4Wawrinka3223- 8.6.1 The Bradley-Terry Model of Quasi-Symmetry \\[\\mathrm{logit}(\\Pi_{ij}) = \\mathrm{log}(\\Pi_{ij}/\\Pi_{ji}) = \\beta_i - \\beta_j.\\] \\[\\hat\\Pi_{ij} = \\mathrm{exp}(\\hat\\beta_i - \\hat\\beta_j)/[1 + \\mathrm{exp}(\\hat\\beta_i - \\hat\\beta_j)].\\] 8.6.2 Example: Ranking Men Tennis Players Tennis &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Tennis.dat&quot;, header = TRUE, stringsAsFactors = TRUE) # Djokovic won 9 lost 6 vs Fed # Federer always beat Murray fit &lt;- glm(nij/(nij + nji) ~ -1 + Djokovic + Federer + Murray + Nadal + Wawrinka, family = binomial, weights = nij + nji, data = Tennis) summary(fit) Call: glm(formula = nij/(nij + nji) ~ -1 + Djokovic + Federer + Murray + Nadal + Wawrinka, family = binomial, data = Tennis, weights = nij + nji) Deviance Residuals: Min 1Q Median 3Q Max -1.1225 -0.1262 0.3715 0.5386 1.2928 Coefficients: (1 not defined because of singularities) Estimate Std. Error z value Pr(&gt;|z|) Djokovic 1.17612 0.49952 2.354 0.0185 * Federer 1.13578 0.51095 2.223 0.0262 * Murray -0.56852 0.56833 -1.000 0.3172 Nadal -0.06185 0.51487 -0.120 0.9044 Wawrinka NA NA NA NA --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 26.8960 on 10 degrees of freedom Residual deviance: 4.3958 on 6 degrees of freedom AIC: 34.041 Number of Fisher Scoring iterations: 4 \\[\\hat\\Pi_{ij} = \\frac{\\mathrm{exp}(\\hat\\beta_i - \\hat\\beta_j)}{1 + \\mathrm{exp}(\\hat\\beta_i - \\hat\\beta_j)} = \\frac{\\mathrm{exp}(1.136 - 1.176)}{1 + \\mathrm{exp}(1.136 - 1.176)} = 0.49\\] "],["Marginal.html", "9 Marginal Modeling of Correlated, Clustered Responses 9.1 Marginal Models Vs Subject-Specific Models 9.2 Marginal Modeling: The Generalized Estimating Equations (GEE) Approach 9.3 Marginal Modeling for Clustered Multinomial Responses 9.4 Transitional Modeling, Given the Past 9.5 Dealing with Missing Data *", " 9 Marginal Modeling of Correlated, Clustered Responses 9.1 Marginal Models Vs Subject-Specific Models 9.1.1 Marginal Models for a Clustered Binary Response 9.1.2 Example: Repeated Responses on Similar Survey Questions Abortion &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Abortion.dat&quot;, header = TRUE, stringsAsFactors = TRUE) library(tidyverse) a_wide &lt;- Abortion %&gt;% tidyr::pivot_wider(id_cols = c(person, gender), # do not pivot names_from=situation, # variable with situation number names_prefix = &quot;sit&quot;, # new name prefix values_from = response) %&gt;% # mutate(pattern = paste(sit1, sit2, sit3, sep = &quot;,&quot;)) %&gt;% # make word with pattern mutate(pattern = factor(pattern, levels = c(&quot;1,1,1&quot;, &quot;1,1,0&quot;, &quot;0,1,1&quot;, &quot;0,1,0&quot;, &quot;1,0,1&quot;, &quot;1,0,0&quot;, &quot;0,0,1&quot;,&quot;0,0,0&quot;), ordered = TRUE)) `Table 9.1` &lt;- as.data.frame.matrix(xtabs( ~ a_wide$gender + a_wide$pattern ), row = 2 ) %&gt;% bind_cols(Gender = c(&quot;Male&quot;, &quot;Female&quot;)) %&gt;% # add sex select(Gender, everything()) # reorder columns theHeader &lt;- data.frame(col_keys = colnames(`Table 9.1`), line1 = c(&quot;Gender&quot;, rep(&quot;Sequene of Responses in Three Situations&quot;, 8)), line2 = colnames(`Table 9.1`)) library(flextable) flextable(`Table 9.1`, col_keys = theHeader$col_keys) %&gt;% set_header_df( mapping = theHeader, key = &quot;col_keys&quot; ) %&gt;% theme_booktabs() %&gt;% merge_v(part = &quot;header&quot;) %&gt;% merge_h(part = &quot;header&quot;) %&gt;% align(align = &quot;center&quot;, part = &quot;all&quot;) %&gt;% align(j=&quot;Gender&quot;, align= &quot;left&quot;, part = &quot;all&quot;) %&gt;% #autofit() %&gt;% empty_blanks() %&gt;% fix_border_issues() %&gt;% set_caption(caption = &quot;Support (1 = yes, 0 = no) for legalized abortion in three situations, by gender&quot;) %&gt;% set_table_properties(width = .75, layout = &quot;autofit&quot;) .tabwid table{ border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 5px; margin-bottom: 5px; table-layout: fixed; border-spacing: 0; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-3fb48554{table-layout:auto;border-collapse:collapse;width:75%;}.cl-3fb07cac{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-3fb087f6{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:3pt;padding-top:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;}.cl-3fb0880a{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:3pt;padding-top:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;}.cl-3fb0af42{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3fb0af56{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3fb0af60{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3fb0af61{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3fb0af74{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3fb0af7e{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3fb0af88{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3fb0af89{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 10: Support (1 = yes, 0 = no) for legalized abortion in three situations, by gender GenderSequene of Responses in Three Situations1,1,11,1,00,1,10,1,01,0,11,0,00,0,10,0,0Male34226621113219356Female440251418144722457 9.1.3 Subject-Specific Models for a Repeated Response 9.2 Marginal Modeling: The Generalized Estimating Equations (GEE) Approach 9.2.1 Quasi-Likelihood Methods 9.2.2 Generalized Estimating Equation Methodology: Basic Ideas 9.2.3 Example: Opinion about Legalized Abortion Revisited Abortion &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Abortion.dat&quot;, header = TRUE, stringsAsFactors = TRUE) library(tidyverse) Abortion %&gt;% filter(row_number() %in% c(1, 2, 3, n()-2, n()-1, n())) person gender situation response 1 1 1 1 1 2 1 1 2 1 3 1 1 3 1 4 1850 0 1 0 5 1850 0 2 0 6 1850 0 3 0 Abortion &lt;- Abortion %&gt;% mutate(sit = factor(situation, levels = c(3, 1, 2))) fit.glm &lt;- glm(response ~ sit + gender, family = binomial, data = Abortion) # ML estimate for 5550 independent observations summary(fit.glm) Call: glm(formula = response ~ sit + gender, family = binomial, data = Abortion) Deviance Residuals: Min 1Q Median 3Q Max -1.189 -1.148 -1.125 1.207 1.231 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -0.125408 0.055601 -2.255 0.0241 * sit1 0.149347 0.065825 2.269 0.0233 * sit2 0.052018 0.065843 0.790 0.4295 gender 0.003582 0.054138 0.066 0.9472 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 7689.5 on 5549 degrees of freedom Residual deviance: 7684.2 on 5546 degrees of freedom AIC: 7692.2 Number of Fisher Scoring iterations: 3 library(gee) # cluster on &quot;id&quot; variable fit.gee &lt;- gee(response ~ sit + gender, id = person, family = binomial, corstr = &quot;independence&quot;, data = Abortion) Beginning Cgee S-function, @(#) geeformula.q 4.13 98/01/27 running glm to get initial regression estimate (Intercept) sit1 sit2 gender -0.125407576 0.149347113 0.052017989 0.003582051 summary(fit.gee) GEE: GENERALIZED LINEAR MODELS FOR DEPENDENT DATA gee S-function, version 4.13 modified 98/01/27 (1998) Model: Link: Logit Variance to Mean Relation: Binomial Correlation Structure: Independent Call: gee(formula = response ~ sit + gender, id = person, data = Abortion, family = binomial, corstr = &quot;independence&quot;) Summary of Residuals: Min 1Q Median 3Q Max -0.5068800 -0.4825552 -0.4686891 0.5174448 0.5313109 Coefficients: Estimate Naive S.E. Naive z Robust S.E. Robust z (Intercept) -0.125407576 0.05562131 -2.25466795 0.06758236 -1.85562596 sit1 0.149347113 0.06584875 2.26803253 0.02973865 5.02198759 sit2 0.052017989 0.06586692 0.78974374 0.02704704 1.92324166 gender 0.003582051 0.05415761 0.06614123 0.08784012 0.04077921 Estimated Scale Parameter: 1.000721 Number of Iterations: 1 Working Correlation [,1] [,2] [,3] [1,] 1 0 0 [2,] 0 1 0 [3,] 0 0 1 fit.gee2 &lt;- gee(response ~ sit + gender, id = person, family = binomial, corstr = &quot;exchangeable&quot;, data = Abortion) Beginning Cgee S-function, @(#) geeformula.q 4.13 98/01/27 running glm to get initial regression estimate (Intercept) sit1 sit2 gender -0.125407576 0.149347113 0.052017989 0.003582051 summary(fit.gee2) GEE: GENERALIZED LINEAR MODELS FOR DEPENDENT DATA gee S-function, version 4.13 modified 98/01/27 (1998) Model: Link: Logit Variance to Mean Relation: Binomial Correlation Structure: Exchangeable Call: gee(formula = response ~ sit + gender, id = person, data = Abortion, family = binomial, corstr = &quot;exchangeable&quot;) Summary of Residuals: Min 1Q Median 3Q Max -0.5068644 -0.4825396 -0.4687095 0.5174604 0.5312905 Coefficients: Estimate Naive S.E. Naive z Robust S.E. Robust z (Intercept) -0.125325730 0.06782579 -1.84775925 0.06758212 -1.85442135 sit1 0.149347107 0.02814374 5.30658404 0.02973865 5.02198729 sit2 0.052017986 0.02815145 1.84779075 0.02704703 1.92324179 gender 0.003437873 0.08790630 0.03910838 0.08784072 0.03913758 Estimated Scale Parameter: 1.000721 Number of Iterations: 2 Working Correlation [,1] [,2] [,3] [1,] 1.0000000 0.8173308 0.8173308 [2,] 0.8173308 1.0000000 0.8173308 [3,] 0.8173308 0.8173308 1.0000000 fit.geeUn &lt;- gee(response ~ sit + gender, id = person, family = binomial, corstr = &quot;unstructured&quot;, data = Abortion) Beginning Cgee S-function, @(#) geeformula.q 4.13 98/01/27 running glm to get initial regression estimate (Intercept) sit1 sit2 gender -0.125407576 0.149347113 0.052017989 0.003582051 summary(fit.geeUn)$working.correlation [,1] [,2] [,3] [1,] 1.0000000 0.8248498 0.7958825 [2,] 0.8248498 1.0000000 0.8312594 [3,] 0.7958825 0.8312594 1.0000000 9.2.4 Limitations of GEE Compared to ML library(geepack) # geepack library enables Wald tests comparing models fit &lt;- geeglm(response ~ gender + factor(situation) , id = person, family = binomial, corstr = &quot;exchangeable&quot;, data = Abortion) anova(fit) Analysis of &#39;Wald statistic&#39; Table Model: binomial, link: logit Response: response Terms added sequentially (first to last) Df X2 P(&gt;|Chi|) gender 1 0.0017 0.9675 factor(situation) 2 26.0171 2.241e-06 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 9.3 Marginal Modeling for Clustered Multinomial Responses 9.3.1 Example: Insomnia Study \\[\\hat\\beta_1 = 1.038\\ (0.168),\\ \\hat\\beta_2 = 0.034\\ (0.238),\\ \\hat\\beta_3 = 0.708\\ (0.224)\\] Insomnia &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Insomnia.dat&quot;, header = TRUE, stringsAsFactors = TRUE) Insomnia %&gt;% filter(row_number() %in% c(1, 2, n()-1, n())) case treat occasion response 1 1 1 0 1 2 1 1 1 1 3 127 0 0 4 4 127 0 1 4 library(multgee) fit &lt;- ordLORgee(response ~ occasion + treat + occasion:treat, id = case, LORstr = &quot;independence&quot;, data = Insomnia) summary(fit) GEE FOR ORDINAL MULTINOMIAL RESPONSES version 1.6.0 modified 2017-07-10 Link : Cumulative logit Local Odds Ratios: Structure: independence call: ordLORgee(formula = response ~ occasion + treat + occasion:treat, data = Insomnia, id = case, LORstr = &quot;independence&quot;) Summary of residuals: Min. 1st Qu. Median Mean 3rd Qu. Max. -0.3804488 -0.2952858 -0.1886117 0.0002019 -0.0938856 0.9061144 Number of Iterations: 1 Coefficients: Estimate san.se san.z Pr(&gt;|san.z|) beta10 -2.26709 0.21876 -10.3633 &lt; 2e-16 *** beta20 -0.95146 0.18092 -5.2591 &lt; 2e-16 *** beta30 0.35174 0.17842 1.9714 0.04868 * occasion 1.03808 0.16759 6.1943 &lt; 2e-16 *** treat 0.03361 0.23844 0.1410 0.88790 occasion:treat 0.70776 0.24352 2.9064 0.00366 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Local Odds Ratios Estimates: [,1] [,2] [,3] [,4] [,5] [,6] [1,] 0 0 0 1 1 1 [2,] 0 0 0 1 1 1 [3,] 0 0 0 1 1 1 [4,] 1 1 1 0 0 0 [5,] 1 1 1 0 0 0 [6,] 1 1 1 0 0 0 pvalue of Null model: &lt;0.0001 9.3.2 Alternative GEE Specification of Working Association 9.4 Transitional Modeling, Given the Past 9.4.1 Transitional Models with Explanatory Variables \\[\\mathrm{logit}[P(Y_t = 1)] = \\alpha + \\beta y_{t-1} + \\beta_1 x_{1t} + \\cdots + \\beta_p x_{pt},\\] 9.4.2 Example: Respiratory Illness and Maternal Smoking \\[\\mathrm{logit}[P(Y_t = 1)] = \\alpha + \\beta y_{t-1} + \\beta_1 s + \\beta_2 t,\\ t = 8, 9, 10\\] Respiratory &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Respiratory.dat&quot;, header = TRUE, stringsAsFactors = TRUE) Respiratory no yes previous s t 1 283 17 0 0 10 2 30 20 1 0 10 3 140 12 0 1 10 4 21 14 1 1 10 5 274 24 0 0 9 6 26 26 1 0 9 7 134 14 0 1 9 8 18 21 1 1 9 9 266 28 0 0 8 10 32 24 1 0 8 11 134 22 0 1 8 12 14 17 1 1 8 fit &lt;- glm(yes/(yes+no) ~ previous + s + t, family = binomial, weights = no + yes, data = Respiratory) summary(fit) Call: glm(formula = yes/(yes + no) ~ previous + s + t, family = binomial, data = Respiratory, weights = no + yes) Deviance Residuals: Min 1Q Median 3Q Max -0.98143 -0.30047 -0.09456 0.36684 0.96039 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -0.29256 0.84603 -0.346 0.7295 previous 2.21107 0.15819 13.977 &lt;2e-16 *** s 0.29596 0.15634 1.893 0.0583 . t -0.24281 0.09466 -2.565 0.0103 * --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 207.2212 on 11 degrees of freedom Residual deviance: 3.1186 on 8 degrees of freedom AIC: 64.392 Number of Fisher Scoring iterations: 3 car::Anova(fit) Analysis of Deviance Table (Type II tests) Response: yes/(yes + no) LR Chisq Df Pr(&gt;Chisq) previous 192.331 1 &lt; 2e-16 *** s 3.546 1 0.05969 . t 6.649 1 0.00992 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 9.4.3 Group Comparisons Treating Initial Response as Covariate \\[\\begin{equation} \\mathrm{logit}[P(Y_2 \\le j)] = \\alpha_j + \\beta_1 x + \\beta_2 y_1 \\tag{25} \\end{equation}\\] Insomnia2 &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Insomnia2.dat&quot;, header = TRUE, stringsAsFactors = TRUE) Insomnia2 treatment initial follow1 follow2 follow3 follow4 1 1 10 7 4 1 0 2 1 25 11 5 2 2 3 1 45 13 23 3 1 4 1 75 9 17 13 8 5 0 10 7 4 2 1 6 0 25 14 5 1 0 7 0 45 6 9 18 2 8 0 75 4 11 14 22 library(VGAM) fit &lt;- vglm(cbind(follow1, follow2, follow3, follow4) ~ treatment + initial, family = cumulative(parallel = TRUE), data = Insomnia2) summary(fit) Call: vglm(formula = cbind(follow1, follow2, follow3, follow4) ~ treatment + initial, family = cumulative(parallel = TRUE), data = Insomnia2) Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept):1 0.581161 0.318824 1.823 0.068330 . (Intercept):2 2.277442 0.355043 6.415 1.41e-10 *** (Intercept):3 3.750952 0.399804 9.382 &lt; 2e-16 *** treatment 0.884679 0.245552 3.603 0.000315 *** initial -0.042106 0.005796 -7.264 3.75e-13 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Names of linear predictors: logitlink(P[Y&lt;=1]), logitlink(P[Y&lt;=2]), logitlink(P[Y&lt;=3]) Residual deviance: 34.7689 on 19 degrees of freedom Log-likelihood: -50.5177 on 19 degrees of freedom Number of Fisher scoring iterations: 5 No Hauck-Donner effect found in any of the estimates Exponentiated coefficients: treatment initial 2.4222064 0.9587682 detach(&quot;package:multgee&quot;, unload = TRUE) detach(&quot;package:VGAM&quot;, unload = TRUE) # contains function s that conflicts with gam 9.5 Dealing with Missing Data * 9.5.1 Missing at Random: Impact on ML and GEE Methods 9.5.2 Multiple Imputation: Monte Carlo Prediction of missing Data "],["Random.html", "10 Random Effects: Generalized Linear Mixed Models 10.1 Random Effects Modeling of Clustered Categorical Data 10.2 Examples: Random Effects Models for Binary Data 10.3 Extensions to Multinomial Responses and Multiple Random Effect Terms 10.4 Multilevel (Hierarchical) Models 10.5 Latent Class Models * Exercises", " 10 Random Effects: Generalized Linear Mixed Models 10.1 Random Effects Modeling of Clustered Categorical Data 10.1.1 The Generalized Linear Mixed Model (GLMM) \\[\\begin{equation} g(u_{it}) = u_i + \\alpha + \\beta_1 x_{it1}+ \\dots + \\beta_p x_{itp},\\ i = 1, \\dots, n,\\ t = 1, \\dots, T. \\tag{26} \\end{equation}\\] 10.1.2 A Logistic GLMM for Binary Matched Pairs \\[\\begin{equation} \\mathrm{logit}[P(Y_{i1}= 1)] = u_i + \\alpha + \\beta,\\ \\ \\mathrm{logit}[P(Y_{i2}= 1)] = u_i + \\alpha \\tag{27} \\end{equation}\\] 10.1.3 Example: Environmental Opinions Revised Opinions &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Envir_opinions.dat&quot;, header = TRUE, stringsAsFactors = TRUE) # Make contingency table tab &lt;- as.matrix(addmargins(xtabs(~y1 + y2, data = Opinions))) library(tibble) # Add label as the first column and variable names `Table 10.1` &lt;- tibble(`Pay Higher Taxes` = c(&quot;Yes&quot;, &quot;No&quot;, &quot;Total&quot;), Yes = tab[,1], No = tab[,2], Total = tab[,3]) library(flextable) my_header &lt;- data.frame( col_keys = colnames(`Table 10.1`), line1 = c(&quot;Pay Higher Taxes&quot;, rep(&quot;Cut Living Standards&quot;, 2), &quot;Total&quot;), line2 = colnames(`Table 10.1`) ) flextable(`Table 10.1`, col_keys = my_header$col_keys) %&gt;% set_header_df( mapping = my_header, key = &quot;col_keys&quot; ) %&gt;% theme_booktabs() %&gt;% autofit(part = &quot;all&quot;) %&gt;% align(align = &quot;center&quot;, part = &quot;all&quot;) %&gt;% merge_h(part = &quot;header&quot;) %&gt;% merge_v(part = &quot;header&quot;) %&gt;% merge_h(part = &quot;body&quot;) %&gt;% merge_v(part = &quot;body&quot;) %&gt;% align_nottext_col(align = &quot;center&quot;) %&gt;% set_caption(caption = &quot;Opinions relating to the environment&quot;) .tabwid table{ border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 5px; margin-bottom: 5px; table-layout: fixed; border-spacing: 0; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-41edd866{border-collapse:collapse;}.cl-41e9ada4{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-41e9b970{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:3pt;padding-top:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;}.cl-41e9d9d2{width:43pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-41e9d9e6{width:117pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-41e9d9fa{width:103pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-41e9da04{width:103pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-41e9da05{width:43pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-41e9da0e{width:117pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-41e9da18{width:117pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-41e9da22{width:103pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-41e9da2c{width:43pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-41e9da36{width:117pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-41e9da40{width:103pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-41e9da41{width:43pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-41e9da4a{width:117pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-41e9da54{width:103pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-41e9da55{width:43pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 11: Opinions relating to the environment Pay Higher TaxesCut Living StandardsTotalYesNoYes227132359No107678785Total3348101,144 Opinions &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Opinions.dat&quot;, header = TRUE, stringsAsFactors = TRUE) Opinions %&gt;% filter(row_number() %in% c(1, 2, n()-1, n())) person question y 1 1 1 1 2 1 0 1 3 1144 1 0 4 1144 0 0 # library(lme4) # fit GLMM by adaptive Gaussian quadrature, # with nAGQ quadrature points, as 10.1.5 explains # (1|person) is random intercept for person fit &lt;- lme4::glmer(y ~ (1|person) + question, family = binomial, nAGQ = 50, data = Opinions) Registered S3 methods overwritten by &#39;lme4&#39;: method from cooks.distance.influence.merMod car influence.merMod car dfbeta.influence.merMod car dfbetas.influence.merMod car summary(fit) Generalized linear mixed model fit by maximum likelihood (Adaptive Gauss-Hermite Quadrature, nAGQ = 50) [glmerMod] Family: binomial ( logit ) Formula: y ~ (1 | person) + question Data: Opinions AIC BIC logLik deviance df.resid 2526.8 2544.0 -1260.4 2520.8 2285 Scaled residuals: Min 1Q Median 3Q Max -0.8872 -0.2691 -0.2423 0.4646 1.2519 Random effects: Groups Name Variance Std.Dev. person (Intercept) 8.143 2.854 Number of obs: 2288, groups: person, 1144 Fixed effects: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -1.8343 0.1624 -11.295 &lt;2e-16 *** question 0.2100 0.1301 1.614 0.106 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) question -0.452 10.1.4 Differing Effects in GLMMs and Marginal Models 10.1.5 Model Fitting for GLMMs 10.1.6 Inference for Model Parameters and Prediction 10.2 Examples: Random Effects Models for Binary Data 10.2.1 Small-Area Estimation of Binomial Probabilities \\[\\begin{equation} \\mathrm{logit}[P(Y_{it} = 1)] = \\mathrm{logit}(\\pi_i) = u_i + \\alpha, \\tag{28} \\end{equation}\\] 10.2.2 Example: Estimating Basketball Free Throw Success FreeThrow &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/FreeThrow.dat&quot;, header = TRUE, stringsAsFactors = TRUE) FreeThrow %&gt;% filter(row_number() %in% c(1, n())) player y T 1 Davis.A 32 39 2 Gobert.R 11 14 library(lme4) Loading required package: Matrix Attaching package: &#39;Matrix&#39; The following objects are masked from &#39;package:tidyr&#39;: expand, pack, unpack # (1|player) = random intercepts for each player # nAGQ = number of points for adaptive Gaussian quadrature fit &lt;- glmer(y/T ~ 1 + (1|player), family=binomial, weights = T, nAGQ= 100, data = FreeThrow) summary(fit) Generalized linear mixed model fit by maximum likelihood (Adaptive Gauss-Hermite Quadrature, nAGQ = 100) [glmerMod] Family: binomial ( logit ) Formula: y/T ~ 1 + (1 | player) Data: FreeThrow Weights: T AIC BIC logLik deviance df.resid 33.8 35.7 -14.9 29.8 18 Scaled residuals: Min 1Q Median 3Q Max -1.5111 -0.6988 0.1050 0.5467 1.3008 Random effects: Groups Name Variance Std.Dev. player (Intercept) 0.1807 0.4251 Number of obs: 20, groups: player, 20 Fixed effects: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) 1.174 0.181 6.484 8.95e-11 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 fitted(fit) # estimated prob&#39;s for 20 players using predicted random effects 1 2 3 4 5 6 7 8 0.7948554 0.7709709 0.6592042 0.7654111 0.7929072 0.7921630 0.7235316 0.7829412 9 10 11 12 13 14 15 16 0.7110775 0.6664667 0.8087839 0.7550424 0.8005694 0.8053209 0.7341520 0.8087839 17 18 19 20 0.7475986 0.7341520 0.7726096 0.7706175 season &lt;- c(0.80, 0.77, 0.63, 0.81, 0.84, 0.81, 0.83, 0.78, 0.57, 0.39, 0.81, 0.82, 0.81, 0.61, 0.79, 0.74, 0.80, 0.67, 0.77, 0.65) `Table 10.2` &lt;- bind_cols(Player = word(FreeThrow$player, 1, sep = fixed(&quot;.&quot;)), T_i = FreeThrow$T, p_i = round(FreeThrow$y/ FreeThrow$T, 2), hat_pi_i = round(fitted(fit), 2), pi_i = season) library(flextable) flextable(`Table 10.2`) %&gt;% theme_booktabs() %&gt;% fix_border_issues() %&gt;% set_caption(caption = &quot;Estimates of probability of making a free throw, based on data from centers from week 1 of an NBA season.&quot;) %&gt;% set_table_properties(width = .5, layout = &quot;autofit&quot;) %&gt;% flextable::compose(part = &quot;header&quot;, j = &quot;T_i&quot;, value = as_paragraph(&quot;T&quot;, as_sub(&quot;i&quot;))) %&gt;% flextable::compose(part = &quot;header&quot;, j = &quot;p_i&quot;, value = as_paragraph(&quot;p&quot;, as_sub(&quot;i&quot;))) %&gt;% flextable::compose(part = &quot;header&quot;, j = &quot;hat_pi_i&quot;, value = as_paragraph(&quot;\\U1D70B\\U0302&quot;, as_sub(&quot;i&quot;))) %&gt;% flextable::compose(part = &quot;header&quot;, j = &quot;pi_i&quot;, value = as_paragraph(&quot;\\U1D70B&quot;, as_sub(&quot;i&quot;))) .tabwid table{ border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 5px; margin-bottom: 5px; table-layout: fixed; border-spacing: 0; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-4355d9b0{table-layout:auto;border-collapse:collapse;width:50%;}.cl-4350dc94{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4350dca8{font-family:'Helvetica';font-size:7pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;position: relative;top:3pt;}.cl-4350e946{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:3pt;padding-top:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;}.cl-4350e95a{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:3pt;padding-top:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;}.cl-4351250a{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-43512528{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-43512532{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-43512533{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4351253c{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-43512546{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 12: Estimates of probability of making a free throw, based on data from centers from week 1 of an NBA season. PlayerTipi𝜋̂i𝜋iDavis390.820.790.80Cousins490.780.770.77Whiteside210.520.660.63Turner130.770.770.81Gasol190.840.790.84Valanciunas140.860.790.81Towns30.330.720.83Embiid120.830.780.78Nurkic190.630.710.57Drummond160.500.670.39Lopez130.920.810.81Jokic30.670.760.82Dieng61.000.800.81Adams71.000.810.61Kanter80.620.730.79Monroe130.920.810.74Horford60.670.750.80Vucevic80.620.730.67Muscala100.800.770.77Gobert140.790.770.65 # compose is also used by purrr (and igraph) # Unicode is a hat over the next character and U1D70B is pi summary(glm(y/T ~ 1, family = binomial, weights = T, data = FreeThrow)) Call: glm(formula = y/T ~ 1, family = binomial, data = FreeThrow, weights = T) Deviance Residuals: Min 1Q Median 3Q Max -2.3217 -0.8336 0.2710 0.9268 1.9710 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) 1.1400 0.1363 8.361 &lt;2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 31.322 on 19 degrees of freedom Residual deviance: 31.322 on 19 degrees of freedom AIC: 81.032 Number of Fisher Scoring iterations: 4 10.2.3 Example: Opinions about Legalizing Abortion Revised Abortion &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Abortion.dat&quot;, header = TRUE, stringsAsFactors = TRUE) %&gt;% mutate(sit = factor(situation, levels = c(3,1,2))) Abortion %&gt;% filter(row_number() %in% c(1:3, n()-2, n()-1, n())) person gender situation response sit 1 1 1 1 1 1 2 1 1 2 1 2 3 1 1 3 1 3 4 1850 0 1 0 1 5 1850 0 2 0 2 6 1850 0 3 0 3 fit &lt;- lme4::glmer(response ~ (1 | person) + sit + gender, family = binomial, nAGQ = 100, data = Abortion) summary(fit) Generalized linear mixed model fit by maximum likelihood (Adaptive Gauss-Hermite Quadrature, nAGQ = 100) [glmerMod] Family: binomial ( logit ) Formula: response ~ (1 | person) + sit + gender Data: Abortion AIC BIC logLik deviance df.resid 4588.5 4621.6 -2289.3 4578.5 5545 Scaled residuals: Min 1Q Median 3Q Max -1.7810 -0.1223 -0.1055 0.1396 1.7149 Random effects: Groups Name Variance Std.Dev. person (Intercept) 76.49 8.746 Number of obs: 5550, groups: person, 1850 Fixed effects: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -0.61937 0.37816 -1.638 0.101 sit1 0.83478 0.16007 5.215 1.84e-07 *** sit2 0.29245 0.15670 1.866 0.062 . gender 0.01262 0.48970 0.026 0.979 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) sit1 sit2 sit1 -0.218 sit2 -0.211 0.508 gender -0.725 0.000 0.000 10.2.4 Item Response Models: The Rasch Model 10.2.5 Choice of Marginal Model or Random Effects Model 10.3 Extensions to Multinomial Responses and Multiple Random Effect Terms 10.3.1 Example: Insomnia Study Revisited Insomnia &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Insomnia.dat&quot;, header = TRUE, stringsAsFactors = TRUE) Insomnia %&gt;% filter(row_number() %in% c(1, 2, n()-1, n())) case treat occasion response 1 1 1 0 1 2 1 1 1 1 3 127 0 0 4 4 127 0 1 4 # response var. from clmm must be a factor fit &lt;- ordinal::clmm(factor(response) ~ (1|case) + occasion + treat + occasion:treat, nAGQ = 20, data = Insomnia) summary(fit) Cumulative Link Mixed Model fitted with the adaptive Gauss-Hermite quadrature approximation with 20 quadrature points formula: factor(response) ~ (1 | case) + occasion + treat + occasion:treat data: Insomnia link threshold nobs logLik AIC niter max.grad cond.H logit flexible 478 -592.97 1199.94 401(1549) 8.28e-05 6.1e+01 Random effects: Groups Name Variance Std.Dev. case (Intercept) 3.628 1.905 Number of groups: case 239 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) occasion -1.60158 0.28336 -5.652 1.59e-08 *** treat -0.05785 0.36630 -0.158 0.87450 occasion:treat -1.08129 0.38046 -2.842 0.00448 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Threshold coefficients: Estimate Std. Error z value 1|2 -3.4896 0.3588 -9.727 2|3 -1.4846 0.2903 -5.114 3|4 0.5613 0.2702 2.078 library(multgee) fit_multgee &lt;- ordLORgee(response ~ occasion + treat + occasion:treat, id = case, LORstr = &quot;independence&quot;, data = Insomnia) fit_ordinal &lt;- ordinal::clmm(factor(response) ~ (1|case) + occasion + treat + occasion:treat, nAGQ = 20, data = Insomnia) `Table 10.4` &lt;- data.frame(Effect = c(&quot;Occasion&quot;, &quot;Treatment&quot;, &quot;Treatment x Occasion&quot;), mm_coef = c(coef(fit_multgee)[&quot;occasion&quot;], coef(fit_multgee)[&quot;treat&quot;], coef(fit_multgee)[&quot;occasion:treat&quot;]), mm_se = c(coef(summary(fit_multgee))[&quot;occasion&quot;, &quot;san.se&quot;], coef(summary(fit_multgee))[&quot;treat&quot;, &quot;san.se&quot;], coef(summary(fit_multgee))[&quot;occasion:treat&quot;, &quot;san.se&quot;]), # note the -1 because of the (weird negative) model specification re_coef = c(coef(fit_ordinal)[&quot;occasion&quot;], coef(fit_ordinal)[&quot;treat&quot;], coef(fit_ordinal)[&quot;occasion:treat&quot;]) * -1, re_se = c(coef(summary(fit_ordinal))[&quot;occasion&quot;, &quot;Std. Error&quot;], coef(summary(fit_ordinal))[&quot;treat&quot;, &quot;Std. Error&quot;], coef(summary(fit_ordinal))[&quot;occasion:treat&quot;, &quot;Std. Error&quot;])) %&gt;% mutate(across(where(is.numeric), round, 3)) %&gt;% mutate(`Marginal Model GEE` = paste0(mm_coef, &quot; (&quot;, mm_se, &quot;)&quot;)) %&gt;% mutate(`Random Effects Model (GLMM) ML` = paste0(re_coef, &quot; (&quot;, re_se, &quot;)&quot;)) %&gt;% select(Effect, `Marginal Model GEE`, `Random Effects Model (GLMM) ML`) library(flextable) flextable(`Table 10.4`) %&gt;% set_caption(caption = &quot;Results of fitting cumulative logit marginal model and random effects model to Table 9.2, with standard errors in parentheses.&quot;) %&gt;% set_table_properties(width = .75, layout = &quot;autofit&quot;) %&gt;% align(align = &quot;center&quot;, part = &quot;all&quot;) .tabwid table{ border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 5px; margin-bottom: 5px; table-layout: fixed; border-spacing: 0; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-4bdea3b4{table-layout:auto;border-collapse:collapse;width:75%;}.cl-4bdadc84{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4bdae9ae{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:3pt;padding-top:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;}.cl-4bdb0862{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4bdb0876{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4bdb0880{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 13: Results of fitting cumulative logit marginal model and random effects model to Table 9.2, with standard errors in parentheses. EffectMarginal Model GEERandom Effects Model (GLMM) MLOccasion1.038 (0.168)1.602 (0.283)Treatment0.034 (0.238)0.058 (0.366)Treatment x Occasion0.708 (0.244)1.081 (0.38) 10.3.2 Meta-Analysis: Bivariate Random Effects for Association Heterogeneity Ulcers &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Ulcers.dat&quot;, header = TRUE, stringsAsFactors = TRUE) Ulcers %&gt;% filter(row_number() %in% c(1, 2, n()-1, n())) study treat y n 1 1 1 7 15 2 1 0 11 13 3 41 1 0 9 4 41 0 0 16 fit &lt;- lme4::glmer(y/n ~ (1|study) + treat, family = binomial, weights = n, nAGQ = 50, data = Ulcers) summary(fit) Generalized linear mixed model fit by maximum likelihood (Adaptive Gauss-Hermite Quadrature, nAGQ = 50) [glmerMod] Family: binomial ( logit ) Formula: y/n ~ (1 | study) + treat Data: Ulcers Weights: n AIC BIC logLik deviance df.resid 306.1 313.3 -150.0 300.1 79 Scaled residuals: Min 1Q Median 3Q Max -4.1808 -0.7646 0.0229 0.9771 4.5243 Random effects: Groups Name Variance Std.Dev. study (Intercept) 0.6721 0.8198 Number of obs: 82, groups: study, 41 Fixed effects: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -0.3212 0.1500 -2.142 0.0322 * treat -1.1728 0.1176 -9.969 &lt;2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) treat -0.313 \\[\\begin{equation} \\mathrm{logit}[P(Y_{i1}= 1)] = u_i + \\alpha + (\\beta + v_1),\\ \\ \\mathrm{logit}[P(Y_{i2}= 1)] = u_i + \\alpha \\tag{29} \\end{equation}\\] fit2 &lt;- lme4::glmer(y/n ~ (1 + treat|study), family = binomial, weights = n, data = Ulcers) summary(fit2) Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [glmerMod] Family: binomial ( logit ) Formula: y/n ~ (1 + treat | study) Data: Ulcers Weights: n AIC BIC logLik deviance df.resid 466.9 476.5 -229.4 458.9 78 Scaled residuals: Min 1Q Median 3Q Max -1.4935 -0.1543 0.0495 0.2850 1.1408 Random effects: Groups Name Variance Std.Dev. Corr study (Intercept) 3.307 1.819 treat 4.257 2.063 -0.93 Number of obs: 82, groups: study, 41 Fixed effects: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -1.2494 0.1626 -7.682 1.57e-14 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 10.4 Multilevel (Hierarchical) Models 10.4.1 Example: Two-Level Model for Student Performance 10.4.2 Example: Smoking Prevention and Cessation Study Smoking &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Smoking.dat&quot;, header = TRUE, stringsAsFactors = TRUE) `Table 10.6` &lt;- Smoking %&gt;% filter(row_number() %in% c(1, 2, n())) %&gt;% select(-y) library(flextable) flextable(`Table 10.6`) %&gt;% set_caption(caption = &quot;Part of smoking prevention and cessation data file.&quot;) %&gt;% set_table_properties(width = .75, layout = &quot;autofit&quot;) %&gt;% align(align = &quot;center&quot;, part = &quot;all&quot;) .tabwid table{ border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 5px; margin-bottom: 5px; table-layout: fixed; border-spacing: 0; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-4c85de18{table-layout:auto;border-collapse:collapse;width:75%;}.cl-4c81e5f6{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4c81f14a{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:3pt;padding-top:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;}.cl-4c8211a2{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4c8211c0{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4c8211ca{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 14: Part of smoking prevention and cessation data file. studentschoolclassSCTVPTHKTHK1403403,10110232403403,10110441,600515515,1130033 Smoking &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Smoking.dat&quot;, header = TRUE, stringsAsFactors = TRUE) Smoking %&gt;% filter(row_number() %in% c(1, n())) student school class SC TV PTHK THK y 1 1 403 403101 1 0 2 3 1 2 1600 515 515113 0 0 3 3 1 fit &lt;- lme4::glmer(y ~ (1|class) + (1|school) + PTHK + SC + TV, family = binomial, data = Smoking) summary(fit) Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [glmerMod] Family: binomial ( logit ) Formula: y ~ (1 | class) + (1 | school) + PTHK + SC + TV Data: Smoking AIC BIC logLik deviance df.resid 2070.2 2102.5 -1029.1 2058.2 1594 Scaled residuals: Min 1Q Median 3Q Max -2.9905 -0.8823 0.4645 0.8379 2.0923 Random effects: Groups Name Variance Std.Dev. class (Intercept) 0.16728 0.4090 school (Intercept) 0.06413 0.2532 Number of obs: 1600, groups: class, 135; school, 28 Fixed effects: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -1.13163 0.17827 -6.348 2.18e-10 *** PTHK 0.39512 0.04627 8.539 &lt; 2e-16 *** SC 0.80014 0.16893 4.737 2.17e-06 *** TV 0.10786 0.16819 0.641 0.521 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) PTHK SC PTHK -0.576 SC -0.498 0.082 TV -0.494 0.023 -0.005 fit.glm &lt;- glm(y ~ PTHK + SC + TV, family = binomial, data = Smoking) summary(fit.glm) Call: glm(formula = y ~ PTHK + SC + TV, family = binomial, data = Smoking) Deviance Residuals: Min 1Q Median 3Q Max -2.1313 -1.0944 0.6746 1.0936 1.6744 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -1.11920 0.13127 -8.526 &lt; 2e-16 *** PTHK 0.39886 0.04401 9.063 &lt; 2e-16 *** SC 0.76532 0.10563 7.245 4.32e-13 *** TV 0.12305 0.10462 1.176 0.24 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 2212.5 on 1599 degrees of freedom Residual deviance: 2077.2 on 1596 degrees of freedom AIC: 2085.2 Number of Fisher Scoring iterations: 4 10.5 Latent Class Models * 10.5.1 Independence Given a Latent Categorical Variable 10.5.2 Example: Latent Class Model for Rater Agreement Carcinoma &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Carcinoma.dat&quot;, header = TRUE, stringsAsFactors = TRUE) Carcinoma &lt;- -Carcinoma + 2 Carcinoma %&gt;% filter(row_number() %in% c(1, n())) library(poLCA) poLCA(cbind(A, B, C, D, E, F, G) ~ 1, nclass = 1, data = Carcinoma) poLCA(cbind(A, B, C, D, E, F, G) ~ 1, nclass = 2, nrep = 9, data = Carcinoma) poLCA(cbind(A, B, C, D, E, F, G) ~ 1, nclass = 3, nrep = 9, data = Carcinoma) poLCA(cbind(A, B, C, D, E, F, G) ~ 1, nclass = 4, nrep = 9, data = Carcinoma) Exercises "],["Classification.html", "11 Classification and Smoothing 11.1 Classification: Linear Discrinant Analysis 11.2 Classification: Tree-Based Prediction 11.3 Cluster Analysis for Categorical Responses 11.4 Smoothing: Generalized Additive Models 11.5 Regularization for High-Dimensional Categorical Data (Large p)", " 11 Classification and Smoothing 11.1 Classification: Linear Discrinant Analysis 11.1.1 Classification with Fisher’s Linear Discriminant Function 11.1.2 Example: Horseshoe Crab Satellites Revisited Crabs &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Crabs.dat&quot;, header = TRUE, stringsAsFactors = TRUE) library(MASS) lda(y~width + color, data = Crabs) Call: lda(y ~ width + color, data = Crabs) Prior probabilities of groups: 0 1 0.3583815 0.6416185 Group means: width color 0 25.16935 2.725806 1 26.92973 2.279279 Coefficients of linear discriminants: LD1 width 0.4290351 color -0.5517138 fit.lda &lt;- lda(y ~ width + color, prior = c(0.5, 0.5), CV = TRUE, data = Crabs) # if prior note specified, uses sample proportions in the two categories xtabs(~Crabs$y + fit.lda$class) # using cross-validation (CV = TRUE) fit.lda$class Crabs$y 0 1 0 43 19 1 39 72 t1df &lt;- as.data.frame.matrix(xtabs(~Crabs$y + fit.lda$class)) %&gt;% rename(&quot;t1_1&quot; = `1`) %&gt;% rename(&quot;t1_0&quot; = `0`) %&gt;% map_df(rev) prop &lt;- sum(Crabs$y) / nrow(Crabs) prop [1] 0.6416185 fit &lt;- glm(y ~ width + factor(color), family = binomial, data = Crabs) predicted &lt;- as.numeric(fitted(fit) &gt; 0.6416185) # predict y=1 when est. &gt; observed probability t2df &lt;- as.data.frame.matrix(xtabs(~ Crabs$y + predicted)) %&gt;% rename(&quot;t2_1&quot; = `1`) %&gt;% rename(&quot;t2_0&quot; = `0`) %&gt;% map_df(rev) # purrr::map_df(rev) reverses order of the data frame Actual &lt;-tibble(Actual = c(&quot;y = 1&quot;, &quot;y = 0&quot;)) Total &lt;- tibble(Total = c(111, 62)) library(flextable) suppressMessages(conflict_prefer(&quot;compose&quot;, &quot;flextable&quot;)) library(dplyr) # for bind_cols() library(officer) # for fp_border() # Make analysis table `Table 11.1` &lt;- bind_cols(Actual, t1df, t2df, Total) # The header needs blank columns for spaces in actual table. # The wide column labels use Unicode characters for pi. Those details are # replaced later with the compose() function. theHeader &lt;- data.frame( col_keys = c(&quot;Actual&quot;, &quot;blank&quot;, &quot;t1_1&quot;, &quot;t1_0&quot;, &quot;blank2&quot;, &quot;t2_1&quot;, &quot;t2_0&quot;, &quot;blank3&quot;, &quot;Total&quot;), line1 = c(&quot;Actual&quot;, &quot;&quot;, rep(&quot;Discriminat Analysis&quot;, 2), &quot;&quot;, rep(&quot;Logistic Regression&quot;, 2), &quot;&quot;, &quot;Total&quot;), line2 = c(&quot;Actual&quot;, &quot;&quot;, &quot;t1_1&quot;, &quot;t1_0&quot;, &quot;&quot;, &quot;t2_1&quot;, &quot;t2_0&quot;, &quot;&quot;, &quot;Total&quot;)) # Border lines big_border &lt;- fp_border(color=&quot;black&quot;, width = 2) # Make the table - compose uses Unicode character # https://stackoverflow.com/questions/64088118/in-r-flextable-can-complex-symbols-appear-in-column-headings flextable(`Table 11.1`, col_keys = theHeader$col_keys) %&gt;% set_header_df(mapping = theHeader, key = &quot;col_keys&quot;) %&gt;% theme_booktabs() %&gt;% merge_v(part = &quot;header&quot;) %&gt;% merge_h(part = &quot;header&quot;) %&gt;% align(align = &quot;center&quot;, part = &quot;all&quot;) %&gt;% empty_blanks() %&gt;% fix_border_issues() %&gt;% set_caption(caption = &quot;Classification tables for horseshoe crab data with width and factor color predictors. Logistic model does not match book.&quot;) %&gt;% set_table_properties(width = 1, layout = &quot;autofit&quot;) %&gt;% hline_top(part=&quot;header&quot;, border = big_border) %&gt;% hline_bottom(part=&quot;body&quot;, border = big_border) %&gt;% # i = 2 refers to second row of column headings compose(part = &quot;header&quot;, i = 2, j = &quot;t1_1&quot;, value = as_paragraph(&quot;y\\U0302 = 1&quot;)) %&gt;% compose(part = &quot;header&quot;, i = 2, j = &quot;t1_0&quot;, value = as_paragraph(&quot;y\\U0302 = 0&quot;)) %&gt;% compose(part = &quot;header&quot;, i = 2, j = &quot;t2_1&quot;, value = as_paragraph(&quot;y\\U0302 = 1&quot;)) %&gt;% compose(part = &quot;header&quot;, i = 2, j = &quot;t2_0&quot;, value = as_paragraph(&quot;y\\U0302 = 0&quot;)) .tabwid table{ border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 5px; margin-bottom: 5px; table-layout: fixed; border-spacing: 0; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-4d87527e{table-layout:auto;border-collapse:collapse;width:100%;}.cl-4d83011a{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4d830138{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4d830caa{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:3pt;padding-top:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;}.cl-4d833c2a{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4d833c48{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4d833c52{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4d833c5c{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4d833c70{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4d833c7a{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4d833c84{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 15: Classification tables for horseshoe crab data with width and factor color predictors. Logistic model does not match book. ActualDiscriminat AnalysisLogistic RegressionTotalŷ = 1ŷ = 0ŷ = 1ŷ = 0y = 172397536111y = 01943194362 11.1.3 Discriminant Analysis Versus Logistic Regression 11.2 Classification: Tree-Based Prediction 11.2.1 Classification Trees 11.2.2 Example: A classification Tree for Horseshoe Crab Mating Crabs &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Crabs.dat&quot;, header = TRUE, stringsAsFactors = TRUE) library(rpart) fit &lt;- rpart(y ~ color + width, method = &quot;class&quot;, data = Crabs) p.fit &lt;- prune(fit, cp = 0.02) library(rpart.plot) rpart.plot(p.fit, extra = 1, digits = 4, box.palette = 0) 11.2.3 How Does the Classification Tree Grow? 11.2.4 Pruning a Tree and Checking Prediction Accuracy Crabs &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Crabs.dat&quot;, header = TRUE, stringsAsFactors = TRUE) library(rpart) # method = &quot;class&quot; for categorical y fit &lt;- rpart(y ~ color + width, method = &quot;class&quot;, data = Crabs) # plots error rate by cp = complexity parameter for pruning plotcp(fit) # select leftmost cp with mean error below horizontal line (1SE above min.) p.fit &lt;- prune(fit, cp = 0.056) library(rpart.plot) rpart.plot(p.fit, extra = 1, digits = 4, box.palette = 0) 11.2.5 Classification Trees Versus Logistic Regression and Discriminant Analysis 11.3 Cluster Analysis for Categorical Responses 11.3.1 Measuring Dissimilarity Between Observations library(flextable) suppressMessages(conflict_prefer(&quot;compose&quot;, &quot;flextable&quot;)) library(dplyr) # for bind_cols() library(officer) # for fp_border() # Make analysis table `Table 11.2` &lt;- bind_cols(`Observation 1` = c(&quot;1&quot;, &quot;0&quot;), `1` = c(&quot;a&quot;, &quot;c&quot;), `0` = c(&quot;b&quot;, &quot;d&quot;)) # The header needs blank columns for spaces in actual table. # The wide column labels use Unicode characters for pi. Those details are # replaced later with the compose() function. theHeader &lt;- data.frame( col_keys = c(&quot;Observation 1&quot;, &quot;blank&quot;, &quot;1&quot;, &quot;0&quot;), line1 = c(&quot;Observation 1&quot;, &quot;&quot;, rep(&quot;Observtion 2&quot;, 2)), line2 = c(&quot;Observation 1&quot;, &quot;&quot;, &quot;1&quot;, &quot;0&quot;)) # Border lines big_border &lt;- fp_border(color=&quot;black&quot;, width = 2) # Make the table - compose uses Unicode character # https://stackoverflow.com/questions/64088118/in-r-flextable-can-complex-symbols-appear-in-column-headings flextable(`Table 11.2`, col_keys = theHeader$col_keys) %&gt;% set_header_df(mapping = theHeader, key = &quot;col_keys&quot;) %&gt;% theme_booktabs() %&gt;% merge_v(part = &quot;header&quot;) %&gt;% merge_h(part = &quot;header&quot;) %&gt;% align(align = &quot;center&quot;, part = &quot;all&quot;) %&gt;% empty_blanks() %&gt;% fix_border_issues() %&gt;% set_caption(caption = &quot;Cross-classification of two observtions on p binary response variables where p = (a + b + c + d)&quot;) %&gt;% set_table_properties(width = .75, layout = &quot;autofit&quot;) %&gt;% hline_top(part=&quot;header&quot;, border = big_border) %&gt;% hline_top(part=&quot;body&quot;, border = big_border) %&gt;% hline_bottom(part=&quot;body&quot;, border = big_border) .tabwid table{ border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 5px; margin-bottom: 5px; table-layout: fixed; border-spacing: 0; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-4eaab5b0{table-layout:auto;border-collapse:collapse;width:75%;}.cl-4ea56e2a{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4ea56e3e{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4ea57a50{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:3pt;padding-top:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;}.cl-4ea59d5a{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4ea59d6e{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4ea59d78{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4ea59d82{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4ea59d8c{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4ea59d96{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4ea59da0{width:54pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 16: Cross-classification of two observtions on p binary response variables where p = (a + b + c + d) Observation 1Observtion 2101ab0cd 11.3.2 Hierarchical Clustering Algorithm and Dendrograms 11.3.3 Example: Clustering States on Presidential Elections Elections &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Elections2.dat&quot;, header = TRUE, stringsAsFactors = TRUE) names(Elections) &lt;- c(&quot;Number&quot;, &quot;State&quot;, seq(1980, 2016, by =4)) # function to recode &quot;1&quot; to &quot;D&quot; and &quot;0&quot; to &quot;R&quot; rd &lt;- function(x){ if_else(x == 1, &quot;D&quot;, &quot;R&quot;) } `Table 11.3` &lt;- Elections %&gt;% select(-&quot;Number&quot;) %&gt;% mutate(across(where(is.numeric), rd)) knitr::kable(`Table 11.3`) State 1980 1984 1988 1992 1996 2000 2004 2008 2012 2016 Arizona R R R R D R R R R R California R R R D D D D D D D Colorado R R R D R R R D D D Florida R R R R D R R D D R Illinois R R R D D D D D D D Massachusetts R R D D D D D D D D Minnesota D D D D D D D D D D Missouro R R R D D R R R R R NewMexico R R R D D D R D D D NewYork R R D D D D D D D D Ohio R R R D D R R D D R Texas R R R R R R R R R R Virginia R R R R R R R D D D Wyoming R R R R R R R R R R Elections &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Elections2.dat&quot;, header = TRUE, stringsAsFactors = TRUE) distances &lt;- dist(Elections[, 3:12], method = &quot;manhattan&quot;) #manhattan measure dissimilarity by no. of election outcomes that differ democlust &lt;-hclust(distances, &quot;average&quot;) # hierarchical clustering plot(democlust, labels = Elections$state) library(gplots) Registered S3 method overwritten by &#39;gplots&#39;: method from reorder.factor gdata heatmap.2(as.matrix(Elections[, 3:12]), labRow = Elections$state, dendrogram = &quot;row&quot;, Colv=FALSE) 11.4 Smoothing: Generalized Additive Models 11.4.1 Generalized Additive Models \\[g(\\mu_i) = s_1(X_{i1}) + s_2(X_{i2}) + \\dots + s_p(X_{ip}),\\] 11.4.2 Example: GAMs for Horseshoe Crab Data 11.4.3 How Much Smoothing? The Bias/Variance Tradeoff 11.4.4 Example: Smoothing to Portray Probability of Kyphosis Kyphosis &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Kyphosis.dat&quot;, header = TRUE, stringsAsFactors = TRUE) Kyphosis %&gt;% filter(row_number() %in% c(1, n())) x y 1 12 1 2 206 0 gam.fit1 &lt;- gam(y~ s(x, df=1), family = binomial, data = Kyphosis) # linear complexity gam.fit2 &lt;- gam(y~ s(x, df=2), family = binomial, data = Kyphosis) # quadratic gam.fit3 &lt;- gam(y~ s(x, df=3), family = binomial, data = Kyphosis) # cubic anova(gam.fit1, gam.fit2, gam.fit3) Analysis of Deviance Table Model 1: y ~ s(x, df = 1) Model 2: y ~ s(x, df = 2) Model 3: y ~ s(x, df = 3) Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi) 1 38 54.504 2 37 49.216 0.99988 5.2879 0.02147 * 3 36 48.231 1.00017 0.9852 0.32097 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 plot(y ~ x, xlab = &quot;Age&quot;, ylab = &quot;Presence of Kythosis&quot;, data = Kyphosis) curve(predict(gam.fit2, data.frame(x = x), type = &quot;resp&quot;), add = TRUE) 11.5 Regularization for High-Dimensional Categorical Data (Large p) 11.5.1 Penalized-Likelihood Methods and \\(L_q\\)-Norm Smoothing \\[L^*(\\beta) = L(\\beta)-s(\\beta),\\] \\[s(\\beta)= \\lambda\\sum_{j=1}^p|\\beta_j|^q\\] 11.5.2 Implementing the Lasso 11.5.3 Example: Predicting Option on Abortion with Student Survey Students &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Students.dat&quot;, header = TRUE, stringsAsFactors = TRUE) fit &lt;- glm(abor ~ gender + age + hsgpa + cogpa + dhome + dres + tv + sport + news + aids + veg + ideol + relig + affirm, family = binomial, data = Students) # news LR P-value = 0.0003 # ideol LR P-value = 0.0010 summary(fit) Call: glm(formula = abor ~ gender + age + hsgpa + cogpa + dhome + dres + tv + sport + news + aids + veg + ideol + relig + affirm, family = binomial, data = Students) Deviance Residuals: Min 1Q Median 3Q Max -1.48649 0.00009 0.04055 0.20125 1.97028 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) 10.1014276 10.8914049 0.927 0.3537 gender 1.0021615 1.8655342 0.537 0.5911 age -0.0783427 0.1274839 -0.615 0.5389 hsgpa -3.7344482 2.8093160 -1.329 0.1837 cogpa 2.5112750 3.7399060 0.671 0.5019 dhome 0.0005574 0.0006789 0.821 0.4116 dres -0.3388230 0.2953830 -1.147 0.2514 tv 0.2659760 0.2531643 1.051 0.2934 sport 0.0272104 0.2551460 0.107 0.9151 news 1.3868778 0.6986772 1.985 0.0471 * aids 0.3966764 0.5663706 0.700 0.4837 veg 4.3213535 3.8614639 1.119 0.2631 ideol -1.6377902 0.7892505 -2.075 0.0380 * relig -0.7245665 0.7820724 -0.926 0.3542 affirm -2.7481550 2.6898822 -1.022 0.3069 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 62.719 on 59 degrees of freedom Residual deviance: 21.368 on 45 degrees of freedom AIC: 51.368 Number of Fisher Scoring iterations: 9 # LR test that all 14 betas = 0 1 - pchisq(62.719 - 21.368, 59-45) [1] 0.0001566051 library(tidyverse) Students &lt;- read.table(&quot;http://users.stat.ufl.edu/~aa/cat/data/Students.dat&quot;, header = TRUE, stringsAsFactors = TRUE) # explanatory variables for lasso x &lt;- with(Students, cbind(gender, age, hsgpa, cogpa, dhome, dres, tv, sport, news, aids, veg, ideol, relig, affirm)) abor &lt;- Students$abor library(glmnet) Loaded glmnet 4.0-2 # alpha = 1 is lasso fit.lasso &lt;- glmnet(x, abor, alpha = 1, family = &quot;binomial&quot;) plot(fit.lasso) set.seed(1) est &lt;- cv.glmnet(x, abor, alpha = 1, family = &quot;binomial&quot;, type.measure= &quot;class&quot;) # , maxit=1000000000) Warning: from glmnet Fortran code (error code -85); Convergence for 85th lambda value not reached after maxit=100000 iterations; solutions for larger lambdas returned # this is a random variable changes from run to run. It is 0.0661 in the book. est$lambda.min # best lambda by 10-fold cross-validation [1] 0.05000413 # also a random variable. It is 0.1267 in the book. theEst &lt;- est$lambda.1se # lambda suggested by one-standard-error rule theEst [1] 0.07962071 coef(glmnet(x, abor, alpha = 1, family = &quot;binomial&quot;, lambda = 0.1267787)) 15 x 1 sparse Matrix of class &quot;dgCMatrix&quot; s0 (Intercept) 2.3671144 gender . age . hsgpa . cogpa . dhome . dres . tv . sport . news . aids . veg . ideol -0.2599409 relig -0.1831115 affirm . coef(glmnet(x, abor, alpha = 1, family = &quot;binomial&quot;, lambda = theEst)) 15 x 1 sparse Matrix of class &quot;dgCMatrix&quot; s0 (Intercept) 2.66049060 gender . age . hsgpa . cogpa . dhome . dres . tv . sport . news 0.08634866 aids . veg . ideol -0.37767205 relig -0.32335761 affirm . summary(glm(abor ~ ideol + relig + news, family = binomial, data = Students)) Call: glm(formula = abor ~ ideol + relig + news, family = binomial, data = Students) Deviance Residuals: Min 1Q Median 3Q Max -2.29381 0.00082 0.10156 0.33555 1.65503 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) 3.5205 1.2513 2.814 0.00490 ** ideol -1.2515 0.4671 -2.679 0.00738 ** relig -0.7198 0.4982 -1.445 0.14854 news 1.1292 0.4574 2.469 0.01356 * --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 62.719 on 59 degrees of freedom Residual deviance: 29.791 on 56 degrees of freedom AIC: 37.791 Number of Fisher Scoring iterations: 7 summary(glm(abor ~ ideol + relig + news, family = binomial, data = Students)) Call: glm(formula = abor ~ ideol + relig + news, family = binomial, data = Students) Deviance Residuals: Min 1Q Median 3Q Max -2.29381 0.00082 0.10156 0.33555 1.65503 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) 3.5205 1.2513 2.814 0.00490 ** ideol -1.2515 0.4671 -2.679 0.00738 ** relig -0.7198 0.4982 -1.445 0.14854 news 1.1292 0.4574 2.469 0.01356 * --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 62.719 on 59 degrees of freedom Residual deviance: 29.791 on 56 degrees of freedom AIC: 37.791 Number of Fisher Scoring iterations: 7 11.5.4 Why Shrink ML Estimates Toward 0? 11.5.5 Issues In variable Selection (Dimension Reduction) 11.5.6 Controlling the False Discovery Rate pvals &lt;- c(0.0001, 0.0004, 0.0019, 0.0095, 0.020, 0.028, 0.030, 0.034, 0.046, 0.32, 0.43, 0.57, 0.65, 0.76, 1.00) p.adjust(pvals, method = c(&quot;bonferroni&quot;)) [1] 0.0015 0.0060 0.0285 0.1425 0.3000 0.4200 0.4500 0.5100 0.6900 1.0000 [11] 1.0000 1.0000 1.0000 1.0000 1.0000 p.adjust(pvals, method = c(&quot;fdr&quot;)) [1] 0.00150000 0.00300000 0.00950000 0.03562500 0.06000000 0.06375000 [7] 0.06375000 0.06375000 0.07666667 0.48000000 0.58636364 0.71250000 [13] 0.75000000 0.81428571 1.00000000 11.5.7 Large \\(p\\) also Makes Bayesian Inference Challenging "],["rmarkdown.html", "99 R Markdown Markdown highlighting Text coloring Equations Section references Footnotes Displaying Formula Greek letters", " 99 R Markdown .col2 { columns: 2 150px; /* number of columns and width in pixels*/ -webkit-columns: 2 150px; /* chrome, safari */ -moz-columns: 2 150px; /* firefox */ } .col3 { columns: 3 100px; -webkit-columns: 3 100px; -moz-columns: 3 100px; } Formatting Formatting Code bold Greek symbol \\boldsymbol{} typewriter {\\tt blah} slide font {\\sf blah} bold \\mathbf{x} pain \\mathrm{Pr} cursive \\mathcal{S} Blackboard bold \\mathbb{R} Symbols Symbols Code \\(\\times\\) \\times \\(\\stackrel{\\text{def}}{=}\\) \\stackrel{\\text{def}}{=} Markdown highlighting Formatting Code bold **bold** bold __bold__ italic *italic* italic _italic_ Text coloring colorText = function(x, color){ if(knitr::is_latex_output()) paste(&quot;\\\\textcolor{&quot;,color,&quot;}{&quot;,x,&quot;}&quot;,sep=&quot;&quot;) else if(knitr::is_html_output()) paste(&quot;&lt;font color=&#39;&quot;,color,&quot;&#39;&gt;&quot;,x,&quot;&lt;/font&gt;&quot;,sep=&quot;&quot;) else x } red = function(x){ if(knitr::is_latex_output()) paste(&quot;\\\\textcolor{&quot;,&#39;red&#39;,&quot;}{&quot;,x,&quot;}&quot;,sep=&quot;&quot;) else if(knitr::is_html_output()) paste(&quot;&lt;font color=&#39;red&#39;&gt;&quot;,x,&quot;&lt;/font&gt;&quot;,sep=&quot;&quot;) else x } Equations The names of equations can not include . or _ but it can include - \\begin{equation} P(Y=1) = (\\#eq:eq71) \\end{equation} \\@ref(eq:eq71) Section references Section 99.4 Section [99.4](#x99.4) Footnotes 1 ^[A footnote] Displaying Formula Notation Based on: https://www.calvin.edu/~rpruim/courses/s341/S17/from-class/MathinRmd.html Math Code \\(x = y\\) $x = y$ \\(x &lt; y\\) $x &lt; y$ \\(x &gt; y\\) $x &gt; y$ \\(x \\le y\\) $x \\le y$ \\(x \\ge y\\) $x \\ge y$ \\(x^{n}\\) $x^{n}$ \\(x_{n}\\) $x_{n}$ \\(\\overline{x}\\) $\\overline{x}$ \\(\\hat{x}\\) $\\hat{x}$ \\(\\tilde{x}\\) $\\tilde{x}$ \\(\\frac{a}{b}\\) $\\frac{a}{b}$ \\(\\displaystyle \\frac{a}{b}\\) $\\displaystyle \\frac{a}{b}$ \\(\\binom{n}{k}\\) $\\binom{n}{k}$ \\(x_{1} + x_{2} + \\cdots + x_{n}\\) $x_{1} + x_{2} + \\cdots + x_{n}$ \\(x_{1}, x_{2}, \\dots, x_{n}\\) $x_{1}, x_{2}, \\dots, x_{n}$ \\(\\mathbf{x} = \\langle x_{1}, x_{2}, \\dots, x_{n}\\rangle\\) $\\mathbf{x} = \\langle x_{1}, x_{2}, \\dots, x_{n}\\rangle$ \\(x \\in A\\) $x \\in A$ \\(|A|\\) $|A|$ \\(x \\in A\\) $x \\in A$ \\(x \\subset B\\) $x \\subset B$ \\(x \\subseteq B\\) $x \\subseteq B$ \\(A \\cup B\\) $A \\cup B$ \\(A \\cap B\\) $A \\cap B$ \\(X \\sim {\\sf Binom}(n, \\pi)\\) X \\sim {\\sf Binom}(n, \\pi)$ \\(\\mathrm{P}(X \\le x) = {\\tt pbinom}(x, n, \\pi)\\) $\\mathrm{P}(X \\le x) = {\\tt pbinom}(x, n, \\pi)$ \\(P(A \\mid B)\\) $P(A \\mid B)$ \\(\\mathrm{P}(A \\mid B)\\) $\\mathrm{P}(A \\mid B)$ \\(\\{1, 2, 3\\}\\) $\\{1, 2, 3\\}$ \\(\\sin(x)\\) $\\sin(x)$ \\(\\log(x)\\) $\\log(x)$ \\(\\int_{a}^{b}\\) $\\int_{a}^{b}$ \\(\\left(\\int_{a}^{b} f(x) \\; dx\\right)\\) $\\left(\\int_{a}^{b} f(x) \\; dx\\right)$ \\(\\left[\\int_{-\\infty}^{\\infty} f(x) \\; dx\\right]\\) $\\left[\\int_{\\-infty}^{\\infty} f(x) \\; dx\\right]$ \\(\\left. F(x) \\right|_{a}^{b}\\) $\\left. F(x) \\right|_{a}^{b}$ \\(\\sum_{x = a}^{b} f(x)\\) $\\sum_{x = a}^{b} f(x)$ \\(\\prod_{x = a}^{b} f(x)\\) $\\prod_{x = a}^{b} f(x)$ \\(\\lim_{x \\to \\infty} f(x)\\) $\\lim_{x \\to \\infty} f(x)$ \\(\\displaystyle \\lim_{x \\to \\infty} f(x)\\) $\\displaystyle \\lim_{x \\to \\infty} f(x)$ ` Greek letters Based on: https://www.calvin.edu/~rpruim/courses/s341/S17/from-class/MathinRmd.html letters code \\(\\alpha A\\) $\\alpha A$ \\(\\beta B\\) $\\beta B$ \\(\\gamma \\Gamma\\) $\\gamma \\Gamma$ \\(\\delta \\Delta\\) $\\delta \\Delta$ \\(\\epsilon \\varepsilon E\\) $\\epsilon \\varepsilon E$ \\(\\zeta Z \\sigma\\) $\\zeta Z \\sigma \\(\\eta H\\) $\\eta H$ \\(\\theta \\vartheta \\Theta\\) $\\theta \\vartheta \\Theta$ \\(\\iota I\\) $\\iota I$ \\(\\kappa K\\) $\\kappa K$ \\(\\lambda \\Lambda\\) $\\lambda \\Lambda$ \\(\\mu M\\) $\\mu M$ \\(\\nu N\\) $\\nu N$ \\(\\xi\\Xi\\) $\\xi\\Xi$ \\(o O\\) $o O$ (omicron) \\(\\pi \\Pi\\) $\\pi \\Pi$ \\(\\rho\\varrho P\\) $\\rho\\varrho P$ \\(\\sigma \\Sigma\\) \\sigma \\Sigma$ \\(\\tau T\\) $\\tau T$ \\(\\upsilon \\Upsilon\\) $\\upsilon \\Upsilon$ \\(\\phi \\varphi \\Phi\\) $\\phi \\varphi \\Phi$ \\(\\chi X\\) $\\chi X$ \\(\\psi \\Psi\\) $\\psi \\Psi$ \\(\\omega \\Omega\\) $\\omega \\Omega$ A footnote↩︎ "]]
